2022-04-14 23:50:11.020 | WARNING  | qlib.tests.data:qlib_data:150 - Data already exists: ~/igorlima/igor_tcc/qlib_data/br_data, the data download will be skipped
	If downloading is required: `exists_skip=False` or `change target_dir`
[105230:MainThread](2022-04-14 23:50:11,021) INFO - qlib.Initialization - [config.py:402] - default_conf: client.
[105230:MainThread](2022-04-14 23:50:11,344) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.
[105230:MainThread](2022-04-14 23:50:11,345) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/lisa/igorlima/igor_tcc/qlib_data/br_data')}
[105230:MainThread](2022-04-14 23:50:11,345) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:83] - Dataset intialization
[105230:MainThread](2022-04-14 23:50:21,059) INFO - qlib.timer - [log.py:113] - Time cost: 9.711s | Loading data Done
[105230:MainThread](2022-04-14 23:50:21,232) INFO - qlib.timer - [log.py:113] - Time cost: 0.061s | DropnaLabel Done
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/data/dataset/processor.py:347: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[cols] = t
[105230:MainThread](2022-04-14 23:50:21,397) INFO - qlib.timer - [log.py:113] - Time cost: 0.165s | CSRankNorm Done
[105230:MainThread](2022-04-14 23:50:21,397) INFO - qlib.timer - [log.py:113] - Time cost: 0.338s | fit & process data Done
[105230:MainThread](2022-04-14 23:50:21,397) INFO - qlib.timer - [log.py:113] - Time cost: 10.050s | Init data Done
[105230:MainThread](2022-04-14 23:50:21,398) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:86] - Start parameter tuning
[105230:MainThread](2022-04-14 23:50:23,437) ERROR - qlib.workflow - [utils.py:41] - An exception has been raised[KeyError: 'Record does not exist.'].
  File "hyperparameter_360_XGBoost_br.py", line 87, in <module>
    study = optuna.Study(study_name="XGBoost_360_br", storage="sqlite:///db_2_0.sqlite3")
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/study.py", line 231, in __init__
    study_id = storage.get_study_id_from_name(study_name)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/storages/_cached_storage.py", line 124, in get_study_id_from_name
    return self._backend.get_study_id_from_name(study_name)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/storages/_rdb/storage.py", line 317, in get_study_id_from_name
    study = models.StudyModel.find_or_raise_by_name(study_name, session)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/storages/_rdb/models.py", line 71, in find_or_raise_by_name
    raise KeyError(NOT_FOUND_MSG)
KeyError: 'Record does not exist.'
2022-04-14 23:54:53.721 | WARNING  | qlib.tests.data:qlib_data:150 - Data already exists: ~/igorlima/igor_tcc/qlib_data/br_data, the data download will be skipped
	If downloading is required: `exists_skip=False` or `change target_dir`
[108015:MainThread](2022-04-14 23:54:53,722) INFO - qlib.Initialization - [config.py:402] - default_conf: client.
[108015:MainThread](2022-04-14 23:54:54,031) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.
[108015:MainThread](2022-04-14 23:54:54,031) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/lisa/igorlima/igor_tcc/qlib_data/br_data')}
[108015:MainThread](2022-04-14 23:54:54,032) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:83] - Dataset intialization
[108015:MainThread](2022-04-14 23:55:02,013) INFO - qlib.timer - [log.py:113] - Time cost: 7.978s | Loading data Done
[108015:MainThread](2022-04-14 23:55:02,177) INFO - qlib.timer - [log.py:113] - Time cost: 0.058s | DropnaLabel Done
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/data/dataset/processor.py:347: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[cols] = t
[108015:MainThread](2022-04-14 23:55:02,332) INFO - qlib.timer - [log.py:113] - Time cost: 0.155s | CSRankNorm Done
[108015:MainThread](2022-04-14 23:55:02,332) INFO - qlib.timer - [log.py:113] - Time cost: 0.319s | fit & process data Done
[108015:MainThread](2022-04-14 23:55:02,333) INFO - qlib.timer - [log.py:113] - Time cost: 8.298s | Init data Done
[108015:MainThread](2022-04-14 23:55:02,333) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:86] - Start parameter tuning
[23:55:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[23:55:07] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[23:55:05] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09959	valid-rmse:1.10450
[23:55:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[23:55:09] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[23:55:11] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09958	valid-rmse:1.10449
[0]	train-rmse:1.09951	valid-rmse:1.10442
[0]	train-rmse:1.01947	valid-rmse:1.02992
[0]	train-rmse:1.09960	valid-rmse:1.10451
[20]	train-rmse:1.09960	valid-rmse:1.10451
[20]	train-rmse:1.09773	valid-rmse:1.10261
[20]	train-rmse:1.09935	valid-rmse:1.10427
[40]	train-rmse:1.09959	valid-rmse:1.10450
[20]	train-rmse:1.09913	valid-rmse:1.10403
[40]	train-rmse:1.09597	valid-rmse:1.10083
[60]	train-rmse:1.09959	valid-rmse:1.10450
[20]	train-rmse:0.99588	valid-rmse:1.07785
[40]	train-rmse:1.09912	valid-rmse:1.10403
[60]	train-rmse:1.09424	valid-rmse:1.09908
[80]	train-rmse:1.09959	valid-rmse:1.10450
[40]	train-rmse:1.09868	valid-rmse:1.10358
[100]	train-rmse:1.09958	valid-rmse:1.10449
[80]	train-rmse:1.09255	valid-rmse:1.09736
[60]	train-rmse:1.09888	valid-rmse:1.10379
[120]	train-rmse:1.09958	valid-rmse:1.10449
[100]	train-rmse:1.09088	valid-rmse:1.09567
[40]	train-rmse:0.99696	valid-rmse:1.15388
[60]	train-rmse:1.09824	valid-rmse:1.10312
[140]	train-rmse:1.09957	valid-rmse:1.10448
[80]	train-rmse:1.09865	valid-rmse:1.10356
[120]	train-rmse:1.08924	valid-rmse:1.09400
[160]	train-rmse:1.09957	valid-rmse:1.10448
[50]	train-rmse:0.99664	valid-rmse:1.18442
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import MultiIndex, Int64Index
[32m[I 2022-04-14 23:58:02,249][0m Trial 1 finished with value: 1.015398 and parameters: {'colsample_bytree': 0.49156288079621363, 'eta': 0.5578662506604894, 'max_depth': 7, 'n_estimators': 138, 'subsample': 0.24527228740603998}. Best is trial 1 with value: 1.015398.[0m
[23:58:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[140]	train-rmse:1.08763	valid-rmse:1.09237
[100]	train-rmse:1.09841	valid-rmse:1.10332
[180]	train-rmse:1.09956	valid-rmse:1.10447
[80]	train-rmse:1.09779	valid-rmse:1.10267
[0]	train-rmse:1.09960	valid-rmse:1.10451
[160]	train-rmse:1.08604	valid-rmse:1.09076
[200]	train-rmse:1.09956	valid-rmse:1.10447
[120]	train-rmse:1.09818	valid-rmse:1.10309
[220]	train-rmse:1.09956	valid-rmse:1.10447
[180]	train-rmse:1.08448	valid-rmse:1.08917
[100]	train-rmse:1.09735	valid-rmse:1.10222
[20]	train-rmse:1.09956	valid-rmse:1.10448
[240]	train-rmse:1.09955	valid-rmse:1.10446
[200]	train-rmse:1.08295	valid-rmse:1.08762
[140]	train-rmse:1.09794	valid-rmse:1.10286
[260]	train-rmse:1.09955	valid-rmse:1.10446
[120]	train-rmse:1.09691	valid-rmse:1.10177
[220]	train-rmse:1.08144	valid-rmse:1.08609
[280]	train-rmse:1.09954	valid-rmse:1.10445
[160]	train-rmse:1.09771	valid-rmse:1.10262
[240]	train-rmse:1.07996	valid-rmse:1.08459
[300]	train-rmse:1.09954	valid-rmse:1.10445
[140]	train-rmse:1.09647	valid-rmse:1.10133
[320]	train-rmse:1.09953	valid-rmse:1.10444
[260]	train-rmse:1.07851	valid-rmse:1.08311
[180]	train-rmse:1.09748	valid-rmse:1.10239
[340]	train-rmse:1.09953	valid-rmse:1.10444
[280]	train-rmse:1.07707	valid-rmse:1.08165
[20]	train-rmse:1.09958	valid-rmse:1.10449
[200]	train-rmse:1.09725	valid-rmse:1.10216
[160]	train-rmse:1.09604	valid-rmse:1.10088
[360]	train-rmse:1.09953	valid-rmse:1.10444
[300]	train-rmse:1.07566	valid-rmse:1.08021
[380]	train-rmse:1.09952	valid-rmse:1.10443
[320]	train-rmse:1.07428	valid-rmse:1.07882
[220]	train-rmse:1.09701	valid-rmse:1.10193
[400]	train-rmse:1.09952	valid-rmse:1.10443
[180]	train-rmse:1.09560	valid-rmse:1.10044
[340]	train-rmse:1.07292	valid-rmse:1.07743
[420]	train-rmse:1.09951	valid-rmse:1.10442
[240]	train-rmse:1.09678	valid-rmse:1.10169
[440]	train-rmse:1.09951	valid-rmse:1.10442
[360]	train-rmse:1.07158	valid-rmse:1.07607
[200]	train-rmse:1.09517	valid-rmse:1.10000
[460]	train-rmse:1.09950	valid-rmse:1.10441
[40]	train-rmse:1.09953	valid-rmse:1.10444
[380]	train-rmse:1.07027	valid-rmse:1.07473
[260]	train-rmse:1.09655	valid-rmse:1.10146
[480]	train-rmse:1.09950	valid-rmse:1.10441
[400]	train-rmse:1.06898	valid-rmse:1.07341
[220]	train-rmse:1.09474	valid-rmse:1.09956
[500]	train-rmse:1.09950	valid-rmse:1.10441
[280]	train-rmse:1.09632	valid-rmse:1.10123
[420]	train-rmse:1.06771	valid-rmse:1.07212
[40]	train-rmse:1.09955	valid-rmse:1.10447
[520]	train-rmse:1.09949	valid-rmse:1.10440
[240]	train-rmse:1.09431	valid-rmse:1.09912
[440]	train-rmse:1.06646	valid-rmse:1.07086
[300]	train-rmse:1.09609	valid-rmse:1.10100
[540]	train-rmse:1.09949	valid-rmse:1.10440
[560]	train-rmse:1.09949	valid-rmse:1.10439
[460]	train-rmse:1.06524	valid-rmse:1.06961
[320]	train-rmse:1.09586	valid-rmse:1.10077
[580]	train-rmse:1.09948	valid-rmse:1.10439
[260]	train-rmse:1.09388	valid-rmse:1.09868
[480]	train-rmse:1.06403	valid-rmse:1.06838
[600]	train-rmse:1.09947	valid-rmse:1.10438
[340]	train-rmse:1.09563	valid-rmse:1.10055
[500]	train-rmse:1.06285	valid-rmse:1.06718
[620]	train-rmse:1.09947	valid-rmse:1.10438
[280]	train-rmse:1.09346	valid-rmse:1.09825
[520]	train-rmse:1.06168	valid-rmse:1.06600
[640]	train-rmse:1.09946	valid-rmse:1.10438
[360]	train-rmse:1.09540	valid-rmse:1.10032
[540]	train-rmse:1.06054	valid-rmse:1.06483
[660]	train-rmse:1.09946	valid-rmse:1.10437
[300]	train-rmse:1.09303	valid-rmse:1.09782
[60]	train-rmse:1.09953	valid-rmse:1.10444
[380]	train-rmse:1.09518	valid-rmse:1.10009
[680]	train-rmse:1.09946	valid-rmse:1.10437
[60]	train-rmse:1.09949	valid-rmse:1.10441
[560]	train-rmse:1.05942	valid-rmse:1.06369
[700]	train-rmse:1.09945	valid-rmse:1.10436
[580]	train-rmse:1.05831	valid-rmse:1.06256
[400]	train-rmse:1.09495	valid-rmse:1.09986
[320]	train-rmse:1.09261	valid-rmse:1.09739
[720]	train-rmse:1.09945	valid-rmse:1.10436
[600]	train-rmse:1.05722	valid-rmse:1.06146
[740]	train-rmse:1.09944	valid-rmse:1.10435
[420]	train-rmse:1.09472	valid-rmse:1.09964
[620]	train-rmse:1.05615	valid-rmse:1.06037
[340]	train-rmse:1.09219	valid-rmse:1.09696
[760]	train-rmse:1.09944	valid-rmse:1.10435
[640]	train-rmse:1.05510	valid-rmse:1.05930
[440]	train-rmse:1.09450	valid-rmse:1.09941
[780]	train-rmse:1.09943	valid-rmse:1.10434
[660]	train-rmse:1.05407	valid-rmse:1.05825
[360]	train-rmse:1.09177	valid-rmse:1.09654
[800]	train-rmse:1.09943	valid-rmse:1.10434
[460]	train-rmse:1.09427	valid-rmse:1.09919
[680]	train-rmse:1.05305	valid-rmse:1.05722
[820]	train-rmse:1.09943	valid-rmse:1.10434
[80]	train-rmse:1.09951	valid-rmse:1.10442
[840]	train-rmse:1.09942	valid-rmse:1.10433
[380]	train-rmse:1.09136	valid-rmse:1.09611
[700]	train-rmse:1.05206	valid-rmse:1.05620
[480]	train-rmse:1.09404	valid-rmse:1.09896
[860]	train-rmse:1.09942	valid-rmse:1.10433
[720]	train-rmse:1.05108	valid-rmse:1.05520
[880]	train-rmse:1.09941	valid-rmse:1.10432
[500]	train-rmse:1.09382	valid-rmse:1.09874
[400]	train-rmse:1.09094	valid-rmse:1.09569
[740]	train-rmse:1.05012	valid-rmse:1.05422
[80]	train-rmse:1.09945	valid-rmse:1.10437
[900]	train-rmse:1.09941	valid-rmse:1.10432
[760]	train-rmse:1.04917	valid-rmse:1.05326
[920]	train-rmse:1.09940	valid-rmse:1.10431
[520]	train-rmse:1.09360	valid-rmse:1.09851
[420]	train-rmse:1.09053	valid-rmse:1.09527
[940]	train-rmse:1.09940	valid-rmse:1.10431
[780]	train-rmse:1.04824	valid-rmse:1.05231
[540]	train-rmse:1.09337	valid-rmse:1.09829
[960]	train-rmse:1.09940	valid-rmse:1.10431
[800]	train-rmse:1.04733	valid-rmse:1.05138
[440]	train-rmse:1.09012	valid-rmse:1.09485
[980]	train-rmse:1.09939	valid-rmse:1.10430
[560]	train-rmse:1.09315	valid-rmse:1.09807
[820]	train-rmse:1.04643	valid-rmse:1.05046
[999]	train-rmse:1.09939	valid-rmse:1.10430
[32m[I 2022-04-15 00:12:19,070][0m Trial 2 finished with value: 1.104298 and parameters: {'colsample_bytree': 0.3359943081149182, 'eta': 1.0944152230340072e-06, 'max_depth': 3, 'n_estimators': 26, 'subsample': 0.27751944081352803}. Best is trial 1 with value: 1.015398.[0m
[100]	train-rmse:1.09948	valid-rmse:1.10440
[00:12:23] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[840]	train-rmse:1.04555	valid-rmse:1.04956
[460]	train-rmse:1.08971	valid-rmse:1.09443
[580]	train-rmse:1.09293	valid-rmse:1.09785
[860]	train-rmse:1.04468	valid-rmse:1.04868
[600]	train-rmse:1.09270	valid-rmse:1.09762
[880]	train-rmse:1.04383	valid-rmse:1.04781
[480]	train-rmse:1.08930	valid-rmse:1.09401
[900]	train-rmse:1.04299	valid-rmse:1.04696
[620]	train-rmse:1.09248	valid-rmse:1.09740
[500]	train-rmse:1.08889	valid-rmse:1.09360
[920]	train-rmse:1.04217	valid-rmse:1.04612
[100]	train-rmse:1.09941	valid-rmse:1.10434
[640]	train-rmse:1.09226	valid-rmse:1.09718
[940]	train-rmse:1.04136	valid-rmse:1.04529
[520]	train-rmse:1.08849	valid-rmse:1.09319
[960]	train-rmse:1.04057	valid-rmse:1.04448
[120]	train-rmse:1.09946	valid-rmse:1.10438
[660]	train-rmse:1.09204	valid-rmse:1.09696
[980]	train-rmse:1.03979	valid-rmse:1.04369
[540]	train-rmse:1.08809	valid-rmse:1.09278
[680]	train-rmse:1.09182	valid-rmse:1.09674
[999]	train-rmse:1.03906	valid-rmse:1.04295
[32m[I 2022-04-15 00:15:52,981][0m Trial 3 finished with value: 1.042946 and parameters: {'colsample_bytree': 0.2721490608977349, 'eta': 0.00046272354440310014, 'max_depth': 3, 'n_estimators': 554, 'subsample': 0.5725879843869872}. Best is trial 1 with value: 1.015398.[0m
[00:15:57] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[20]	train-rmse:1.09960	valid-rmse:1.10451
[700]	train-rmse:1.09160	valid-rmse:1.09652
[560]	train-rmse:1.08769	valid-rmse:1.09237
[720]	train-rmse:1.09138	valid-rmse:1.09630
[20]	train-rmse:1.09959	valid-rmse:1.10450
[580]	train-rmse:1.08729	valid-rmse:1.09196
[740]	train-rmse:1.09116	valid-rmse:1.09608
[140]	train-rmse:1.09943	valid-rmse:1.10436
[600]	train-rmse:1.08689	valid-rmse:1.09156
[120]	train-rmse:1.09938	valid-rmse:1.10431
[40]	train-rmse:1.09958	valid-rmse:1.10449
[760]	train-rmse:1.09094	valid-rmse:1.09586
[620]	train-rmse:1.08649	valid-rmse:1.09115
[780]	train-rmse:1.09072	valid-rmse:1.09564
[60]	train-rmse:1.09957	valid-rmse:1.10448
[800]	train-rmse:1.09051	valid-rmse:1.09543
[640]	train-rmse:1.08610	valid-rmse:1.09075
[40]	train-rmse:1.09959	valid-rmse:1.10451
[820]	train-rmse:1.09029	valid-rmse:1.09521
[660]	train-rmse:1.08570	valid-rmse:1.09035
[80]	train-rmse:1.09956	valid-rmse:1.10447
[160]	train-rmse:1.09941	valid-rmse:1.10434
[840]	train-rmse:1.09007	valid-rmse:1.09499
[680]	train-rmse:1.08531	valid-rmse:1.08995
[860]	train-rmse:1.08986	valid-rmse:1.09478
[100]	train-rmse:1.09955	valid-rmse:1.10446
[700]	train-rmse:1.08492	valid-rmse:1.08956
[880]	train-rmse:1.08964	valid-rmse:1.09456
[140]	train-rmse:1.09934	valid-rmse:1.10427
[720]	train-rmse:1.08454	valid-rmse:1.08916
[900]	train-rmse:1.08943	valid-rmse:1.09435
[120]	train-rmse:1.09954	valid-rmse:1.10445
[920]	train-rmse:1.08921	valid-rmse:1.09413
[740]	train-rmse:1.08415	valid-rmse:1.08877
[180]	train-rmse:1.09939	valid-rmse:1.10431
[60]	train-rmse:1.09959	valid-rmse:1.10450
[140]	train-rmse:1.09953	valid-rmse:1.10444
[940]	train-rmse:1.08900	valid-rmse:1.09392
[760]	train-rmse:1.08377	valid-rmse:1.08838
[960]	train-rmse:1.08878	valid-rmse:1.09371
[160]	train-rmse:1.09952	valid-rmse:1.10443
[780]	train-rmse:1.08338	valid-rmse:1.08799
[980]	train-rmse:1.08857	valid-rmse:1.09349
[999]	train-rmse:1.08837	valid-rmse:1.09329
[32m[I 2022-04-15 00:25:30,874][0m Trial 5 finished with value: 1.093292 and parameters: {'colsample_bytree': 0.23909168156937943, 'eta': 6.022770376712244e-05, 'max_depth': 5, 'n_estimators': 644, 'subsample': 0.502793609005115}. Best is trial 1 with value: 1.015398.[0m
[800]	train-rmse:1.08300	valid-rmse:1.08760
[00:25:35] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[160]	train-rmse:1.09930	valid-rmse:1.10424
[180]	train-rmse:1.09951	valid-rmse:1.10442
[20]	train-rmse:1.09959	valid-rmse:1.10450
[200]	train-rmse:1.09936	valid-rmse:1.10429
[820]	train-rmse:1.08262	valid-rmse:1.08721
[40]	train-rmse:1.09958	valid-rmse:1.10449
[60]	train-rmse:1.09957	valid-rmse:1.10448
[80]	train-rmse:1.09956	valid-rmse:1.10447
[200]	train-rmse:1.09950	valid-rmse:1.10441
[840]	train-rmse:1.08224	valid-rmse:1.08683
[100]	train-rmse:1.09954	valid-rmse:1.10445
[80]	train-rmse:1.09959	valid-rmse:1.10450
[120]	train-rmse:1.09953	valid-rmse:1.10444
[140]	train-rmse:1.09952	valid-rmse:1.10443
[860]	train-rmse:1.08187	valid-rmse:1.08644
[220]	train-rmse:1.09949	valid-rmse:1.10440
[160]	train-rmse:1.09951	valid-rmse:1.10442
[180]	train-rmse:1.09950	valid-rmse:1.10441
[880]	train-rmse:1.08150	valid-rmse:1.08606
[200]	train-rmse:1.09949	valid-rmse:1.10439
[220]	train-rmse:1.09934	valid-rmse:1.10427
[220]	train-rmse:1.09947	valid-rmse:1.10438
[240]	train-rmse:1.09948	valid-rmse:1.10439
[240]	train-rmse:1.09946	valid-rmse:1.10437
[900]	train-rmse:1.08112	valid-rmse:1.08568
[260]	train-rmse:1.09945	valid-rmse:1.10436
[180]	train-rmse:1.09927	valid-rmse:1.10420
[280]	train-rmse:1.09944	valid-rmse:1.10435
[920]	train-rmse:1.08075	valid-rmse:1.08530
[260]	train-rmse:1.09947	valid-rmse:1.10438
[300]	train-rmse:1.09943	valid-rmse:1.10433
[320]	train-rmse:1.09941	valid-rmse:1.10432
[340]	train-rmse:1.09940	valid-rmse:1.10431
[940]	train-rmse:1.08038	valid-rmse:1.08493
[360]	train-rmse:1.09939	valid-rmse:1.10430
[100]	train-rmse:1.09959	valid-rmse:1.10450
[280]	train-rmse:1.09946	valid-rmse:1.10437
[380]	train-rmse:1.09938	valid-rmse:1.10429
[960]	train-rmse:1.08001	valid-rmse:1.08455
[240]	train-rmse:1.09932	valid-rmse:1.10425
[400]	train-rmse:1.09937	valid-rmse:1.10427
[420]	train-rmse:1.09936	valid-rmse:1.10426
[980]	train-rmse:1.07964	valid-rmse:1.08418
[300]	train-rmse:1.09945	valid-rmse:1.10435
[440]	train-rmse:1.09934	valid-rmse:1.10425
[460]	train-rmse:1.09933	valid-rmse:1.10424
[480]	train-rmse:1.09932	valid-rmse:1.10423
[999]	train-rmse:1.07930	valid-rmse:1.08382
[32m[I 2022-04-15 00:33:04,643][0m Trial 0 finished with value: 1.083824 and parameters: {'colsample_bytree': 0.4379955751629873, 'eta': 0.00011566311112452341, 'max_depth': 3, 'n_estimators': 211, 'subsample': 0.9731800156196793}. Best is trial 1 with value: 1.015398.[0m
[00:33:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[500]	train-rmse:1.09931	valid-rmse:1.10421
[0]	train-rmse:1.09148	valid-rmse:1.09706
[200]	train-rmse:1.09923	valid-rmse:1.10417
[320]	train-rmse:1.09943	valid-rmse:1.10434
[520]	train-rmse:1.09930	valid-rmse:1.10420
[540]	train-rmse:1.09928	valid-rmse:1.10419
[560]	train-rmse:1.09927	valid-rmse:1.10418
[260]	train-rmse:1.09929	valid-rmse:1.10423
[340]	train-rmse:1.09943	valid-rmse:1.10434
[580]	train-rmse:1.09926	valid-rmse:1.10417
[120]	train-rmse:1.09958	valid-rmse:1.10450
[600]	train-rmse:1.09925	valid-rmse:1.10416
[620]	train-rmse:1.09924	valid-rmse:1.10414
[640]	train-rmse:1.09923	valid-rmse:1.10413
[360]	train-rmse:1.09942	valid-rmse:1.10432
[660]	train-rmse:1.09922	valid-rmse:1.10412
[20]	train-rmse:1.00378	valid-rmse:1.02163
[680]	train-rmse:1.09920	valid-rmse:1.10411
[700]	train-rmse:1.09919	valid-rmse:1.10410
[720]	train-rmse:1.09918	valid-rmse:1.10408
[380]	train-rmse:1.09940	valid-rmse:1.10431
[740]	train-rmse:1.09917	valid-rmse:1.10407
[280]	train-rmse:1.09927	valid-rmse:1.10420
[220]	train-rmse:1.09919	valid-rmse:1.10414
[760]	train-rmse:1.09916	valid-rmse:1.10406
[780]	train-rmse:1.09914	valid-rmse:1.10405
[400]	train-rmse:1.09939	valid-rmse:1.10430
[800]	train-rmse:1.09913	valid-rmse:1.10404
[820]	train-rmse:1.09912	valid-rmse:1.10403
[840]	train-rmse:1.09911	valid-rmse:1.10401
[140]	train-rmse:1.09958	valid-rmse:1.10449
[40]	train-rmse:0.97542	valid-rmse:1.00509
[420]	train-rmse:1.09938	valid-rmse:1.10429
[860]	train-rmse:1.09910	valid-rmse:1.10400
[880]	train-rmse:1.09909	valid-rmse:1.10399
[900]	train-rmse:1.09908	valid-rmse:1.10398
[920]	train-rmse:1.09906	valid-rmse:1.10397
[440]	train-rmse:1.09937	valid-rmse:1.10428
[300]	train-rmse:1.09924	valid-rmse:1.10418
[940]	train-rmse:1.09905	valid-rmse:1.10396
[960]	train-rmse:1.09904	valid-rmse:1.10394
[980]	train-rmse:1.09903	valid-rmse:1.10393
[999]	train-rmse:1.09902	valid-rmse:1.10392
[460]	train-rmse:1.09936	valid-rmse:1.10427
[32m[I 2022-04-15 00:41:01,604][0m Trial 9 finished with value: 1.10392 and parameters: {'colsample_bytree': 0.3454130700713822, 'eta': 3.0212704428443838e-06, 'max_depth': 3, 'n_estimators': 796, 'subsample': 0.22364371352379422}. Best is trial 1 with value: 1.015398.[0m
[240]	train-rmse:1.09916	valid-rmse:1.10410
[00:41:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[60]	train-rmse:0.96204	valid-rmse:1.00173
[480]	train-rmse:1.09935	valid-rmse:1.10426
[160]	train-rmse:1.09958	valid-rmse:1.10449
[20]	train-rmse:1.09960	valid-rmse:1.10451
[320]	train-rmse:1.09922	valid-rmse:1.10416
[500]	train-rmse:1.09934	valid-rmse:1.10425
[80]	train-rmse:0.95209	valid-rmse:1.00081
[520]	train-rmse:1.09933	valid-rmse:1.10424
[40]	train-rmse:1.09960	valid-rmse:1.10451
[260]	train-rmse:1.09912	valid-rmse:1.10407
[540]	train-rmse:1.09932	valid-rmse:1.10423
[340]	train-rmse:1.09920	valid-rmse:1.10414
[180]	train-rmse:1.09958	valid-rmse:1.10449
[60]	train-rmse:1.09960	valid-rmse:1.10451
[560]	train-rmse:1.09931	valid-rmse:1.10422
[67]	train-rmse:1.09960	valid-rmse:1.10451
[32m[I 2022-04-15 00:46:40,503][0m Trial 11 finished with value: 1.104512 and parameters: {'colsample_bytree': 0.5225270615905753, 'eta': 2.3033874453989724e-08, 'max_depth': 7, 'n_estimators': 843, 'subsample': 0.5330356657718209}. Best is trial 1 with value: 1.015398.[0m
[00:46:44] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[100]	train-rmse:0.94136	valid-rmse:1.00084
[0]	train-rmse:1.09793	valid-rmse:1.10285
[580]	train-rmse:1.09930	valid-rmse:1.10421
[20]	train-rmse:1.06872	valid-rmse:1.07439
[600]	train-rmse:1.09929	valid-rmse:1.10420
[40]	train-rmse:1.04703	valid-rmse:1.05354
[280]	train-rmse:1.09908	valid-rmse:1.10403
[360]	train-rmse:1.09918	valid-rmse:1.10412
[60]	train-rmse:1.03139	valid-rmse:1.03853
[120]	train-rmse:0.93104	valid-rmse:1.00119
[620]	train-rmse:1.09928	valid-rmse:1.10419
[200]	train-rmse:1.09957	valid-rmse:1.10448
[123]	train-rmse:0.92978	valid-rmse:1.00121
[32m[I 2022-04-15 00:50:03,556][0m Trial 10 finished with value: 1.000768 and parameters: {'colsample_bytree': 0.6023602728561701, 'eta': 0.03860480425923229, 'max_depth': 9, 'n_estimators': 73, 'subsample': 0.6116172587858377}. Best is trial 10 with value: 1.000768.[0m
[00:50:07] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:1.01978	valid-rmse:1.02783
[0]	train-rmse:1.09959	valid-rmse:1.10451
[640]	train-rmse:1.09927	valid-rmse:1.10418
[100]	train-rmse:1.01107	valid-rmse:1.01998
[380]	train-rmse:1.09915	valid-rmse:1.10409
[660]	train-rmse:1.09926	valid-rmse:1.10417
[120]	train-rmse:1.00450	valid-rmse:1.01433
[300]	train-rmse:1.09904	valid-rmse:1.10400
[20]	train-rmse:1.09947	valid-rmse:1.10439
[680]	train-rmse:1.09925	valid-rmse:1.10416
[140]	train-rmse:0.99966	valid-rmse:1.01030
[220]	train-rmse:1.09957	valid-rmse:1.10448
[160]	train-rmse:0.99597	valid-rmse:1.00734
[700]	train-rmse:1.09924	valid-rmse:1.10415
[400]	train-rmse:1.09913	valid-rmse:1.10407
[180]	train-rmse:0.99299	valid-rmse:1.00521
[40]	train-rmse:1.09935	valid-rmse:1.10427
[720]	train-rmse:1.09923	valid-rmse:1.10414
[200]	train-rmse:0.99054	valid-rmse:1.00368
[740]	train-rmse:1.09922	valid-rmse:1.10413
[320]	train-rmse:1.09901	valid-rmse:1.10396
[220]	train-rmse:0.98861	valid-rmse:1.00262
[60]	train-rmse:1.09923	valid-rmse:1.10415
[240]	train-rmse:1.09957	valid-rmse:1.10448
[420]	train-rmse:1.09910	valid-rmse:1.10405
[240]	train-rmse:0.98698	valid-rmse:1.00186
[760]	train-rmse:1.09921	valid-rmse:1.10411
[260]	train-rmse:0.98554	valid-rmse:1.00126
[780]	train-rmse:1.09920	valid-rmse:1.10410
[280]	train-rmse:0.98418	valid-rmse:1.00076
[80]	train-rmse:1.09911	valid-rmse:1.10404
[800]	train-rmse:1.09919	valid-rmse:1.10409
[300]	train-rmse:0.98313	valid-rmse:1.00048
[440]	train-rmse:1.09908	valid-rmse:1.10403
[340]	train-rmse:1.09897	valid-rmse:1.10393
[820]	train-rmse:1.09918	valid-rmse:1.10408
[320]	train-rmse:0.98199	valid-rmse:1.00033
[260]	train-rmse:1.09956	valid-rmse:1.10448
[100]	train-rmse:1.09899	valid-rmse:1.10392
[340]	train-rmse:0.98107	valid-rmse:1.00022
[840]	train-rmse:1.09917	valid-rmse:1.10407
[360]	train-rmse:0.98011	valid-rmse:1.00016
[860]	train-rmse:1.09916	valid-rmse:1.10406
[460]	train-rmse:1.09905	valid-rmse:1.10401
[380]	train-rmse:0.97912	valid-rmse:1.00007
[120]	train-rmse:1.09886	valid-rmse:1.10380
[880]	train-rmse:1.09915	valid-rmse:1.10405
[360]	train-rmse:1.09893	valid-rmse:1.10390
[400]	train-rmse:0.97826	valid-rmse:1.00000
[280]	train-rmse:1.09956	valid-rmse:1.10447
[900]	train-rmse:1.09914	valid-rmse:1.10404
[420]	train-rmse:0.97740	valid-rmse:1.00001
[480]	train-rmse:1.09903	valid-rmse:1.10398
[140]	train-rmse:1.09874	valid-rmse:1.10368
[920]	train-rmse:1.09913	valid-rmse:1.10403
[440]	train-rmse:0.97642	valid-rmse:1.00002
[460]	train-rmse:0.97549	valid-rmse:1.00002
[940]	train-rmse:1.09912	valid-rmse:1.10402
[465]	train-rmse:0.97528	valid-rmse:1.00001
[32m[I 2022-04-15 01:07:13,464][0m Trial 12 finished with value: 0.999956 and parameters: {'colsample_bytree': 0.35918040854036826, 'eta': 0.008578685810531636, 'max_depth': 7, 'n_estimators': 724, 'subsample': 0.2580846645871704}. Best is trial 12 with value: 0.999956.[0m
[01:07:17] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[380]	train-rmse:1.09889	valid-rmse:1.10386
[160]	train-rmse:1.09862	valid-rmse:1.10357
[960]	train-rmse:1.09911	valid-rmse:1.10401
[300]	train-rmse:1.09956	valid-rmse:1.10447
[500]	train-rmse:1.09901	valid-rmse:1.10396
[980]	train-rmse:1.09910	valid-rmse:1.10400
[20]	train-rmse:1.09960	valid-rmse:1.10451
[999]	train-rmse:1.09909	valid-rmse:1.10399
[180]	train-rmse:1.09850	valid-rmse:1.10345
[32m[I 2022-04-15 01:10:02,916][0m Trial 8 finished with value: 1.103991 and parameters: {'colsample_bytree': 0.8496745657139164, 'eta': 2.6482300182925704e-06, 'max_depth': 3, 'n_estimators': 198, 'subsample': 0.691653043896203}. Best is trial 12 with value: 0.999956.[0m
[01:10:07] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09820	valid-rmse:1.10321
[520]	train-rmse:1.09898	valid-rmse:1.10394
[40]	train-rmse:1.09960	valid-rmse:1.10451
[400]	train-rmse:1.09886	valid-rmse:1.10383
[320]	train-rmse:1.09956	valid-rmse:1.10447
[200]	train-rmse:1.09838	valid-rmse:1.10333
[20]	train-rmse:1.07311	valid-rmse:1.07996
[60]	train-rmse:1.09960	valid-rmse:1.10451
[540]	train-rmse:1.09896	valid-rmse:1.10392
[220]	train-rmse:1.09826	valid-rmse:1.10321
[40]	train-rmse:1.05304	valid-rmse:1.06186
[420]	train-rmse:1.09882	valid-rmse:1.10379
[80]	train-rmse:1.09960	valid-rmse:1.10451
[340]	train-rmse:1.09955	valid-rmse:1.10447
[240]	train-rmse:1.09814	valid-rmse:1.10310
[560]	train-rmse:1.09894	valid-rmse:1.10390
[97]	train-rmse:1.09960	valid-rmse:1.10451
[32m[I 2022-04-15 01:17:14,507][0m Trial 14 finished with value: 1.104511 and parameters: {'colsample_bytree': 0.9278452000221926, 'eta': 1.1268884237946623e-07, 'max_depth': 5, 'n_estimators': 409, 'subsample': 0.7348922406893454}. Best is trial 12 with value: 0.999956.[0m
[60]	train-rmse:1.03729	valid-rmse:1.04768
[01:17:18] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08655	valid-rmse:1.09256
[260]	train-rmse:1.09802	valid-rmse:1.10298
[440]	train-rmse:1.09878	valid-rmse:1.10376
[360]	train-rmse:1.09955	valid-rmse:1.10446
[580]	train-rmse:1.09891	valid-rmse:1.10387
[80]	train-rmse:1.02448	valid-rmse:1.03670
[20]	train-rmse:0.98511	valid-rmse:1.00836
[280]	train-rmse:1.09790	valid-rmse:1.10286
[100]	train-rmse:1.01429	valid-rmse:1.02834
[600]	train-rmse:1.09889	valid-rmse:1.10385
[40]	train-rmse:0.96151	valid-rmse:1.00311
[460]	train-rmse:1.09875	valid-rmse:1.10373
[380]	train-rmse:1.09954	valid-rmse:1.10446
[300]	train-rmse:1.09778	valid-rmse:1.10275
[120]	train-rmse:1.00585	valid-rmse:1.02169
[60]	train-rmse:0.94592	valid-rmse:1.00394
[620]	train-rmse:1.09887	valid-rmse:1.10383
[320]	train-rmse:1.09766	valid-rmse:1.10263
[400]	train-rmse:1.09954	valid-rmse:1.10446
[140]	train-rmse:0.99915	valid-rmse:1.01659
[480]	train-rmse:1.09871	valid-rmse:1.10369
[80]	train-rmse:0.93042	valid-rmse:1.00538
[340]	train-rmse:1.09753	valid-rmse:1.10252
[640]	train-rmse:1.09884	valid-rmse:1.10381
[89]	train-rmse:0.92379	valid-rmse:1.00605
[32m[I 2022-04-15 01:28:45,476][0m Trial 16 finished with value: 1.003005 and parameters: {'colsample_bytree': 0.7012566249035236, 'eta': 0.06447775316239014, 'max_depth': 9, 'n_estimators': 1011, 'subsample': 0.4201259795519234}. Best is trial 12 with value: 0.999956.[0m
[01:28:49] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[160]	train-rmse:0.99369	valid-rmse:1.01268
[0]	train-rmse:1.09805	valid-rmse:1.10309
[360]	train-rmse:1.09742	valid-rmse:1.10240
[420]	train-rmse:1.09954	valid-rmse:1.10445
[500]	train-rmse:1.09867	valid-rmse:1.10366
[660]	train-rmse:1.09882	valid-rmse:1.10379
[180]	train-rmse:0.98901	valid-rmse:1.00963
[380]	train-rmse:1.09730	valid-rmse:1.10228
[20]	train-rmse:1.06996	valid-rmse:1.07772
[200]	train-rmse:0.98507	valid-rmse:1.00724
[680]	train-rmse:1.09879	valid-rmse:1.10377
[440]	train-rmse:1.09953	valid-rmse:1.10445
[520]	train-rmse:1.09864	valid-rmse:1.10362
[400]	train-rmse:1.09718	valid-rmse:1.10217
[40]	train-rmse:1.04789	valid-rmse:1.05846
[220]	train-rmse:0.98176	valid-rmse:1.00541
[700]	train-rmse:1.09877	valid-rmse:1.10374
[420]	train-rmse:1.09706	valid-rmse:1.10205
[460]	train-rmse:1.09953	valid-rmse:1.10445
[540]	train-rmse:1.09860	valid-rmse:1.10359
[240]	train-rmse:0.97866	valid-rmse:1.00402
[440]	train-rmse:1.09694	valid-rmse:1.10194
[60]	train-rmse:1.03037	valid-rmse:1.04385
[720]	train-rmse:1.09875	valid-rmse:1.10372
[260]	train-rmse:0.97557	valid-rmse:1.00302
[460]	train-rmse:1.09682	valid-rmse:1.10182
[480]	train-rmse:1.09953	valid-rmse:1.10445
[560]	train-rmse:1.09856	valid-rmse:1.10356
[740]	train-rmse:1.09872	valid-rmse:1.10370
[80]	train-rmse:1.01661	valid-rmse:1.03286
[280]	train-rmse:0.97309	valid-rmse:1.00217
[480]	train-rmse:1.09670	valid-rmse:1.10170
[760]	train-rmse:1.09870	valid-rmse:1.10368
[500]	train-rmse:1.09953	valid-rmse:1.10444
[500]	train-rmse:1.09658	valid-rmse:1.10159
[300]	train-rmse:0.97097	valid-rmse:1.00155
[580]	train-rmse:1.09852	valid-rmse:1.10352
[100]	train-rmse:1.00558	valid-rmse:1.02464
[780]	train-rmse:1.09868	valid-rmse:1.10366
[520]	train-rmse:1.09646	valid-rmse:1.10148
[320]	train-rmse:0.96874	valid-rmse:1.00103
[520]	train-rmse:1.09952	valid-rmse:1.10444
[120]	train-rmse:0.99658	valid-rmse:1.01839
[600]	train-rmse:1.09849	valid-rmse:1.10349
[540]	train-rmse:1.09634	valid-rmse:1.10136
[800]	train-rmse:1.09865	valid-rmse:1.10363
[340]	train-rmse:0.96671	valid-rmse:1.00068
[560]	train-rmse:1.09622	valid-rmse:1.10125
[540]	train-rmse:1.09952	valid-rmse:1.10444
[140]	train-rmse:0.98955	valid-rmse:1.01374
[620]	train-rmse:1.09845	valid-rmse:1.10345
[360]	train-rmse:0.96475	valid-rmse:1.00033
[820]	train-rmse:1.09863	valid-rmse:1.10361
[580]	train-rmse:1.09611	valid-rmse:1.10113
[380]	train-rmse:0.96264	valid-rmse:1.00004
[560]	train-rmse:1.09952	valid-rmse:1.10444
[160]	train-rmse:0.98359	valid-rmse:1.01021
[840]	train-rmse:1.09861	valid-rmse:1.10359
[600]	train-rmse:1.09599	valid-rmse:1.10102
[640]	train-rmse:1.09841	valid-rmse:1.10342
[400]	train-rmse:0.96090	valid-rmse:0.99988
[620]	train-rmse:1.09587	valid-rmse:1.10090
[860]	train-rmse:1.09858	valid-rmse:1.10357
[180]	train-rmse:0.97871	valid-rmse:1.00751
[580]	train-rmse:1.09951	valid-rmse:1.10443
[660]	train-rmse:1.09838	valid-rmse:1.10339
[420]	train-rmse:0.95896	valid-rmse:0.99979
[640]	train-rmse:1.09575	valid-rmse:1.10079
[880]	train-rmse:1.09856	valid-rmse:1.10355
[200]	train-rmse:0.97470	valid-rmse:1.00551
[440]	train-rmse:0.95710	valid-rmse:0.99974
[600]	train-rmse:1.09951	valid-rmse:1.10443
[660]	train-rmse:1.09563	valid-rmse:1.10067
[680]	train-rmse:1.09834	valid-rmse:1.10335
[900]	train-rmse:1.09854	valid-rmse:1.10353
[680]	train-rmse:1.09551	valid-rmse:1.10056
[460]	train-rmse:0.95544	valid-rmse:0.99965
[220]	train-rmse:0.97107	valid-rmse:1.00406
[620]	train-rmse:1.09951	valid-rmse:1.10443
[920]	train-rmse:1.09851	valid-rmse:1.10350
[700]	train-rmse:1.09540	valid-rmse:1.10045
[700]	train-rmse:1.09831	valid-rmse:1.10332
[480]	train-rmse:0.95385	valid-rmse:0.99958
[240]	train-rmse:0.96801	valid-rmse:1.00294
[720]	train-rmse:1.09528	valid-rmse:1.10033
[940]	train-rmse:1.09849	valid-rmse:1.10348
[640]	train-rmse:1.09950	valid-rmse:1.10442
[500]	train-rmse:0.95202	valid-rmse:0.99950
[720]	train-rmse:1.09827	valid-rmse:1.10328
[740]	train-rmse:1.09516	valid-rmse:1.10022
[260]	train-rmse:0.96510	valid-rmse:1.00210
[960]	train-rmse:1.09847	valid-rmse:1.10346
[520]	train-rmse:0.95017	valid-rmse:0.99957
[660]	train-rmse:1.09950	valid-rmse:1.10442
[760]	train-rmse:1.09504	valid-rmse:1.10011
[980]	train-rmse:1.09844	valid-rmse:1.10344
[740]	train-rmse:1.09823	valid-rmse:1.10325
[540]	train-rmse:0.94826	valid-rmse:0.99962
[280]	train-rmse:0.96249	valid-rmse:1.00142
[780]	train-rmse:1.09493	valid-rmse:1.09999
[546]	train-rmse:0.94781	valid-rmse:0.99961
[32m[I 2022-04-15 02:16:34,305][0m Trial 15 finished with value: 0.999478 and parameters: {'colsample_bytree': 0.7103050612805366, 'eta': 0.006748878236202877, 'max_depth': 9, 'n_estimators': 1019, 'subsample': 0.3923426245032063}. Best is trial 15 with value: 0.999478.[0m
[02:16:38] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09875	valid-rmse:1.10372
[680]	train-rmse:1.09950	valid-rmse:1.10442
[999]	train-rmse:1.09842	valid-rmse:1.10342
[32m[I 2022-04-15 02:18:10,931][0m Trial 6 finished with value: 1.103417 and parameters: {'colsample_bytree': 0.7425498626891842, 'eta': 5.644473287709005e-06, 'max_depth': 9, 'n_estimators': 915, 'subsample': 0.4778007690277277}. Best is trial 15 with value: 0.999478.[0m
[02:18:15] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[800]	train-rmse:1.09481	valid-rmse:1.09988
[0]	train-rmse:1.09918	valid-rmse:1.10410
[300]	train-rmse:0.96006	valid-rmse:1.00099
[760]	train-rmse:1.09819	valid-rmse:1.10322
[20]	train-rmse:1.08264	valid-rmse:1.08867
[20]	train-rmse:1.09095	valid-rmse:1.09608
[820]	train-rmse:1.09469	valid-rmse:1.09977
[700]	train-rmse:1.09950	valid-rmse:1.10442
[40]	train-rmse:1.08328	valid-rmse:1.08866
[40]	train-rmse:1.06853	valid-rmse:1.07568
[320]	train-rmse:0.95758	valid-rmse:1.00060
[840]	train-rmse:1.09458	valid-rmse:1.09965
[780]	train-rmse:1.09816	valid-rmse:1.10318
[60]	train-rmse:1.07623	valid-rmse:1.08185
[60]	train-rmse:1.05640	valid-rmse:1.06462
[720]	train-rmse:1.09949	valid-rmse:1.10441
[80]	train-rmse:1.06968	valid-rmse:1.07554
[860]	train-rmse:1.09446	valid-rmse:1.09954
[340]	train-rmse:0.95564	valid-rmse:1.00026
[100]	train-rmse:1.06359	valid-rmse:1.06967
[80]	train-rmse:1.04577	valid-rmse:1.05525
[800]	train-rmse:1.09812	valid-rmse:1.10315
[880]	train-rmse:1.09434	valid-rmse:1.09943
[120]	train-rmse:1.05792	valid-rmse:1.06422
[740]	train-rmse:1.09949	valid-rmse:1.10441
[100]	train-rmse:1.03652	valid-rmse:1.04710
[140]	train-rmse:1.05265	valid-rmse:1.05917
[360]	train-rmse:0.95341	valid-rmse:1.00007
[900]	train-rmse:1.09423	valid-rmse:1.09932
[820]	train-rmse:1.09808	valid-rmse:1.10311
[160]	train-rmse:1.04778	valid-rmse:1.05451
[120]	train-rmse:1.02842	valid-rmse:1.04013
[920]	train-rmse:1.09411	valid-rmse:1.09920
[760]	train-rmse:1.09949	valid-rmse:1.10441
[180]	train-rmse:1.04327	valid-rmse:1.05017
[380]	train-rmse:0.95115	valid-rmse:0.99992
[140]	train-rmse:1.02144	valid-rmse:1.03413
[200]	train-rmse:1.03910	valid-rmse:1.04621
[940]	train-rmse:1.09399	valid-rmse:1.09909
[840]	train-rmse:1.09805	valid-rmse:1.10308
[220]	train-rmse:1.03524	valid-rmse:1.04256
[780]	train-rmse:1.09949	valid-rmse:1.10441
[160]	train-rmse:1.01521	valid-rmse:1.02907
[960]	train-rmse:1.09388	valid-rmse:1.09898
[400]	train-rmse:0.94913	valid-rmse:0.99978
[240]	train-rmse:1.03164	valid-rmse:1.03917
[860]	train-rmse:1.09801	valid-rmse:1.10305
[180]	train-rmse:1.00988	valid-rmse:1.02472
[980]	train-rmse:1.09376	valid-rmse:1.09887
[260]	train-rmse:1.02828	valid-rmse:1.03607
[800]	train-rmse:1.09948	valid-rmse:1.10440
[420]	train-rmse:0.94765	valid-rmse:0.99973
[280]	train-rmse:1.02519	valid-rmse:1.03318
[999]	train-rmse:1.09365	valid-rmse:1.09876
[200]	train-rmse:1.00519	valid-rmse:1.02096
[32m[I 2022-04-15 02:40:18,836][0m Trial 13 finished with value: 1.09876 and parameters: {'colsample_bytree': 0.7779790850490254, 'eta': 3.0137859373788002e-05, 'max_depth': 7, 'n_estimators': 829, 'subsample': 0.536977214923771}. Best is trial 15 with value: 0.999478.[0m
[02:40:23] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09874	valid-rmse:1.10370
[300]	train-rmse:1.02233	valid-rmse:1.03052
[880]	train-rmse:1.09797	valid-rmse:1.10301
[220]	train-rmse:1.00112	valid-rmse:1.01781
[440]	train-rmse:0.94561	valid-rmse:0.99970
[20]	train-rmse:1.08254	valid-rmse:1.08851
[320]	train-rmse:1.01969	valid-rmse:1.02812
[820]	train-rmse:1.09948	valid-rmse:1.10440
[340]	train-rmse:1.01723	valid-rmse:1.02588
[240]	train-rmse:0.99743	valid-rmse:1.01511
[40]	train-rmse:1.06833	valid-rmse:1.07548
[900]	train-rmse:1.09794	valid-rmse:1.10298
[360]	train-rmse:1.01491	valid-rmse:1.02380
[460]	train-rmse:0.94366	valid-rmse:0.99961
[840]	train-rmse:1.09948	valid-rmse:1.10440
[60]	train-rmse:1.05628	valid-rmse:1.06440
[260]	train-rmse:0.99395	valid-rmse:1.01290
[380]	train-rmse:1.01273	valid-rmse:1.02187
[400]	train-rmse:1.01076	valid-rmse:1.02010
[80]	train-rmse:1.04564	valid-rmse:1.05500
[920]	train-rmse:1.09790	valid-rmse:1.10294
[480]	train-rmse:0.94189	valid-rmse:0.99961
[280]	train-rmse:0.99107	valid-rmse:1.01092
[860]	train-rmse:1.09947	valid-rmse:1.10439
[420]	train-rmse:1.00890	valid-rmse:1.01844
[100]	train-rmse:1.03638	valid-rmse:1.04685
[440]	train-rmse:1.00720	valid-rmse:1.01694
[300]	train-rmse:0.98842	valid-rmse:1.00922
[500]	train-rmse:0.93968	valid-rmse:0.99959
[940]	train-rmse:1.09786	valid-rmse:1.10291
[460]	train-rmse:1.00563	valid-rmse:1.01557
[120]	train-rmse:1.02828	valid-rmse:1.03986
[880]	train-rmse:1.09947	valid-rmse:1.10439
[320]	train-rmse:0.98622	valid-rmse:1.00785
[480]	train-rmse:1.00412	valid-rmse:1.01428
[140]	train-rmse:1.02128	valid-rmse:1.03392
[520]	train-rmse:0.93787	valid-rmse:0.99961
[500]	train-rmse:1.00273	valid-rmse:1.01315
[340]	train-rmse:0.98408	valid-rmse:1.00661
[960]	train-rmse:1.09783	valid-rmse:1.10288
[900]	train-rmse:1.09947	valid-rmse:1.10439
[160]	train-rmse:1.01513	valid-rmse:1.02884
[520]	train-rmse:1.00144	valid-rmse:1.01206
[360]	train-rmse:0.98208	valid-rmse:1.00562
[540]	train-rmse:1.00022	valid-rmse:1.01108
[540]	train-rmse:0.93603	valid-rmse:0.99965
[180]	train-rmse:1.00978	valid-rmse:1.02448
[545]	train-rmse:0.93545	valid-rmse:0.99963
[32m[I 2022-04-15 03:00:37,575][0m Trial 17 finished with value: 0.99957 and parameters: {'colsample_bytree': 0.6627562145039668, 'eta': 0.007466393805783826, 'max_depth': 9, 'n_estimators': 441, 'subsample': 0.8357576994302865}. Best is trial 15 with value: 0.999478.[0m
[980]	train-rmse:1.09779	valid-rmse:1.10284
[560]	train-rmse:0.99909	valid-rmse:1.01017
[03:00:41] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09902	valid-rmse:1.10398
[920]	train-rmse:1.09946	valid-rmse:1.10438
[380]	train-rmse:0.98013	valid-rmse:1.00473
[200]	train-rmse:1.00511	valid-rmse:1.02077
[580]	train-rmse:0.99801	valid-rmse:1.00930
[400]	train-rmse:0.97849	valid-rmse:1.00395
[600]	train-rmse:0.99702	valid-rmse:1.00851
[220]	train-rmse:1.00107	valid-rmse:1.01759
[999]	train-rmse:1.09775	valid-rmse:1.10281
[20]	train-rmse:1.08781	valid-rmse:1.09377
[32m[I 2022-04-15 03:04:32,262][0m Trial 4 finished with value: 1.10281 and parameters: {'colsample_bytree': 0.9840810530045516, 'eta': 8.77712503285814e-06, 'max_depth': 9, 'n_estimators': 726, 'subsample': 0.5622021515588467}. Best is trial 15 with value: 0.999478.[0m
[03:04:36] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[940]	train-rmse:1.09946	valid-rmse:1.10438
[0]	train-rmse:1.09928	valid-rmse:1.10422
[620]	train-rmse:0.99608	valid-rmse:1.00780
[420]	train-rmse:0.97676	valid-rmse:1.00335
[240]	train-rmse:0.99737	valid-rmse:1.01497
[640]	train-rmse:0.99518	valid-rmse:1.00715
[40]	train-rmse:1.07757	valid-rmse:1.08454
[440]	train-rmse:0.97534	valid-rmse:1.00283
[260]	train-rmse:0.99385	valid-rmse:1.01269
[660]	train-rmse:0.99435	valid-rmse:1.00653
[20]	train-rmse:1.09305	valid-rmse:1.09851
[960]	train-rmse:1.09946	valid-rmse:1.10438
[680]	train-rmse:0.99357	valid-rmse:1.00598
[280]	train-rmse:0.99098	valid-rmse:1.01080
[460]	train-rmse:0.97399	valid-rmse:1.00241
[700]	train-rmse:0.99283	valid-rmse:1.00546
[60]	train-rmse:1.06821	valid-rmse:1.07619
[40]	train-rmse:1.08709	valid-rmse:1.09313
[980]	train-rmse:1.09945	valid-rmse:1.10438
[300]	train-rmse:0.98847	valid-rmse:1.00914
[480]	train-rmse:0.97265	valid-rmse:1.00203
[720]	train-rmse:0.99211	valid-rmse:1.00499
[740]	train-rmse:0.99142	valid-rmse:1.00455
[320]	train-rmse:0.98621	valid-rmse:1.00782
[80]	train-rmse:1.05959	valid-rmse:1.06863
[500]	train-rmse:0.97129	valid-rmse:1.00171
[60]	train-rmse:1.08145	valid-rmse:1.08801
[999]	train-rmse:1.09945	valid-rmse:1.10437
[760]	train-rmse:0.99081	valid-rmse:1.00415
[32m[I 2022-04-15 03:15:56,563][0m Trial 7 finished with value: 1.104374 and parameters: {'colsample_bytree': 0.7172106769722115, 'eta': 7.069024575453144e-07, 'max_depth': 9, 'n_estimators': 411, 'subsample': 0.8688266351063512}. Best is trial 15 with value: 0.999478.[0m
[03:16:00] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[340]	train-rmse:0.98404	valid-rmse:1.00663
[0]	train-rmse:1.09916	valid-rmse:1.10410
[520]	train-rmse:0.97005	valid-rmse:1.00147
[780]	train-rmse:0.99015	valid-rmse:1.00378
[100]	train-rmse:1.05179	valid-rmse:1.06183
[80]	train-rmse:1.07605	valid-rmse:1.08319
[360]	train-rmse:0.98196	valid-rmse:1.00558
[800]	train-rmse:0.98957	valid-rmse:1.00342
[540]	train-rmse:0.96869	valid-rmse:1.00127
[20]	train-rmse:1.09048	valid-rmse:1.09616
[820]	train-rmse:0.98902	valid-rmse:1.00308
[380]	train-rmse:0.98001	valid-rmse:1.00472
[120]	train-rmse:1.04462	valid-rmse:1.05567
[100]	train-rmse:1.07090	valid-rmse:1.07862
[560]	train-rmse:0.96751	valid-rmse:1.00108
[840]	train-rmse:0.98852	valid-rmse:1.00277
[400]	train-rmse:0.97832	valid-rmse:1.00401
[40]	train-rmse:1.08238	valid-rmse:1.08881
[860]	train-rmse:0.98797	valid-rmse:1.00251
[580]	train-rmse:0.96624	valid-rmse:1.00094
[880]	train-rmse:0.98749	valid-rmse:1.00227
[420]	train-rmse:0.97648	valid-rmse:1.00337
[140]	train-rmse:1.03801	valid-rmse:1.05008
[120]	train-rmse:1.06603	valid-rmse:1.07428
[60]	train-rmse:1.07486	valid-rmse:1.08204
[900]	train-rmse:0.98705	valid-rmse:1.00204
[600]	train-rmse:0.96503	valid-rmse:1.00079
[440]	train-rmse:0.97490	valid-rmse:1.00284
[920]	train-rmse:0.98662	valid-rmse:1.00182
[140]	train-rmse:1.06134	valid-rmse:1.07017
[160]	train-rmse:1.03184	valid-rmse:1.04507
[620]	train-rmse:0.96386	valid-rmse:1.00068
[460]	train-rmse:0.97352	valid-rmse:1.00243
[940]	train-rmse:0.98617	valid-rmse:1.00163
[80]	train-rmse:1.06781	valid-rmse:1.07574
[960]	train-rmse:0.98577	valid-rmse:1.00143
[640]	train-rmse:0.96265	valid-rmse:1.00057
[480]	train-rmse:0.97216	valid-rmse:1.00203
[160]	train-rmse:1.05687	valid-rmse:1.06630
[180]	train-rmse:1.02627	valid-rmse:1.04055
[980]	train-rmse:0.98537	valid-rmse:1.00126
[100]	train-rmse:1.06120	valid-rmse:1.06993
[500]	train-rmse:0.97075	valid-rmse:1.00172
[660]	train-rmse:0.96151	valid-rmse:1.00053
[999]	train-rmse:0.98497	valid-rmse:1.00114
[32m[I 2022-04-15 03:33:37,524][0m Trial 19 finished with value: 1.001138 and parameters: {'colsample_bytree': 0.6464867368220147, 'eta': 0.0021270175264025424, 'max_depth': 7, 'n_estimators': 692, 'subsample': 0.3558969242540247}. Best is trial 15 with value: 0.999478.[0m
[03:33:41] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.00124	valid-rmse:1.00642
[180]	train-rmse:1.05262	valid-rmse:1.06262
[200]	train-rmse:1.02112	valid-rmse:1.03649
[520]	train-rmse:0.96955	valid-rmse:1.00150
[680]	train-rmse:0.96033	valid-rmse:1.00046
[120]	train-rmse:1.05504	valid-rmse:1.06454
[20]	train-rmse:0.97161	valid-rmse:1.02745
[540]	train-rmse:0.96827	valid-rmse:1.00127
[700]	train-rmse:0.95917	valid-rmse:1.00039
[40]	train-rmse:0.94938	valid-rmse:1.05004
[200]	train-rmse:1.04861	valid-rmse:1.05915
[220]	train-rmse:1.01637	valid-rmse:1.03279
[140]	train-rmse:1.04925	valid-rmse:1.05958
[50]	train-rmse:0.93776	valid-rmse:1.05975
[32m[I 2022-04-15 03:39:14,353][0m Trial 24 finished with value: 1.00182 and parameters: {'colsample_bytree': 0.8374009876414555, 'eta': 0.7882762860151962, 'max_depth': 5, 'n_estimators': 377, 'subsample': 0.8453708324574702}. Best is trial 15 with value: 0.999478.[0m
[03:39:18] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[560]	train-rmse:0.96706	valid-rmse:1.00109
[0]	train-rmse:1.09941	valid-rmse:1.10434
[720]	train-rmse:0.95801	valid-rmse:1.00031
[220]	train-rmse:1.04477	valid-rmse:1.05585
[580]	train-rmse:0.96582	valid-rmse:1.00095
[240]	train-rmse:1.01205	valid-rmse:1.02949
[160]	train-rmse:1.04382	valid-rmse:1.05495
[20]	train-rmse:1.09566	valid-rmse:1.10089
[740]	train-rmse:0.95686	valid-rmse:1.00032
[600]	train-rmse:0.96471	valid-rmse:1.00082
[240]	train-rmse:1.04108	valid-rmse:1.05275
[760]	train-rmse:0.95578	valid-rmse:1.00030
[40]	train-rmse:1.09200	valid-rmse:1.09754
[260]	train-rmse:1.00803	valid-rmse:1.02651
[180]	train-rmse:1.03875	valid-rmse:1.05069
[620]	train-rmse:0.96358	valid-rmse:1.00070
[780]	train-rmse:0.95477	valid-rmse:1.00029
[60]	train-rmse:1.08847	valid-rmse:1.09431
[640]	train-rmse:0.96242	valid-rmse:1.00057
[260]	train-rmse:1.03762	valid-rmse:1.04979
[200]	train-rmse:1.03405	valid-rmse:1.04675
[280]	train-rmse:1.00430	valid-rmse:1.02381
[800]	train-rmse:0.95368	valid-rmse:1.00030
[660]	train-rmse:0.96130	valid-rmse:1.00051
[805]	train-rmse:0.95336	valid-rmse:1.00029
[80]	train-rmse:1.08502	valid-rmse:1.09118
[32m[I 2022-04-15 03:50:42,810][0m Trial 18 finished with value: 1.000286 and parameters: {'colsample_bytree': 0.7304450697536347, 'eta': 0.004174847853960499, 'max_depth': 9, 'n_estimators': 979, 'subsample': 0.3631675259092978}. Best is trial 15 with value: 0.999478.[0m
[03:50:47] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09670	valid-rmse:1.10167
[280]	train-rmse:1.03426	valid-rmse:1.04701
[220]	train-rmse:1.02962	valid-rmse:1.04309
[300]	train-rmse:1.00089	valid-rmse:1.02137
[20]	train-rmse:1.05164	valid-rmse:1.05796
[680]	train-rmse:0.96008	valid-rmse:1.00048
[100]	train-rmse:1.08166	valid-rmse:1.08816
[40]	train-rmse:1.02466	valid-rmse:1.03255
[700]	train-rmse:0.95902	valid-rmse:1.00040
[60]	train-rmse:1.00891	valid-rmse:1.01822
[300]	train-rmse:1.03107	valid-rmse:1.04438
[240]	train-rmse:1.02541	valid-rmse:1.03973
[320]	train-rmse:0.99773	valid-rmse:1.01921
[80]	train-rmse:0.99945	valid-rmse:1.01003
[120]	train-rmse:1.07844	valid-rmse:1.08523
[720]	train-rmse:0.95794	valid-rmse:1.00037
[100]	train-rmse:0.99316	valid-rmse:1.00542
[320]	train-rmse:1.02800	valid-rmse:1.04190
[260]	train-rmse:1.02152	valid-rmse:1.03660
[120]	train-rmse:0.98890	valid-rmse:1.00269
[740]	train-rmse:0.95683	valid-rmse:1.00030
[340]	train-rmse:0.99476	valid-rmse:1.01724
[140]	train-rmse:1.07528	valid-rmse:1.08239
[140]	train-rmse:0.98581	valid-rmse:1.00126
[760]	train-rmse:0.95577	valid-rmse:1.00031
[160]	train-rmse:0.98330	valid-rmse:1.00050
[340]	train-rmse:1.02511	valid-rmse:1.03955
[280]	train-rmse:1.01782	valid-rmse:1.03371
[160]	train-rmse:1.07221	valid-rmse:1.07965
[360]	train-rmse:0.99201	valid-rmse:1.01547
[180]	train-rmse:0.98119	valid-rmse:1.00004
[780]	train-rmse:0.95470	valid-rmse:1.00028
[200]	train-rmse:0.97933	valid-rmse:0.99975
[180]	train-rmse:1.06924	valid-rmse:1.07698
[300]	train-rmse:1.01446	valid-rmse:1.03106
[360]	train-rmse:1.02230	valid-rmse:1.03732
[220]	train-rmse:0.97749	valid-rmse:0.99963
[800]	train-rmse:0.95349	valid-rmse:1.00025
[380]	train-rmse:0.98947	valid-rmse:1.01386
[240]	train-rmse:0.97573	valid-rmse:0.99950
[200]	train-rmse:1.06636	valid-rmse:1.07440
[820]	train-rmse:0.95234	valid-rmse:1.00025
[260]	train-rmse:0.97377	valid-rmse:0.99963
[320]	train-rmse:1.01131	valid-rmse:1.02860
[380]	train-rmse:1.01959	valid-rmse:1.03522
[280]	train-rmse:0.97215	valid-rmse:0.99973
[281]	train-rmse:0.97210	valid-rmse:0.99974
[400]	train-rmse:0.98714	valid-rmse:1.01242
[32m[I 2022-04-15 04:09:13,757][0m Trial 26 finished with value: 0.999492 and parameters: {'colsample_bytree': 0.5652094258913339, 'eta': 0.014711326181250286, 'max_depth': 7, 'n_estimators': 553, 'subsample': 0.33456771991035}. Best is trial 15 with value: 0.999478.[0m
[04:09:18] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09162	valid-rmse:1.09696
[840]	train-rmse:0.95119	valid-rmse:1.00024
[220]	train-rmse:1.06355	valid-rmse:1.07191
[340]	train-rmse:1.00830	valid-rmse:1.02633
[20]	train-rmse:1.00657	valid-rmse:1.02109
[400]	train-rmse:1.01708	valid-rmse:1.03323
[860]	train-rmse:0.95003	valid-rmse:1.00025
[420]	train-rmse:0.98493	valid-rmse:1.01112
[240]	train-rmse:1.06084	valid-rmse:1.06949
[40]	train-rmse:0.97964	valid-rmse:1.00527
[360]	train-rmse:1.00549	valid-rmse:1.02425
[880]	train-rmse:0.94900	valid-rmse:1.00026
[420]	train-rmse:1.01461	valid-rmse:1.03135
[888]	train-rmse:0.94864	valid-rmse:1.00029
[60]	train-rmse:0.96751	valid-rmse:1.00266
[32m[I 2022-04-15 04:15:27,433][0m Trial 20 finished with value: 1.000231 and parameters: {'colsample_bytree': 0.6266520026447315, 'eta': 0.004197412740310833, 'max_depth': 9, 'n_estimators': 654, 'subsample': 0.359887859769667}. Best is trial 15 with value: 0.999478.[0m
[04:15:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08819	valid-rmse:1.09348
[440]	train-rmse:0.98288	valid-rmse:1.00996
[260]	train-rmse:1.05820	valid-rmse:1.06715
[80]	train-rmse:0.95805	valid-rmse:1.00240
[380]	train-rmse:1.00279	valid-rmse:1.02232
[20]	train-rmse:0.99701	valid-rmse:1.00930
[440]	train-rmse:1.01225	valid-rmse:1.02958
[280]	train-rmse:1.05561	valid-rmse:1.06488
[460]	train-rmse:0.98096	valid-rmse:1.00893
[40]	train-rmse:0.98130	valid-rmse:1.00072
[100]	train-rmse:0.94718	valid-rmse:1.00280
[400]	train-rmse:1.00025	valid-rmse:1.02054
[60]	train-rmse:0.97343	valid-rmse:1.00011
[120]	train-rmse:0.93711	valid-rmse:1.00349
[300]	train-rmse:1.05315	valid-rmse:1.06269
[460]	train-rmse:1.00998	valid-rmse:1.02789
[480]	train-rmse:0.97920	valid-rmse:1.00799
[80]	train-rmse:0.96630	valid-rmse:1.00047
[132]	train-rmse:0.93077	valid-rmse:1.00367
[32m[I 2022-04-15 04:22:59,896][0m Trial 27 finished with value: 1.002359 and parameters: {'colsample_bytree': 0.581220320105981, 'eta': 0.03969446590858911, 'max_depth': 9, 'n_estimators': 523, 'subsample': 0.3563019607494392}. Best is trial 15 with value: 0.999478.[0m
[04:23:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09946	valid-rmse:1.10437
[420]	train-rmse:0.99792	valid-rmse:1.01890
[320]	train-rmse:1.05076	valid-rmse:1.06059
[100]	train-rmse:0.95963	valid-rmse:1.00065
[20]	train-rmse:1.09659	valid-rmse:1.10160
[480]	train-rmse:1.00786	valid-rmse:1.02634
[107]	train-rmse:0.95688	valid-rmse:1.00081
[32m[I 2022-04-15 04:25:22,189][0m Trial 28 finished with value: 1.000078 and parameters: {'colsample_bytree': 0.5170008772374808, 'eta': 0.05779924439693843, 'max_depth': 7, 'n_estimators': 521, 'subsample': 0.7002189951657986}. Best is trial 15 with value: 0.999478.[0m
[04:25:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09947	valid-rmse:1.10438
[500]	train-rmse:0.97760	valid-rmse:1.00715
[40]	train-rmse:1.09378	valid-rmse:1.09888
[440]	train-rmse:0.99571	valid-rmse:1.01738
[340]	train-rmse:1.04841	valid-rmse:1.05855
[20]	train-rmse:1.09676	valid-rmse:1.10176
[500]	train-rmse:1.00578	valid-rmse:1.02485
[60]	train-rmse:1.09105	valid-rmse:1.09625
[520]	train-rmse:0.97594	valid-rmse:1.00641
[40]	train-rmse:1.09411	valid-rmse:1.09920
[360]	train-rmse:1.04612	valid-rmse:1.05658
[460]	train-rmse:0.99355	valid-rmse:1.01598
[80]	train-rmse:1.08838	valid-rmse:1.09368
[60]	train-rmse:1.09153	valid-rmse:1.09670
[520]	train-rmse:1.00381	valid-rmse:1.02345
[540]	train-rmse:0.97452	valid-rmse:1.00574
[100]	train-rmse:1.08579	valid-rmse:1.09119
[80]	train-rmse:1.08902	valid-rmse:1.09427
[380]	train-rmse:1.04390	valid-rmse:1.05466
[480]	train-rmse:0.99160	valid-rmse:1.01470
[100]	train-rmse:1.08655	valid-rmse:1.09189
[120]	train-rmse:1.08325	valid-rmse:1.08874
[540]	train-rmse:1.00197	valid-rmse:1.02212
[560]	train-rmse:0.97313	valid-rmse:1.00511
[400]	train-rmse:1.04173	valid-rmse:1.05282
[120]	train-rmse:1.08415	valid-rmse:1.08957
[140]	train-rmse:1.08078	valid-rmse:1.08637
[500]	train-rmse:0.98968	valid-rmse:1.01352
[140]	train-rmse:1.08179	valid-rmse:1.08731
[160]	train-rmse:1.07837	valid-rmse:1.08405
[420]	train-rmse:1.03964	valid-rmse:1.05101
[560]	train-rmse:1.00012	valid-rmse:1.02086
[580]	train-rmse:0.97183	valid-rmse:1.00454
[160]	train-rmse:1.07950	valid-rmse:1.08510
[180]	train-rmse:1.07600	valid-rmse:1.08179
[520]	train-rmse:0.98798	valid-rmse:1.01245
[440]	train-rmse:1.03761	valid-rmse:1.04928
[180]	train-rmse:1.07726	valid-rmse:1.08294
[200]	train-rmse:1.07372	valid-rmse:1.07959
[580]	train-rmse:0.99838	valid-rmse:1.01966
[600]	train-rmse:0.97061	valid-rmse:1.00403
[200]	train-rmse:1.07507	valid-rmse:1.08085
[540]	train-rmse:0.98629	valid-rmse:1.01146
[220]	train-rmse:1.07148	valid-rmse:1.07745
[460]	train-rmse:1.03564	valid-rmse:1.04760
[220]	train-rmse:1.07294	valid-rmse:1.07878
[600]	train-rmse:0.99671	valid-rmse:1.01852
[620]	train-rmse:0.96956	valid-rmse:1.00358
[240]	train-rmse:1.06930	valid-rmse:1.07537
[560]	train-rmse:0.98477	valid-rmse:1.01052
[240]	train-rmse:1.07085	valid-rmse:1.07678
[480]	train-rmse:1.03373	valid-rmse:1.04598
[260]	train-rmse:1.06717	valid-rmse:1.07334
[260]	train-rmse:1.06881	valid-rmse:1.07482
[640]	train-rmse:0.96850	valid-rmse:1.00316
[620]	train-rmse:0.99514	valid-rmse:1.01745
[280]	train-rmse:1.06509	valid-rmse:1.07136
[580]	train-rmse:0.98320	valid-rmse:1.00965
[500]	train-rmse:1.03184	valid-rmse:1.04442
[280]	train-rmse:1.06683	valid-rmse:1.07292
[300]	train-rmse:1.06306	valid-rmse:1.06943
[300]	train-rmse:1.06488	valid-rmse:1.07106
[660]	train-rmse:0.96742	valid-rmse:1.00280
[640]	train-rmse:0.99360	valid-rmse:1.01646
[520]	train-rmse:1.03004	valid-rmse:1.04292
[320]	train-rmse:1.06110	valid-rmse:1.06756
[600]	train-rmse:0.98175	valid-rmse:1.00885
[320]	train-rmse:1.06299	valid-rmse:1.06925
[340]	train-rmse:1.05918	valid-rmse:1.06573
[540]	train-rmse:1.02832	valid-rmse:1.04146
[680]	train-rmse:0.96634	valid-rmse:1.00247
[660]	train-rmse:0.99216	valid-rmse:1.01551
[340]	train-rmse:1.06114	valid-rmse:1.06748
[620]	train-rmse:0.98042	valid-rmse:1.00812
[360]	train-rmse:1.05730	valid-rmse:1.06395
[360]	train-rmse:1.05934	valid-rmse:1.06576
[560]	train-rmse:1.02660	valid-rmse:1.04004
[380]	train-rmse:1.05547	valid-rmse:1.06221
[700]	train-rmse:0.96546	valid-rmse:1.00216
[680]	train-rmse:0.99079	valid-rmse:1.01462
[380]	train-rmse:1.05756	valid-rmse:1.06407
[640]	train-rmse:0.97925	valid-rmse:1.00745
[400]	train-rmse:1.05368	valid-rmse:1.06052
[400]	train-rmse:1.05585	valid-rmse:1.06245
[580]	train-rmse:1.02492	valid-rmse:1.03868
[720]	train-rmse:0.96437	valid-rmse:1.00188
[420]	train-rmse:1.05194	valid-rmse:1.05887
[700]	train-rmse:0.98942	valid-rmse:1.01376
[660]	train-rmse:0.97795	valid-rmse:1.00682
[420]	train-rmse:1.05417	valid-rmse:1.06084
[600]	train-rmse:1.02329	valid-rmse:1.03735
[440]	train-rmse:1.05024	valid-rmse:1.05726
[440]	train-rmse:1.05253	valid-rmse:1.05929
[740]	train-rmse:0.96353	valid-rmse:1.00163
[720]	train-rmse:0.98815	valid-rmse:1.01297
[680]	train-rmse:0.97667	valid-rmse:1.00626
[460]	train-rmse:1.04859	valid-rmse:1.05570
[460]	train-rmse:1.05093	valid-rmse:1.05777
[620]	train-rmse:1.02172	valid-rmse:1.03608
[480]	train-rmse:1.04698	valid-rmse:1.05418
[480]	train-rmse:1.04937	valid-rmse:1.05628
[760]	train-rmse:0.96261	valid-rmse:1.00142
[740]	train-rmse:0.98694	valid-rmse:1.01223
[700]	train-rmse:0.97548	valid-rmse:1.00575
[640]	train-rmse:1.02019	valid-rmse:1.03484
[500]	train-rmse:1.04540	valid-rmse:1.05270
[500]	train-rmse:1.04784	valid-rmse:1.05483
[520]	train-rmse:1.04387	valid-rmse:1.05127
[520]	train-rmse:1.04635	valid-rmse:1.05342
[780]	train-rmse:0.96170	valid-rmse:1.00121
[660]	train-rmse:1.01871	valid-rmse:1.03364
[760]	train-rmse:0.98576	valid-rmse:1.01153
[720]	train-rmse:0.97437	valid-rmse:1.00524
[540]	train-rmse:1.04238	valid-rmse:1.04987
[540]	train-rmse:1.04490	valid-rmse:1.05204
[680]	train-rmse:1.01725	valid-rmse:1.03249
[800]	train-rmse:0.96080	valid-rmse:1.00104
[560]	train-rmse:1.04349	valid-rmse:1.05070
[560]	train-rmse:1.04092	valid-rmse:1.04850
[740]	train-rmse:0.97340	valid-rmse:1.00480
[780]	train-rmse:0.98456	valid-rmse:1.01085
[580]	train-rmse:1.04211	valid-rmse:1.04939
[580]	train-rmse:1.03950	valid-rmse:1.04718
[700]	train-rmse:1.01584	valid-rmse:1.03137
[760]	train-rmse:0.97244	valid-rmse:1.00439
[820]	train-rmse:0.95988	valid-rmse:1.00088
[600]	train-rmse:1.04075	valid-rmse:1.04810
[800]	train-rmse:0.98342	valid-rmse:1.01022
[600]	train-rmse:1.03811	valid-rmse:1.04588
[720]	train-rmse:1.01446	valid-rmse:1.03030
[620]	train-rmse:1.03943	valid-rmse:1.04685
[620]	train-rmse:1.03676	valid-rmse:1.04462
[780]	train-rmse:0.97138	valid-rmse:1.00399
[840]	train-rmse:0.95912	valid-rmse:1.00074
[820]	train-rmse:0.98237	valid-rmse:1.00964
[640]	train-rmse:1.03815	valid-rmse:1.04564
[640]	train-rmse:1.03543	valid-rmse:1.04340
[740]	train-rmse:1.01313	valid-rmse:1.02925
[660]	train-rmse:1.03690	valid-rmse:1.04446
[660]	train-rmse:1.03414	valid-rmse:1.04220
[800]	train-rmse:0.97040	valid-rmse:1.00363
[860]	train-rmse:0.95817	valid-rmse:1.00061
[840]	train-rmse:0.98137	valid-rmse:1.00906
[680]	train-rmse:1.03567	valid-rmse:1.04331
[760]	train-rmse:1.01183	valid-rmse:1.02825
[680]	train-rmse:1.03288	valid-rmse:1.04105
[700]	train-rmse:1.03446	valid-rmse:1.04220
[820]	train-rmse:0.96949	valid-rmse:1.00329
[700]	train-rmse:1.03166	valid-rmse:1.03992
[880]	train-rmse:0.95727	valid-rmse:1.00050
[780]	train-rmse:1.01053	valid-rmse:1.02728
[860]	train-rmse:0.98040	valid-rmse:1.00853
[720]	train-rmse:1.03329	valid-rmse:1.04110
[720]	train-rmse:1.03047	valid-rmse:1.03883
[840]	train-rmse:0.96854	valid-rmse:1.00300
[740]	train-rmse:1.03216	valid-rmse:1.04003
[800]	train-rmse:1.00928	valid-rmse:1.02635
[900]	train-rmse:0.95652	valid-rmse:1.00040
[740]	train-rmse:1.02931	valid-rmse:1.03776
[880]	train-rmse:0.97940	valid-rmse:1.00803
[760]	train-rmse:1.03103	valid-rmse:1.03899
[760]	train-rmse:1.02817	valid-rmse:1.03672
[820]	train-rmse:1.00807	valid-rmse:1.02544
[860]	train-rmse:0.96767	valid-rmse:1.00272
[780]	train-rmse:1.02994	valid-rmse:1.03798
[920]	train-rmse:0.95573	valid-rmse:1.00032
[900]	train-rmse:0.97844	valid-rmse:1.00756
[780]	train-rmse:1.02706	valid-rmse:1.03570
[800]	train-rmse:1.02887	valid-rmse:1.03700
[840]	train-rmse:1.00690	valid-rmse:1.02457
[880]	train-rmse:0.96681	valid-rmse:1.00246
[800]	train-rmse:1.02597	valid-rmse:1.03471
[820]	train-rmse:1.02782	valid-rmse:1.03603
[940]	train-rmse:0.95495	valid-rmse:1.00023
[920]	train-rmse:0.97759	valid-rmse:1.00710
[820]	train-rmse:1.02491	valid-rmse:1.03375
[860]	train-rmse:1.00576	valid-rmse:1.02372
[840]	train-rmse:1.02681	valid-rmse:1.03508
[900]	train-rmse:0.96608	valid-rmse:1.00222
[840]	train-rmse:1.02388	valid-rmse:1.03282
[960]	train-rmse:0.95417	valid-rmse:1.00015
[860]	train-rmse:1.02581	valid-rmse:1.03417
[940]	train-rmse:0.97672	valid-rmse:1.00668
[880]	train-rmse:1.00463	valid-rmse:1.02290
[860]	train-rmse:1.02287	valid-rmse:1.03191
[880]	train-rmse:1.02484	valid-rmse:1.03328
[920]	train-rmse:0.96527	valid-rmse:1.00200
[880]	train-rmse:1.02188	valid-rmse:1.03102
[980]	train-rmse:0.95339	valid-rmse:1.00008
[900]	train-rmse:1.02391	valid-rmse:1.03240
[900]	train-rmse:1.00356	valid-rmse:1.02212
[960]	train-rmse:0.97582	valid-rmse:1.00629
[900]	train-rmse:1.02093	valid-rmse:1.03016
[940]	train-rmse:0.96445	valid-rmse:1.00180
[920]	train-rmse:1.02298	valid-rmse:1.03155
[999]	train-rmse:0.95269	valid-rmse:1.00003
[920]	train-rmse:1.00251	valid-rmse:1.02135
[32m[I 2022-04-15 05:48:31,256][0m Trial 21 finished with value: 1.000034 and parameters: {'colsample_bytree': 0.6234740940796359, 'eta': 0.00274542141193771, 'max_depth': 9, 'n_estimators': 417, 'subsample': 0.92331105640835}. Best is trial 15 with value: 0.999478.[0m
[920]	train-rmse:1.01999	valid-rmse:1.02932
[05:48:35] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[980]	train-rmse:0.97501	valid-rmse:1.00591
[0]	train-rmse:1.09952	valid-rmse:1.10443
[940]	train-rmse:1.02208	valid-rmse:1.03072
[960]	train-rmse:0.96358	valid-rmse:1.00162
[940]	train-rmse:1.01907	valid-rmse:1.02850
[960]	train-rmse:1.02119	valid-rmse:1.02992
[20]	train-rmse:1.09786	valid-rmse:1.10282
[940]	train-rmse:1.00149	valid-rmse:1.02060
[999]	train-rmse:0.97433	valid-rmse:1.00557
[32m[I 2022-04-15 05:52:02,730][0m Trial 22 finished with value: 1.005572 and parameters: {'colsample_bytree': 0.619645900321685, 'eta': 0.0014966043150283384, 'max_depth': 9, 'n_estimators': 366, 'subsample': 0.8930232324569021}. Best is trial 15 with value: 0.999478.[0m
[05:52:07] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[960]	train-rmse:1.01818	valid-rmse:1.02771
[0]	train-rmse:1.09952	valid-rmse:1.10443
[980]	train-rmse:1.02033	valid-rmse:1.02914
[40]	train-rmse:1.09622	valid-rmse:1.10123
[980]	train-rmse:0.96283	valid-rmse:1.00145
[20]	train-rmse:1.09784	valid-rmse:1.10281
[960]	train-rmse:1.00047	valid-rmse:1.01988
[999]	train-rmse:1.01953	valid-rmse:1.02841
[980]	train-rmse:1.01730	valid-rmse:1.02694
[32m[I 2022-04-15 05:54:04,935][0m Trial 30 finished with value: 1.028414 and parameters: {'colsample_bytree': 0.6683160762661686, 'eta': 0.0006775545094420505, 'max_depth': 7, 'n_estimators': 303, 'subsample': 0.4520571664540545}. Best is trial 15 with value: 0.999478.[0m
[05:54:09] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.06265	valid-rmse:1.06776
[40]	train-rmse:1.09619	valid-rmse:1.10120
[60]	train-rmse:1.09461	valid-rmse:1.09967
[999]	train-rmse:1.01651	valid-rmse:1.02622
[32m[I 2022-04-15 05:55:51,302][0m Trial 29 finished with value: 1.026224 and parameters: {'colsample_bytree': 0.5373216578225679, 'eta': 0.0007167836867297866, 'max_depth': 7, 'n_estimators': 303, 'subsample': 0.6974853933295484}. Best is trial 15 with value: 0.999478.[0m
[05:55:55] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09956	valid-rmse:1.10447
[60]	train-rmse:1.09457	valid-rmse:1.09962
[20]	train-rmse:0.98581	valid-rmse:1.00140
[999]	train-rmse:0.96227	valid-rmse:1.00130
[980]	train-rmse:0.99949	valid-rmse:1.01918
[32m[I 2022-04-15 05:56:30,362][0m Trial 23 finished with value: 1.001298 and parameters: {'colsample_bytree': 0.6448644594115787, 'eta': 0.0021076813207415337, 'max_depth': 9, 'n_estimators': 342, 'subsample': 0.8154280337609541}. Best is trial 15 with value: 0.999478.[0m
[05:56:34] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09956	valid-rmse:1.10447
[80]	train-rmse:1.09303	valid-rmse:1.09814
[20]	train-rmse:1.09869	valid-rmse:1.10360
[80]	train-rmse:1.09297	valid-rmse:1.09807
[40]	train-rmse:0.97710	valid-rmse:1.00378
[20]	train-rmse:1.09871	valid-rmse:1.10362
[40]	train-rmse:1.09782	valid-rmse:1.10274
[100]	train-rmse:1.09139	valid-rmse:1.09654
[100]	train-rmse:1.09146	valid-rmse:1.09663
[999]	train-rmse:0.99859	valid-rmse:1.01855
[40]	train-rmse:1.09786	valid-rmse:1.10277
[32m[I 2022-04-15 05:59:21,089][0m Trial 25 finished with value: 1.018552 and parameters: {'colsample_bytree': 0.5895291132617325, 'eta': 0.0008976312534943112, 'max_depth': 9, 'n_estimators': 552, 'subsample': 0.6841271015595596}. Best is trial 15 with value: 0.999478.[0m
[60]	train-rmse:1.09696	valid-rmse:1.10188
[05:59:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.06662	valid-rmse:1.07191
[60]	train-rmse:0.96828	valid-rmse:1.00527
[120]	train-rmse:1.08983	valid-rmse:1.09502
[63]	train-rmse:0.96694	valid-rmse:1.00553
[20]	train-rmse:0.99092	valid-rmse:1.00457
[32m[I 2022-04-15 06:00:09,210][0m Trial 33 finished with value: 1.00072 and parameters: {'colsample_bytree': 0.7994283434264277, 'eta': 0.20729025207093363, 'max_depth': 5, 'n_estimators': 281, 'subsample': 0.7938264595516275}. Best is trial 15 with value: 0.999478.[0m
[06:00:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09741	valid-rmse:1.10236
[80]	train-rmse:1.09611	valid-rmse:1.10103
[60]	train-rmse:1.09702	valid-rmse:1.10193
[40]	train-rmse:0.98417	valid-rmse:1.00818
[120]	train-rmse:1.08992	valid-rmse:1.09513
[140]	train-rmse:1.08829	valid-rmse:1.09353
[20]	train-rmse:1.06110	valid-rmse:1.06676
[60]	train-rmse:0.97775	valid-rmse:1.01223
[62]	train-rmse:0.97730	valid-rmse:1.01262
[32m[I 2022-04-15 06:01:35,101][0m Trial 36 finished with value: 1.003748 and parameters: {'colsample_bytree': 0.40877159565495447, 'eta': 0.1845834058249249, 'max_depth': 5, 'n_estimators': 619, 'subsample': 0.2811394174641439}. Best is trial 15 with value: 0.999478.[0m
[100]	train-rmse:1.09526	valid-rmse:1.10019
[06:01:39] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09700	valid-rmse:1.10199
[80]	train-rmse:1.09619	valid-rmse:1.10110
[160]	train-rmse:1.08678	valid-rmse:1.09206
[40]	train-rmse:1.03657	valid-rmse:1.04340
[120]	train-rmse:1.09443	valid-rmse:1.09935
[140]	train-rmse:1.08839	valid-rmse:1.09367
[100]	train-rmse:1.09537	valid-rmse:1.10028
[60]	train-rmse:1.02045	valid-rmse:1.02810
[20]	train-rmse:1.05534	valid-rmse:1.06207
[180]	train-rmse:1.08530	valid-rmse:1.09061
[140]	train-rmse:1.09359	valid-rmse:1.09852
[120]	train-rmse:1.09455	valid-rmse:1.09946
[80]	train-rmse:1.00948	valid-rmse:1.01834
[200]	train-rmse:1.08383	valid-rmse:1.08919
[160]	train-rmse:1.09277	valid-rmse:1.09770
[160]	train-rmse:1.08689	valid-rmse:1.09221
[100]	train-rmse:1.00181	valid-rmse:1.01181
[140]	train-rmse:1.09373	valid-rmse:1.09865
[40]	train-rmse:1.02894	valid-rmse:1.03753
[180]	train-rmse:1.09195	valid-rmse:1.09688
[220]	train-rmse:1.08238	valid-rmse:1.08778
[120]	train-rmse:0.99638	valid-rmse:1.00746
[160]	train-rmse:1.09293	valid-rmse:1.09784
[180]	train-rmse:1.08541	valid-rmse:1.09078
[200]	train-rmse:1.09114	valid-rmse:1.09607
[60]	train-rmse:1.01195	valid-rmse:1.02253
[240]	train-rmse:1.08095	valid-rmse:1.08641
[140]	train-rmse:0.99255	valid-rmse:1.00457
[180]	train-rmse:1.09213	valid-rmse:1.09704
[220]	train-rmse:1.09033	valid-rmse:1.09527
[160]	train-rmse:0.98973	valid-rmse:1.00278
[260]	train-rmse:1.07955	valid-rmse:1.08505
[200]	train-rmse:1.08395	valid-rmse:1.08938
[80]	train-rmse:1.00093	valid-rmse:1.01344
[200]	train-rmse:1.09133	valid-rmse:1.09624
[240]	train-rmse:1.08953	valid-rmse:1.09447
[180]	train-rmse:0.98746	valid-rmse:1.00164
[280]	train-rmse:1.07816	valid-rmse:1.08371
[220]	train-rmse:1.09054	valid-rmse:1.09545
[260]	train-rmse:1.08874	valid-rmse:1.09368
[200]	train-rmse:0.98548	valid-rmse:1.00097
[100]	train-rmse:0.99365	valid-rmse:1.00794
[220]	train-rmse:1.08251	valid-rmse:1.08798
[300]	train-rmse:1.07679	valid-rmse:1.08239
[220]	train-rmse:0.98376	valid-rmse:1.00052
[280]	train-rmse:1.08796	valid-rmse:1.09290
[240]	train-rmse:1.08976	valid-rmse:1.09467
[320]	train-rmse:1.07545	valid-rmse:1.08110
[240]	train-rmse:0.98220	valid-rmse:1.00016
[300]	train-rmse:1.08717	valid-rmse:1.09212
[120]	train-rmse:0.98901	valid-rmse:1.00455
[260]	train-rmse:1.08899	valid-rmse:1.09390
[240]	train-rmse:1.08110	valid-rmse:1.08662
[260]	train-rmse:0.98073	valid-rmse:1.00004
[340]	train-rmse:1.07413	valid-rmse:1.07983
[320]	train-rmse:1.08640	valid-rmse:1.09135
[280]	train-rmse:1.08822	valid-rmse:1.09313
[280]	train-rmse:0.97941	valid-rmse:0.99991
[140]	train-rmse:0.98562	valid-rmse:1.00249
[340]	train-rmse:1.08563	valid-rmse:1.09058
[360]	train-rmse:1.07282	valid-rmse:1.07856
[260]	train-rmse:1.07970	valid-rmse:1.08528
[300]	train-rmse:1.08745	valid-rmse:1.09236
[300]	train-rmse:0.97819	valid-rmse:0.99983
[360]	train-rmse:1.08487	valid-rmse:1.08982
[380]	train-rmse:1.07153	valid-rmse:1.07732
[160]	train-rmse:0.98291	valid-rmse:1.00121
[320]	train-rmse:0.97696	valid-rmse:0.99979
[320]	train-rmse:1.08669	valid-rmse:1.09161
[280]	train-rmse:1.07833	valid-rmse:1.08396
[380]	train-rmse:1.08411	valid-rmse:1.08907
[400]	train-rmse:1.07027	valid-rmse:1.07611
[340]	train-rmse:0.97596	valid-rmse:0.99987
[340]	train-rmse:1.08594	valid-rmse:1.09085
[400]	train-rmse:1.08336	valid-rmse:1.08832
[180]	train-rmse:0.98081	valid-rmse:1.00044
[360]	train-rmse:0.97464	valid-rmse:0.99997
[32m[I 2022-04-15 06:19:16,710][0m Trial 37 finished with value: 0.999743 and parameters: {'colsample_bytree': 0.4399302785834396, 'eta': 0.011171939395071752, 'max_depth': 7, 'n_estimators': 921, 'subsample': 0.2874149060193534}. Best is trial 15 with value: 0.999478.[0m
[06:19:21] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[420]	train-rmse:1.06902	valid-rmse:1.07490
[0]	train-rmse:1.09579	valid-rmse:1.10086
[300]	train-rmse:1.07697	valid-rmse:1.08265
[360]	train-rmse:1.08520	valid-rmse:1.09011
[420]	train-rmse:1.08262	valid-rmse:1.08758
[440]	train-rmse:1.06779	valid-rmse:1.07372
[200]	train-rmse:0.97880	valid-rmse:0.99998
[440]	train-rmse:1.08188	valid-rmse:1.08684
[380]	train-rmse:1.08445	valid-rmse:1.08937
[20]	train-rmse:1.04108	valid-rmse:1.04875
[320]	train-rmse:1.07564	valid-rmse:1.08136
[460]	train-rmse:1.06658	valid-rmse:1.07256
[460]	train-rmse:1.08115	valid-rmse:1.08611
[400]	train-rmse:1.08372	valid-rmse:1.08863
[220]	train-rmse:0.97715	valid-rmse:0.99975
[480]	train-rmse:1.06539	valid-rmse:1.07140
[40]	train-rmse:1.01291	valid-rmse:1.02315
[480]	train-rmse:1.08043	valid-rmse:1.08539
[420]	train-rmse:1.08299	valid-rmse:1.08791
[340]	train-rmse:1.07432	valid-rmse:1.08010
[500]	train-rmse:1.06421	valid-rmse:1.07028
[500]	train-rmse:1.07971	valid-rmse:1.08467
[240]	train-rmse:0.97574	valid-rmse:0.99961
[440]	train-rmse:1.08227	valid-rmse:1.08719
[60]	train-rmse:0.99786	valid-rmse:1.01092
[520]	train-rmse:1.07899	valid-rmse:1.08396
[520]	train-rmse:1.06305	valid-rmse:1.06916
[360]	train-rmse:1.07303	valid-rmse:1.07886
[460]	train-rmse:1.08155	valid-rmse:1.08647
[260]	train-rmse:0.97420	valid-rmse:0.99948
[540]	train-rmse:1.07828	valid-rmse:1.08326
[80]	train-rmse:0.98933	valid-rmse:1.00496
[540]	train-rmse:1.06191	valid-rmse:1.06807
[480]	train-rmse:1.08084	valid-rmse:1.08576
[560]	train-rmse:1.07758	valid-rmse:1.08256
[380]	train-rmse:1.07174	valid-rmse:1.07763
[560]	train-rmse:1.06079	valid-rmse:1.06699
[280]	train-rmse:0.97270	valid-rmse:0.99945
[500]	train-rmse:1.08013	valid-rmse:1.08506
[100]	train-rmse:0.98440	valid-rmse:1.00208
[580]	train-rmse:1.07688	valid-rmse:1.08186
[580]	train-rmse:1.05968	valid-rmse:1.06594
[400]	train-rmse:1.07049	valid-rmse:1.07642
[600]	train-rmse:1.07619	valid-rmse:1.08117
[520]	train-rmse:1.07943	valid-rmse:1.08435
[300]	train-rmse:0.97141	valid-rmse:0.99942
[120]	train-rmse:0.98072	valid-rmse:1.00073
[600]	train-rmse:1.05859	valid-rmse:1.06489
[620]	train-rmse:1.07550	valid-rmse:1.08048
[540]	train-rmse:1.07874	valid-rmse:1.08366
[420]	train-rmse:1.06924	valid-rmse:1.07522
[320]	train-rmse:0.97000	valid-rmse:0.99940
[620]	train-rmse:1.05751	valid-rmse:1.06386
[640]	train-rmse:1.07482	valid-rmse:1.07981
[140]	train-rmse:0.97820	valid-rmse:1.00009
[560]	train-rmse:1.07805	valid-rmse:1.08297
[660]	train-rmse:1.07415	valid-rmse:1.07914
[640]	train-rmse:1.05646	valid-rmse:1.06285
[580]	train-rmse:1.07736	valid-rmse:1.08228
[340]	train-rmse:0.96867	valid-rmse:0.99944
[440]	train-rmse:1.06803	valid-rmse:1.07405
[160]	train-rmse:0.97575	valid-rmse:0.99982
[680]	train-rmse:1.07348	valid-rmse:1.07847
[660]	train-rmse:1.05541	valid-rmse:1.06186
[600]	train-rmse:1.07668	valid-rmse:1.08161
[700]	train-rmse:1.07281	valid-rmse:1.07781
[360]	train-rmse:0.96742	valid-rmse:0.99945
[680]	train-rmse:1.05439	valid-rmse:1.06088
[460]	train-rmse:1.06682	valid-rmse:1.07289
[180]	train-rmse:0.97357	valid-rmse:0.99968
[362]	train-rmse:0.96730	valid-rmse:0.99946
[32m[I 2022-04-15 06:36:43,687][0m Trial 38 finished with value: 0.999384 and parameters: {'colsample_bytree': 0.4479772798233485, 'eta': 0.0129360174993181, 'max_depth': 7, 'n_estimators': 471, 'subsample': 0.9889594018734298}. Best is trial 38 with value: 0.999384.[0m
[620]	train-rmse:1.07601	valid-rmse:1.08093
[06:36:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09954	valid-rmse:1.10446
[720]	train-rmse:1.07215	valid-rmse:1.07715
[700]	train-rmse:1.05337	valid-rmse:1.05991
[640]	train-rmse:1.07534	valid-rmse:1.08027
[740]	train-rmse:1.07150	valid-rmse:1.07650
[200]	train-rmse:0.97168	valid-rmse:0.99960
[480]	train-rmse:1.06563	valid-rmse:1.07175
[20]	train-rmse:1.09837	valid-rmse:1.10332
[720]	train-rmse:1.05238	valid-rmse:1.05895
[660]	train-rmse:1.07468	valid-rmse:1.07960
[760]	train-rmse:1.07085	valid-rmse:1.07585
[740]	train-rmse:1.05140	valid-rmse:1.05801
[220]	train-rmse:0.96958	valid-rmse:0.99955
[780]	train-rmse:1.07021	valid-rmse:1.07521
[680]	train-rmse:1.07402	valid-rmse:1.07895
[500]	train-rmse:1.06446	valid-rmse:1.07063
[40]	train-rmse:1.09720	valid-rmse:1.10219
[760]	train-rmse:1.05043	valid-rmse:1.05709
[800]	train-rmse:1.06957	valid-rmse:1.07458
[700]	train-rmse:1.07337	valid-rmse:1.07830
[240]	train-rmse:0.96731	valid-rmse:0.99959
[60]	train-rmse:1.09605	valid-rmse:1.10108
[820]	train-rmse:1.06894	valid-rmse:1.07395
[780]	train-rmse:1.04947	valid-rmse:1.05618
[520]	train-rmse:1.06330	valid-rmse:1.06953
[720]	train-rmse:1.07272	valid-rmse:1.07765
[840]	train-rmse:1.06831	valid-rmse:1.07333
[800]	train-rmse:1.04853	valid-rmse:1.05529
[260]	train-rmse:0.96515	valid-rmse:0.99960
[740]	train-rmse:1.07208	valid-rmse:1.07701
[80]	train-rmse:1.09491	valid-rmse:1.09997
[540]	train-rmse:1.06216	valid-rmse:1.06844
[860]	train-rmse:1.06769	valid-rmse:1.07271
[820]	train-rmse:1.04760	valid-rmse:1.05441
[272]	train-rmse:0.96374	valid-rmse:0.99967
[32m[I 2022-04-15 06:45:36,986][0m Trial 39 finished with value: 0.999535 and parameters: {'colsample_bytree': 0.4576230032463514, 'eta': 0.01887027672373262, 'max_depth': 7, 'n_estimators': 922, 'subsample': 0.9645432549460224}. Best is trial 38 with value: 0.999384.[0m
[06:45:41] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09958	valid-rmse:1.10449
[760]	train-rmse:1.07144	valid-rmse:1.07637
[880]	train-rmse:1.06707	valid-rmse:1.07209
[100]	train-rmse:1.09379	valid-rmse:1.09888
[840]	train-rmse:1.04668	valid-rmse:1.05354
[560]	train-rmse:1.06105	valid-rmse:1.06737
[780]	train-rmse:1.07081	valid-rmse:1.07574
[900]	train-rmse:1.06646	valid-rmse:1.07148
[20]	train-rmse:1.09911	valid-rmse:1.10404
[860]	train-rmse:1.04578	valid-rmse:1.05269
[120]	train-rmse:1.09267	valid-rmse:1.09780
[800]	train-rmse:1.07018	valid-rmse:1.07512
[920]	train-rmse:1.06585	valid-rmse:1.07088
[580]	train-rmse:1.05994	valid-rmse:1.06632
[880]	train-rmse:1.04490	valid-rmse:1.05184
[940]	train-rmse:1.06525	valid-rmse:1.07028
[820]	train-rmse:1.06956	valid-rmse:1.07450
[40]	train-rmse:1.09865	valid-rmse:1.10359
[140]	train-rmse:1.09156	valid-rmse:1.09673
[900]	train-rmse:1.04403	valid-rmse:1.05102
[960]	train-rmse:1.06465	valid-rmse:1.06968
[840]	train-rmse:1.06894	valid-rmse:1.07388
[600]	train-rmse:1.05885	valid-rmse:1.06527
[60]	train-rmse:1.09819	valid-rmse:1.10315
[980]	train-rmse:1.06405	valid-rmse:1.06909
[920]	train-rmse:1.04316	valid-rmse:1.05020
[160]	train-rmse:1.09046	valid-rmse:1.09567
[860]	train-rmse:1.06832	valid-rmse:1.07327
[999]	train-rmse:1.06350	valid-rmse:1.06853
[32m[I 2022-04-15 06:53:08,330][0m Trial 34 finished with value: 1.068533 and parameters: {'colsample_bytree': 0.4555479152714706, 'eta': 0.0002219020223421569, 'max_depth': 5, 'n_estimators': 590, 'subsample': 0.7612383511814629}. Best is trial 38 with value: 0.999384.[0m
[06:53:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[620]	train-rmse:1.05778	valid-rmse:1.06424
[940]	train-rmse:1.04232	valid-rmse:1.04939
[0]	train-rmse:1.09579	valid-rmse:1.10085
[880]	train-rmse:1.06772	valid-rmse:1.07266
[80]	train-rmse:1.09773	valid-rmse:1.10271
[180]	train-rmse:1.08938	valid-rmse:1.09462
[960]	train-rmse:1.04148	valid-rmse:1.04859
[900]	train-rmse:1.06711	valid-rmse:1.07206
[640]	train-rmse:1.05672	valid-rmse:1.06324
[20]	train-rmse:1.04080	valid-rmse:1.04862
[100]	train-rmse:1.09728	valid-rmse:1.10226
[980]	train-rmse:1.04066	valid-rmse:1.04782
[200]	train-rmse:1.08830	valid-rmse:1.09359
[920]	train-rmse:1.06651	valid-rmse:1.07147
[999]	train-rmse:1.03988	valid-rmse:1.04709
[32m[I 2022-04-15 06:57:12,111][0m Trial 32 finished with value: 1.047089 and parameters: {'colsample_bytree': 0.4345681500584294, 'eta': 0.0004185037889580184, 'max_depth': 7, 'n_estimators': 294, 'subsample': 0.43917412586066124}. Best is trial 38 with value: 0.999384.[0m
[06:57:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[40]	train-rmse:1.01259	valid-rmse:1.02302
[0]	train-rmse:1.07436	valid-rmse:1.08010
[660]	train-rmse:1.05568	valid-rmse:1.06225
[940]	train-rmse:1.06592	valid-rmse:1.07087
[120]	train-rmse:1.09682	valid-rmse:1.10183
[220]	train-rmse:1.08724	valid-rmse:1.09256
[960]	train-rmse:1.06533	valid-rmse:1.07029
[20]	train-rmse:0.97874	valid-rmse:1.00096
[60]	train-rmse:0.99743	valid-rmse:1.01085
[680]	train-rmse:1.05466	valid-rmse:1.06127
[140]	train-rmse:1.09637	valid-rmse:1.10139
[240]	train-rmse:1.08619	valid-rmse:1.09154
[980]	train-rmse:1.06475	valid-rmse:1.06971
[40]	train-rmse:0.96380	valid-rmse:1.00236
[80]	train-rmse:0.98929	valid-rmse:1.00500
[999]	train-rmse:1.06419	valid-rmse:1.06916
[32m[I 2022-04-15 07:01:20,891][0m Trial 35 finished with value: 1.069157 and parameters: {'colsample_bytree': 0.45459892057330914, 'eta': 0.0002165240885205903, 'max_depth': 5, 'n_estimators': 223, 'subsample': 0.964308077406697}. Best is trial 38 with value: 0.999384.[0m
[07:01:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[700]	train-rmse:1.05364	valid-rmse:1.06031
[0]	train-rmse:1.09625	valid-rmse:1.10125
[60]	train-rmse:0.95078	valid-rmse:1.00424
[260]	train-rmse:1.08515	valid-rmse:1.09054
[160]	train-rmse:1.09592	valid-rmse:1.10095
[69]	train-rmse:0.94474	valid-rmse:1.00457
[32m[I 2022-04-15 07:02:27,455][0m Trial 43 finished with value: 1.000955 and parameters: {'colsample_bytree': 0.2828218790314996, 'eta': 0.1313141391377144, 'max_depth': 7, 'n_estimators': 914, 'subsample': 0.9843601031073519}. Best is trial 38 with value: 0.999384.[0m
[07:02:32] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09454	valid-rmse:1.09959
[20]	train-rmse:1.04590	valid-rmse:1.05316
[100]	train-rmse:0.98413	valid-rmse:1.00206
[720]	train-rmse:1.05265	valid-rmse:1.05936
[280]	train-rmse:1.08411	valid-rmse:1.08954
[180]	train-rmse:1.09547	valid-rmse:1.10051
[20]	train-rmse:1.02872	valid-rmse:1.03721
[40]	train-rmse:1.01808	valid-rmse:1.02771
[120]	train-rmse:0.98055	valid-rmse:1.00069
[740]	train-rmse:1.05167	valid-rmse:1.05842
[300]	train-rmse:1.08309	valid-rmse:1.08856
[200]	train-rmse:1.09502	valid-rmse:1.10008
[60]	train-rmse:1.00233	valid-rmse:1.01417
[40]	train-rmse:1.00141	valid-rmse:1.01338
[140]	train-rmse:0.97793	valid-rmse:0.99999
[80]	train-rmse:0.99307	valid-rmse:1.00697
[760]	train-rmse:1.05070	valid-rmse:1.05750
[320]	train-rmse:1.08208	valid-rmse:1.08759
[60]	train-rmse:0.98933	valid-rmse:1.00452
[220]	train-rmse:1.09457	valid-rmse:1.09965
[100]	train-rmse:0.98759	valid-rmse:1.00325
[160]	train-rmse:0.97546	valid-rmse:0.99975
[80]	train-rmse:0.98314	valid-rmse:1.00118
[340]	train-rmse:1.08108	valid-rmse:1.08663
[780]	train-rmse:1.04975	valid-rmse:1.05660
[240]	train-rmse:1.09413	valid-rmse:1.09922
[120]	train-rmse:0.98398	valid-rmse:1.00126
[100]	train-rmse:0.97925	valid-rmse:1.00003
[180]	train-rmse:0.97313	valid-rmse:0.99968
[140]	train-rmse:0.98127	valid-rmse:1.00023
[360]	train-rmse:1.08009	valid-rmse:1.08568
[260]	train-rmse:1.09369	valid-rmse:1.09879
[800]	train-rmse:1.04881	valid-rmse:1.05571
[120]	train-rmse:0.97646	valid-rmse:0.99952
[160]	train-rmse:0.97918	valid-rmse:0.99970
[200]	train-rmse:0.97100	valid-rmse:0.99971
[380]	train-rmse:1.07911	valid-rmse:1.08474
[280]	train-rmse:1.09325	valid-rmse:1.09837
[820]	train-rmse:1.04788	valid-rmse:1.05483
[180]	train-rmse:0.97714	valid-rmse:0.99944
[140]	train-rmse:0.97352	valid-rmse:0.99949
[220]	train-rmse:0.96915	valid-rmse:0.99964
[400]	train-rmse:1.07814	valid-rmse:1.08381
[200]	train-rmse:0.97543	valid-rmse:0.99941
[300]	train-rmse:1.09281	valid-rmse:1.09794
[840]	train-rmse:1.04696	valid-rmse:1.05396
[160]	train-rmse:0.97002	valid-rmse:0.99960
[240]	train-rmse:0.96710	valid-rmse:0.99976
[220]	train-rmse:0.97378	valid-rmse:0.99933
[420]	train-rmse:1.07718	valid-rmse:1.08289
[180]	train-rmse:0.96741	valid-rmse:0.99972
[320]	train-rmse:1.09237	valid-rmse:1.09752
[860]	train-rmse:1.04606	valid-rmse:1.05312
[240]	train-rmse:0.97198	valid-rmse:0.99929
[190]	train-rmse:0.96611	valid-rmse:0.99980
[32m[I 2022-04-15 07:18:33,083][0m Trial 45 finished with value: 0.999489 and parameters: {'colsample_bytree': 0.384843390680077, 'eta': 0.025333564531841733, 'max_depth': 7, 'n_estimators': 766, 'subsample': 0.9477085253203428}. Best is trial 38 with value: 0.999384.[0m
[07:18:37] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09451	valid-rmse:1.09960
[260]	train-rmse:0.96505	valid-rmse:0.99989
[440]	train-rmse:1.07623	valid-rmse:1.08197
[260]	train-rmse:0.97017	valid-rmse:0.99930
[340]	train-rmse:1.09193	valid-rmse:1.09710
[270]	train-rmse:0.96387	valid-rmse:0.99992
[32m[I 2022-04-15 07:20:00,601][0m Trial 42 finished with value: 0.999637 and parameters: {'colsample_bytree': 0.4754685827380298, 'eta': 0.01894910290715494, 'max_depth': 7, 'n_estimators': 905, 'subsample': 0.9212849844168547}. Best is trial 38 with value: 0.999384.[0m
[880]	train-rmse:1.04517	valid-rmse:1.05228
[07:20:05] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09473	valid-rmse:1.09984
[20]	train-rmse:1.02875	valid-rmse:1.03740
[460]	train-rmse:1.07529	valid-rmse:1.08108
[280]	train-rmse:0.96858	valid-rmse:0.99931
[360]	train-rmse:1.09150	valid-rmse:1.09668
[20]	train-rmse:1.03041	valid-rmse:1.03892
[900]	train-rmse:1.04430	valid-rmse:1.05145
[40]	train-rmse:1.00117	valid-rmse:1.01359
[300]	train-rmse:0.96702	valid-rmse:0.99933
[302]	train-rmse:0.96690	valid-rmse:0.99933
[32m[I 2022-04-15 07:22:53,835][0m Trial 44 finished with value: 0.999254 and parameters: {'colsample_bytree': 0.2837078621960535, 'eta': 0.01673595459223884, 'max_depth': 7, 'n_estimators': 908, 'subsample': 0.9988265114907936}. Best is trial 44 with value: 0.999254.[0m
[07:22:58] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09569	valid-rmse:1.10068
[480]	train-rmse:1.07435	valid-rmse:1.08018
[20]	train-rmse:1.04076	valid-rmse:1.04698
[40]	train-rmse:1.00280	valid-rmse:1.01484
[60]	train-rmse:0.98891	valid-rmse:1.00453
[380]	train-rmse:1.09107	valid-rmse:1.09626
[920]	train-rmse:1.04344	valid-rmse:1.05063
[40]	train-rmse:1.01383	valid-rmse:1.02137
[60]	train-rmse:1.00081	valid-rmse:1.00981
[500]	train-rmse:1.07343	valid-rmse:1.07930
[80]	train-rmse:0.99387	valid-rmse:1.00464
[80]	train-rmse:0.98289	valid-rmse:1.00113
[60]	train-rmse:0.99032	valid-rmse:1.00552
[400]	train-rmse:1.09064	valid-rmse:1.09585
[100]	train-rmse:0.98964	valid-rmse:1.00212
[940]	train-rmse:1.04259	valid-rmse:1.04983
[120]	train-rmse:0.98662	valid-rmse:1.00092
[520]	train-rmse:1.07252	valid-rmse:1.07843
[100]	train-rmse:0.97892	valid-rmse:0.99993
[140]	train-rmse:0.98438	valid-rmse:1.00063
[80]	train-rmse:0.98389	valid-rmse:1.00197
[160]	train-rmse:0.98228	valid-rmse:1.00038
[420]	train-rmse:1.09021	valid-rmse:1.09544
[180]	train-rmse:0.98050	valid-rmse:1.00045
[960]	train-rmse:1.04175	valid-rmse:1.04904
[540]	train-rmse:1.07162	valid-rmse:1.07757
[120]	train-rmse:0.97566	valid-rmse:0.99941
[200]	train-rmse:0.97858	valid-rmse:1.00047
[100]	train-rmse:0.98013	valid-rmse:1.00061
[212]	train-rmse:0.97725	valid-rmse:1.00060
[32m[I 2022-04-15 07:29:22,141][0m Trial 48 finished with value: 1.000362 and parameters: {'colsample_bytree': 0.20644915241965733, 'eta': 0.020025654077499833, 'max_depth': 7, 'n_estimators': 803, 'subsample': 0.20091202843922085}. Best is trial 44 with value: 0.999254.[0m
[07:29:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.05233	valid-rmse:1.05856
[440]	train-rmse:1.08978	valid-rmse:1.09502
[140]	train-rmse:0.97274	valid-rmse:0.99933
[980]	train-rmse:1.04093	valid-rmse:1.04827
[560]	train-rmse:1.07072	valid-rmse:1.07671
[120]	train-rmse:0.97688	valid-rmse:0.99996
[20]	train-rmse:0.96912	valid-rmse:1.00435
[460]	train-rmse:1.08936	valid-rmse:1.09461
[160]	train-rmse:0.96974	valid-rmse:0.99934
[140]	train-rmse:0.97396	valid-rmse:0.99976
[999]	train-rmse:1.04015	valid-rmse:1.04754
[580]	train-rmse:1.06984	valid-rmse:1.07587
[40]	train-rmse:0.94083	valid-rmse:1.00991
[32m[I 2022-04-15 07:32:33,685][0m Trial 31 finished with value: 1.047541 and parameters: {'colsample_bytree': 0.8246693141824883, 'eta': 0.00041321079817504533, 'max_depth': 7, 'n_estimators': 325, 'subsample': 0.4401725360265827}. Best is trial 44 with value: 0.999254.[0m
[07:32:38] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.07985	valid-rmse:1.08545
[180]	train-rmse:0.96750	valid-rmse:0.99946
[480]	train-rmse:1.08893	valid-rmse:1.09420
[60]	train-rmse:0.91353	valid-rmse:1.01490
[160]	train-rmse:0.97141	valid-rmse:0.99985
[32m[I 2022-04-15 07:34:03,925][0m Trial 49 finished with value: 1.001989 and parameters: {'colsample_bytree': 0.2989376925012503, 'eta': 0.2646351601734074, 'max_depth': 7, 'n_estimators': 757, 'subsample': 0.998768436677279}. Best is trial 44 with value: 0.999254.[0m
[07:34:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.02049	valid-rmse:1.02961
[600]	train-rmse:1.06896	valid-rmse:1.07503
[20]	train-rmse:0.98254	valid-rmse:1.00121
[200]	train-rmse:0.96457	valid-rmse:0.99961
[201]	train-rmse:0.96446	valid-rmse:0.99964
[32m[I 2022-04-15 07:35:34,593][0m Trial 46 finished with value: 0.999319 and parameters: {'colsample_bytree': 0.38203590504097085, 'eta': 0.02524325556662713, 'max_depth': 7, 'n_estimators': 957, 'subsample': 0.9360031786495214}. Best is trial 44 with value: 0.999254.[0m
[07:35:38] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[180]	train-rmse:0.96897	valid-rmse:0.99992
[0]	train-rmse:1.03391	valid-rmse:1.03945
[500]	train-rmse:1.08851	valid-rmse:1.09380
[20]	train-rmse:0.94737	valid-rmse:1.02044
[40]	train-rmse:0.97017	valid-rmse:1.00083
[620]	train-rmse:1.06810	valid-rmse:1.07420
[190]	train-rmse:0.96762	valid-rmse:0.99993
[32m[I 2022-04-15 07:36:39,510][0m Trial 47 finished with value: 0.999757 and parameters: {'colsample_bytree': 0.40365670872730364, 'eta': 0.024321239370962477, 'max_depth': 7, 'n_estimators': 797, 'subsample': 0.9545176651375398}. Best is trial 44 with value: 0.999254.[0m
[07:36:43] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.07831	valid-rmse:1.08312
[20]	train-rmse:0.98033	valid-rmse:1.00700
[40]	train-rmse:0.90120	valid-rmse:1.03309
[520]	train-rmse:1.08809	valid-rmse:1.09339
[20]	train-rmse:0.99166	valid-rmse:1.00023
[60]	train-rmse:0.95906	valid-rmse:1.00155
[40]	train-rmse:0.96504	valid-rmse:1.01191
[640]	train-rmse:1.06724	valid-rmse:1.07338
[51]	train-rmse:0.87587	valid-rmse:1.03897
[32m[I 2022-04-15 07:38:51,788][0m Trial 51 finished with value: 1.007178 and parameters: {'colsample_bytree': 0.38790647227033853, 'eta': 0.49835079615813926, 'max_depth': 7, 'n_estimators': 972, 'subsample': 0.9325775083852919}. Best is trial 44 with value: 0.999254.[0m
[07:38:56] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[55]	train-rmse:0.95382	valid-rmse:1.01503
[32m[I 2022-04-15 07:38:57,068][0m Trial 52 finished with value: 1.00178 and parameters: {'colsample_bytree': 0.38598617630485493, 'eta': 0.4047895876775741, 'max_depth': 5, 'n_estimators': 979, 'subsample': 0.9299230103797044}. Best is trial 44 with value: 0.999254.[0m
[40]	train-rmse:0.98567	valid-rmse:0.99977
[07:39:01] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.07993	valid-rmse:1.08488
[0]	train-rmse:1.08257	valid-rmse:1.08797
[80]	train-rmse:0.94840	valid-rmse:1.00222
[540]	train-rmse:1.08767	valid-rmse:1.09299
[20]	train-rmse:0.99215	valid-rmse:1.00079
[60]	train-rmse:0.98077	valid-rmse:1.00035
[84]	train-rmse:0.94602	valid-rmse:1.00247
[32m[I 2022-04-15 07:40:07,299][0m Trial 50 finished with value: 1.000527 and parameters: {'colsample_bytree': 0.3938887184789647, 'eta': 0.10139974910417099, 'max_depth': 7, 'n_estimators': 478, 'subsample': 0.9366098612748853}. Best is trial 44 with value: 0.999254.[0m
[07:40:11] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[660]	train-rmse:1.06639	valid-rmse:1.07257
[0]	train-rmse:1.09836	valid-rmse:1.10330
[20]	train-rmse:0.98552	valid-rmse:1.00195
[40]	train-rmse:0.98619	valid-rmse:0.99980
[80]	train-rmse:0.97610	valid-rmse:1.00098
[85]	train-rmse:0.97485	valid-rmse:1.00117
[32m[I 2022-04-15 07:41:27,014][0m Trial 53 finished with value: 0.999481 and parameters: {'colsample_bytree': 0.36585267695351464, 'eta': 0.1138682378523554, 'max_depth': 5, 'n_estimators': 976, 'subsample': 0.8905969998650687}. Best is trial 44 with value: 0.999254.[0m
[40]	train-rmse:0.97316	valid-rmse:1.00035
[07:41:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09847	valid-rmse:1.10336
[20]	train-rmse:1.07591	valid-rmse:1.08168
[560]	train-rmse:1.08726	valid-rmse:1.09259
[60]	train-rmse:0.98166	valid-rmse:1.00080
[20]	train-rmse:1.07812	valid-rmse:1.08266
[680]	train-rmse:1.06555	valid-rmse:1.07176
[40]	train-rmse:1.06173	valid-rmse:1.06597
[60]	train-rmse:0.96451	valid-rmse:1.00113
[80]	train-rmse:0.97716	valid-rmse:1.00148
[40]	train-rmse:1.05780	valid-rmse:1.06446
[86]	train-rmse:0.97603	valid-rmse:1.00165
[32m[I 2022-04-15 07:43:55,282][0m Trial 54 finished with value: 0.99976 and parameters: {'colsample_bytree': 0.3160607738093691, 'eta': 0.10492305932027576, 'max_depth': 5, 'n_estimators': 866, 'subsample': 0.8846742133181381}. Best is trial 44 with value: 0.999254.[0m
[07:44:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.04857	valid-rmse:1.05255
[0]	train-rmse:1.09960	valid-rmse:1.10451
[580]	train-rmse:1.08684	valid-rmse:1.09219
[20]	train-rmse:1.09950	valid-rmse:1.10441
[80]	train-rmse:1.03802	valid-rmse:1.04183
[80]	train-rmse:0.95540	valid-rmse:1.00196
[700]	train-rmse:1.06472	valid-rmse:1.07096
[60]	train-rmse:1.04340	valid-rmse:1.05070
[84]	train-rmse:0.95357	valid-rmse:1.00216
[32m[I 2022-04-15 07:46:03,831][0m Trial 55 finished with value: 1.000084 and parameters: {'colsample_bytree': 0.2506538466505188, 'eta': 0.08812252743486487, 'max_depth': 7, 'n_estimators': 862, 'subsample': 0.8634652183715412}. Best is trial 44 with value: 0.999254.[0m
[40]	train-rmse:1.09941	valid-rmse:1.10432
[07:46:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09876	valid-rmse:1.10366
[100]	train-rmse:1.02958	valid-rmse:1.03322
[60]	train-rmse:1.09931	valid-rmse:1.10422
[20]	train-rmse:1.08311	valid-rmse:1.08778
[120]	train-rmse:1.02285	valid-rmse:1.02633
[80]	train-rmse:1.09922	valid-rmse:1.10412
[40]	train-rmse:1.06977	valid-rmse:1.07422
[80]	train-rmse:1.03176	valid-rmse:1.03985
[140]	train-rmse:1.01744	valid-rmse:1.02081
[600]	train-rmse:1.08643	valid-rmse:1.09179
[100]	train-rmse:1.09912	valid-rmse:1.10403
[60]	train-rmse:1.05846	valid-rmse:1.06274
[160]	train-rmse:1.01314	valid-rmse:1.01640
[720]	train-rmse:1.06389	valid-rmse:1.07018
[120]	train-rmse:1.09903	valid-rmse:1.10393
[80]	train-rmse:1.04887	valid-rmse:1.05297
[180]	train-rmse:1.00970	valid-rmse:1.01285
[100]	train-rmse:1.02241	valid-rmse:1.03126
[140]	train-rmse:1.09894	valid-rmse:1.10384
[100]	train-rmse:1.04072	valid-rmse:1.04465
[200]	train-rmse:1.00696	valid-rmse:1.01005
[160]	train-rmse:1.09884	valid-rmse:1.10374
[120]	train-rmse:1.03384	valid-rmse:1.03764
[220]	train-rmse:1.00476	valid-rmse:1.00780
[180]	train-rmse:1.09875	valid-rmse:1.10364
[620]	train-rmse:1.08602	valid-rmse:1.09139
[120]	train-rmse:1.01490	valid-rmse:1.02448
[740]	train-rmse:1.06307	valid-rmse:1.06940
[140]	train-rmse:1.02799	valid-rmse:1.03166
[240]	train-rmse:1.00300	valid-rmse:1.00600
[200]	train-rmse:1.09865	valid-rmse:1.10355
[160]	train-rmse:1.02304	valid-rmse:1.02661
[260]	train-rmse:1.00159	valid-rmse:1.00456
[220]	train-rmse:1.09856	valid-rmse:1.10345
[180]	train-rmse:1.01886	valid-rmse:1.02232
[140]	train-rmse:1.00876	valid-rmse:1.01912
[280]	train-rmse:1.00045	valid-rmse:1.00341
[240]	train-rmse:1.09847	valid-rmse:1.10336
[200]	train-rmse:1.01534	valid-rmse:1.01871
[640]	train-rmse:1.08561	valid-rmse:1.09099
[300]	train-rmse:0.99953	valid-rmse:1.00248
[760]	train-rmse:1.06226	valid-rmse:1.06863
[260]	train-rmse:1.09837	valid-rmse:1.10326
[220]	train-rmse:1.01235	valid-rmse:1.01565
[320]	train-rmse:0.99878	valid-rmse:1.00173
[280]	train-rmse:1.09828	valid-rmse:1.10317
[240]	train-rmse:1.00984	valid-rmse:1.01306
[160]	train-rmse:1.00376	valid-rmse:1.01490
[300]	train-rmse:1.09819	valid-rmse:1.10307
[340]	train-rmse:0.99817	valid-rmse:1.00114
[260]	train-rmse:1.00769	valid-rmse:1.01089
[320]	train-rmse:1.09809	valid-rmse:1.10298
[280]	train-rmse:1.00588	valid-rmse:1.00904
[360]	train-rmse:0.99766	valid-rmse:1.00067
[180]	train-rmse:0.99971	valid-rmse:1.01149
[780]	train-rmse:1.06147	valid-rmse:1.06787
[660]	train-rmse:1.08520	valid-rmse:1.09060
[340]	train-rmse:1.09800	valid-rmse:1.10288
[300]	train-rmse:1.00434	valid-rmse:1.00745
[380]	train-rmse:0.99724	valid-rmse:1.00028
[360]	train-rmse:1.09791	valid-rmse:1.10279
[320]	train-rmse:1.00306	valid-rmse:1.00615
[400]	train-rmse:0.99690	valid-rmse:0.99997
[380]	train-rmse:1.09781	valid-rmse:1.10269
[340]	train-rmse:1.00196	valid-rmse:1.00503
[200]	train-rmse:0.99641	valid-rmse:1.00891
[420]	train-rmse:0.99660	valid-rmse:0.99972
[400]	train-rmse:1.09772	valid-rmse:1.10260
[360]	train-rmse:1.00102	valid-rmse:1.00407
[440]	train-rmse:0.99635	valid-rmse:0.99953
[800]	train-rmse:1.06067	valid-rmse:1.06712
[680]	train-rmse:1.08479	valid-rmse:1.09021
[420]	train-rmse:1.09763	valid-rmse:1.10250
[380]	train-rmse:1.00021	valid-rmse:1.00325
[460]	train-rmse:0.99613	valid-rmse:0.99938
[220]	train-rmse:0.99362	valid-rmse:1.00684
[440]	train-rmse:1.09753	valid-rmse:1.10241
[400]	train-rmse:0.99953	valid-rmse:1.00255
[480]	train-rmse:0.99594	valid-rmse:0.99925
[460]	train-rmse:1.09744	valid-rmse:1.10231
[420]	train-rmse:0.99894	valid-rmse:1.00195
[500]	train-rmse:0.99578	valid-rmse:0.99915
[480]	train-rmse:1.09735	valid-rmse:1.10222
[440]	train-rmse:0.99845	valid-rmse:1.00146
[240]	train-rmse:0.99134	valid-rmse:1.00527
[820]	train-rmse:1.05989	valid-rmse:1.06638
[700]	train-rmse:1.08438	valid-rmse:1.08982
[520]	train-rmse:0.99563	valid-rmse:0.99908
[460]	train-rmse:0.99801	valid-rmse:1.00105
[500]	train-rmse:1.09726	valid-rmse:1.10212
[540]	train-rmse:0.99550	valid-rmse:0.99902
[480]	train-rmse:0.99763	valid-rmse:1.00069
[520]	train-rmse:1.09716	valid-rmse:1.10203
[260]	train-rmse:0.98925	valid-rmse:1.00398
[560]	train-rmse:0.99538	valid-rmse:0.99896
[500]	train-rmse:0.99731	valid-rmse:1.00039
[540]	train-rmse:1.09707	valid-rmse:1.10194
[520]	train-rmse:0.99703	valid-rmse:1.00015
[560]	train-rmse:1.09698	valid-rmse:1.10184
[580]	train-rmse:0.99526	valid-rmse:0.99892
[840]	train-rmse:1.05911	valid-rmse:1.06564
[720]	train-rmse:1.08398	valid-rmse:1.08943
[540]	train-rmse:0.99677	valid-rmse:0.99992
[580]	train-rmse:1.09689	valid-rmse:1.10175
[600]	train-rmse:0.99514	valid-rmse:0.99887
[280]	train-rmse:0.98749	valid-rmse:1.00301
[560]	train-rmse:0.99655	valid-rmse:0.99974
[600]	train-rmse:1.09679	valid-rmse:1.10165
[620]	train-rmse:0.99504	valid-rmse:0.99885
[580]	train-rmse:0.99635	valid-rmse:0.99957
[620]	train-rmse:1.09670	valid-rmse:1.10156
[640]	train-rmse:0.99495	valid-rmse:0.99882
[300]	train-rmse:0.98598	valid-rmse:1.00216
[600]	train-rmse:0.99616	valid-rmse:0.99942
[640]	train-rmse:1.09661	valid-rmse:1.10147
[860]	train-rmse:1.05834	valid-rmse:1.06491
[660]	train-rmse:0.99484	valid-rmse:0.99880
[740]	train-rmse:1.08358	valid-rmse:1.08904
[620]	train-rmse:0.99601	valid-rmse:0.99929
[660]	train-rmse:1.09652	valid-rmse:1.10137
[680]	train-rmse:0.99474	valid-rmse:0.99880
[640]	train-rmse:0.99587	valid-rmse:0.99919
[680]	train-rmse:1.09643	valid-rmse:1.10128
[320]	train-rmse:0.98463	valid-rmse:1.00156
[700]	train-rmse:0.99465	valid-rmse:0.99878
[660]	train-rmse:0.99573	valid-rmse:0.99911
[700]	train-rmse:1.09633	valid-rmse:1.10119
[720]	train-rmse:0.99456	valid-rmse:0.99877
[880]	train-rmse:1.05758	valid-rmse:1.06420
[680]	train-rmse:0.99561	valid-rmse:0.99904
[720]	train-rmse:1.09624	valid-rmse:1.10109
[760]	train-rmse:1.08318	valid-rmse:1.08866
[340]	train-rmse:0.98348	valid-rmse:1.00107
[740]	train-rmse:0.99448	valid-rmse:0.99875
[700]	train-rmse:0.99550	valid-rmse:0.99898
[740]	train-rmse:1.09615	valid-rmse:1.10100
[760]	train-rmse:0.99440	valid-rmse:0.99875
[720]	train-rmse:0.99539	valid-rmse:0.99893
[760]	train-rmse:1.09606	valid-rmse:1.10091
[780]	train-rmse:0.99431	valid-rmse:0.99875
[740]	train-rmse:0.99529	valid-rmse:0.99889
[780]	train-rmse:1.09597	valid-rmse:1.10081
[360]	train-rmse:0.98249	valid-rmse:1.00070
[900]	train-rmse:1.05683	valid-rmse:1.06348
[760]	train-rmse:0.99519	valid-rmse:0.99884
[800]	train-rmse:1.09588	valid-rmse:1.10072
[800]	train-rmse:0.99423	valid-rmse:0.99875
[780]	train-rmse:1.08278	valid-rmse:1.08827
[780]	train-rmse:0.99511	valid-rmse:0.99881
[820]	train-rmse:1.09579	valid-rmse:1.10063
[820]	train-rmse:0.99414	valid-rmse:0.99875
[380]	train-rmse:0.98143	valid-rmse:1.00038
[800]	train-rmse:0.99503	valid-rmse:0.99879
[840]	train-rmse:1.09569	valid-rmse:1.10053
[840]	train-rmse:0.99406	valid-rmse:0.99875
[842]	train-rmse:0.99405	valid-rmse:0.99875
[32m[I 2022-04-15 08:11:29,549][0m Trial 57 finished with value: 0.998744 and parameters: {'colsample_bytree': 0.32087077030990446, 'eta': 0.005849862760416412, 'max_depth': 3, 'n_estimators': 869, 'subsample': 0.8790116796538695}. Best is trial 57 with value: 0.998744.[0m
[08:11:34] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09829	valid-rmse:1.10318
[860]	train-rmse:1.09560	valid-rmse:1.10044
[820]	train-rmse:0.99494	valid-rmse:0.99876
[920]	train-rmse:1.05608	valid-rmse:1.06278
[20]	train-rmse:1.07520	valid-rmse:1.07971
[840]	train-rmse:0.99486	valid-rmse:0.99874
[880]	train-rmse:1.09551	valid-rmse:1.10035
[400]	train-rmse:0.98046	valid-rmse:1.00011
[800]	train-rmse:1.08238	valid-rmse:1.08789
[860]	train-rmse:0.99479	valid-rmse:0.99873
[900]	train-rmse:1.09542	valid-rmse:1.10025
[40]	train-rmse:1.05722	valid-rmse:1.06140
[920]	train-rmse:1.09533	valid-rmse:1.10016
[880]	train-rmse:0.99471	valid-rmse:0.99870
[60]	train-rmse:1.04329	valid-rmse:1.04720
[420]	train-rmse:0.97955	valid-rmse:0.99991
[940]	train-rmse:1.09524	valid-rmse:1.10007
[900]	train-rmse:0.99464	valid-rmse:0.99870
[940]	train-rmse:1.05534	valid-rmse:1.06208
[80]	train-rmse:1.03250	valid-rmse:1.03622
[960]	train-rmse:1.09515	valid-rmse:1.09998
[920]	train-rmse:0.99457	valid-rmse:0.99869
[820]	train-rmse:1.08198	valid-rmse:1.08751
[100]	train-rmse:1.02416	valid-rmse:1.02772
[980]	train-rmse:1.09506	valid-rmse:1.09988
[940]	train-rmse:0.99450	valid-rmse:0.99869
[440]	train-rmse:0.97864	valid-rmse:0.99976
[120]	train-rmse:1.01774	valid-rmse:1.02113
[999]	train-rmse:1.09497	valid-rmse:1.09980
[960]	train-rmse:0.99442	valid-rmse:0.99870
[32m[I 2022-04-15 08:15:25,370][0m Trial 58 finished with value: 1.099796 and parameters: {'colsample_bytree': 0.2645788096077266, 'eta': 2.4325314719490172e-05, 'max_depth': 3, 'n_estimators': 1020, 'subsample': 0.9987781403546474}. Best is trial 57 with value: 0.998744.[0m
[08:15:29] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09833	valid-rmse:1.10323
[969]	train-rmse:0.99439	valid-rmse:0.99870
[32m[I 2022-04-15 08:15:42,322][0m Trial 59 finished with value: 0.998688 and parameters: {'colsample_bytree': 0.3507224721069534, 'eta': 0.004374062435152421, 'max_depth': 3, 'n_estimators': 998, 'subsample': 0.6120220762055004}. Best is trial 59 with value: 0.998688.[0m
[08:15:46] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09853	valid-rmse:1.10342
[960]	train-rmse:1.05461	valid-rmse:1.06139
[140]	train-rmse:1.01277	valid-rmse:1.01604
[20]	train-rmse:1.07569	valid-rmse:1.08025
[460]	train-rmse:0.97770	valid-rmse:0.99967
[20]	train-rmse:1.07891	valid-rmse:1.08353
[160]	train-rmse:1.00894	valid-rmse:1.01211
[840]	train-rmse:1.08159	valid-rmse:1.08713
[40]	train-rmse:1.05793	valid-rmse:1.06221
[40]	train-rmse:1.06295	valid-rmse:1.06732
[60]	train-rmse:1.04411	valid-rmse:1.04812
[180]	train-rmse:1.00599	valid-rmse:1.00907
[60]	train-rmse:1.05005	valid-rmse:1.05418
[80]	train-rmse:1.03337	valid-rmse:1.03717
[480]	train-rmse:0.97687	valid-rmse:0.99958
[200]	train-rmse:1.00371	valid-rmse:1.00674
[80]	train-rmse:1.03962	valid-rmse:1.04356
[980]	train-rmse:1.05389	valid-rmse:1.06071
[100]	train-rmse:1.02501	valid-rmse:1.02860
[100]	train-rmse:1.03118	valid-rmse:1.03491
[220]	train-rmse:1.00194	valid-rmse:1.00493
[120]	train-rmse:1.01853	valid-rmse:1.02199
[860]	train-rmse:1.08120	valid-rmse:1.08675
[120]	train-rmse:1.02438	valid-rmse:1.02797
[240]	train-rmse:1.00057	valid-rmse:1.00353
[500]	train-rmse:0.97604	valid-rmse:0.99952
[140]	train-rmse:1.01348	valid-rmse:1.01682
[140]	train-rmse:1.01888	valid-rmse:1.02233
[260]	train-rmse:0.99950	valid-rmse:1.00245
[160]	train-rmse:1.00957	valid-rmse:1.01279
[160]	train-rmse:1.01445	valid-rmse:1.01778
[999]	train-rmse:1.05321	valid-rmse:1.06007
[32m[I 2022-04-15 08:19:49,297][0m Trial 40 finished with value: 1.06007 and parameters: {'colsample_bytree': 0.4446198118631166, 'eta': 0.0002906261938468737, 'max_depth': 7, 'n_estimators': 472, 'subsample': 0.9793446973789568}. Best is trial 59 with value: 0.998688.[0m
[08:19:53] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09847	valid-rmse:1.10337
[180]	train-rmse:1.00652	valid-rmse:1.00965
[180]	train-rmse:1.01087	valid-rmse:1.01410
[280]	train-rmse:0.99865	valid-rmse:1.00162
[520]	train-rmse:0.97522	valid-rmse:0.99949
[20]	train-rmse:1.07803	valid-rmse:1.08262
[200]	train-rmse:1.00418	valid-rmse:1.00726
[200]	train-rmse:1.00800	valid-rmse:1.01117
[880]	train-rmse:1.08081	valid-rmse:1.08638
[300]	train-rmse:0.99797	valid-rmse:1.00097
[40]	train-rmse:1.06155	valid-rmse:1.06589
[220]	train-rmse:1.00567	valid-rmse:1.00878
[220]	train-rmse:1.00234	valid-rmse:1.00537
[320]	train-rmse:0.99743	valid-rmse:1.00046
[60]	train-rmse:1.04837	valid-rmse:1.05246
[240]	train-rmse:1.00380	valid-rmse:1.00686
[540]	train-rmse:0.97440	valid-rmse:0.99947
[240]	train-rmse:1.00090	valid-rmse:1.00392
[340]	train-rmse:0.99701	valid-rmse:1.00006
[80]	train-rmse:1.03783	valid-rmse:1.04174
[260]	train-rmse:1.00227	valid-rmse:1.00532
[260]	train-rmse:0.99975	valid-rmse:1.00278
[100]	train-rmse:1.02939	valid-rmse:1.03309
[280]	train-rmse:1.00103	valid-rmse:1.00407
[360]	train-rmse:0.99664	valid-rmse:0.99976
[280]	train-rmse:0.99886	valid-rmse:1.00189
[900]	train-rmse:1.08042	valid-rmse:1.08600
[560]	train-rmse:0.97361	valid-rmse:0.99940
[120]	train-rmse:1.02267	valid-rmse:1.02622
[300]	train-rmse:1.00002	valid-rmse:1.00303
[300]	train-rmse:0.99814	valid-rmse:1.00119
[380]	train-rmse:0.99635	valid-rmse:0.99952
[140]	train-rmse:1.01727	valid-rmse:1.02069
[320]	train-rmse:0.99921	valid-rmse:1.00224
[320]	train-rmse:0.99758	valid-rmse:1.00066
[400]	train-rmse:0.99610	valid-rmse:0.99933
[160]	train-rmse:1.01298	valid-rmse:1.01629
[340]	train-rmse:0.99855	valid-rmse:1.00157
[340]	train-rmse:0.99712	valid-rmse:1.00023
[580]	train-rmse:0.97274	valid-rmse:0.99942
[180]	train-rmse:1.00955	valid-rmse:1.01276
[420]	train-rmse:0.99588	valid-rmse:0.99919
[360]	train-rmse:0.99799	valid-rmse:1.00104
[360]	train-rmse:0.99674	valid-rmse:0.99990
[920]	train-rmse:1.08003	valid-rmse:1.08563
[200]	train-rmse:1.00683	valid-rmse:1.00999
[380]	train-rmse:0.99752	valid-rmse:1.00059
[440]	train-rmse:0.99569	valid-rmse:0.99907
[380]	train-rmse:0.99642	valid-rmse:0.99962
[220]	train-rmse:1.00465	valid-rmse:1.00774
[400]	train-rmse:0.99714	valid-rmse:1.00022
[600]	train-rmse:0.97196	valid-rmse:0.99943
[460]	train-rmse:0.99552	valid-rmse:0.99899
[400]	train-rmse:0.99616	valid-rmse:0.99942
[240]	train-rmse:1.00290	valid-rmse:1.00596
[420]	train-rmse:0.99681	valid-rmse:0.99992
[420]	train-rmse:0.99593	valid-rmse:0.99926
[480]	train-rmse:0.99538	valid-rmse:0.99891
[260]	train-rmse:1.00148	valid-rmse:1.00453
[440]	train-rmse:0.99653	valid-rmse:0.99967
[615]	train-rmse:0.97137	valid-rmse:0.99943
[32m[I 2022-04-15 08:27:02,980][0m Trial 56 finished with value: 0.999391 and parameters: {'colsample_bytree': 0.33786630774321974, 'eta': 0.006218004271951415, 'max_depth': 7, 'n_estimators': 863, 'subsample': 0.6407837966303446}. Best is trial 59 with value: 0.998688.[0m
[440]	train-rmse:0.99574	valid-rmse:0.99911
[08:27:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[940]	train-rmse:1.07964	valid-rmse:1.08526
[0]	train-rmse:1.09859	valid-rmse:1.10349
[280]	train-rmse:1.00035	valid-rmse:1.00340
[500]	train-rmse:0.99524	valid-rmse:0.99886
[460]	train-rmse:0.99628	valid-rmse:0.99948
[460]	train-rmse:0.99555	valid-rmse:0.99902
[20]	train-rmse:1.08014	valid-rmse:1.08475
[300]	train-rmse:0.99942	valid-rmse:1.00247
[480]	train-rmse:0.99608	valid-rmse:0.99933
[520]	train-rmse:0.99511	valid-rmse:0.99883
[40]	train-rmse:1.06491	valid-rmse:1.06930
[480]	train-rmse:0.99540	valid-rmse:0.99894
[320]	train-rmse:0.99869	valid-rmse:1.00176
[500]	train-rmse:0.99590	valid-rmse:0.99921
[540]	train-rmse:0.99499	valid-rmse:0.99880
[60]	train-rmse:1.05242	valid-rmse:1.05662
[500]	train-rmse:0.99526	valid-rmse:0.99889
[340]	train-rmse:0.99809	valid-rmse:1.00117
[520]	train-rmse:0.99574	valid-rmse:0.99912
[80]	train-rmse:1.04219	valid-rmse:1.04620
[560]	train-rmse:0.99487	valid-rmse:0.99879
[520]	train-rmse:0.99513	valid-rmse:0.99886
[360]	train-rmse:0.99759	valid-rmse:1.00071
[540]	train-rmse:0.99558	valid-rmse:0.99904
[960]	train-rmse:1.07926	valid-rmse:1.08489
[100]	train-rmse:1.03378	valid-rmse:1.03760
[540]	train-rmse:0.99500	valid-rmse:0.99883
[560]	train-rmse:0.99545	valid-rmse:0.99897
[380]	train-rmse:0.99717	valid-rmse:1.00032
[580]	train-rmse:0.99476	valid-rmse:0.99877
[120]	train-rmse:1.02691	valid-rmse:1.03059
[580]	train-rmse:0.99532	valid-rmse:0.99890
[400]	train-rmse:0.99683	valid-rmse:1.00000
[560]	train-rmse:0.99488	valid-rmse:0.99881
[600]	train-rmse:0.99465	valid-rmse:0.99874
[140]	train-rmse:1.02127	valid-rmse:1.02483
[600]	train-rmse:0.99520	valid-rmse:0.99884
[420]	train-rmse:0.99654	valid-rmse:0.99975
[580]	train-rmse:0.99476	valid-rmse:0.99876
[160]	train-rmse:1.01666	valid-rmse:1.02010
[620]	train-rmse:0.99455	valid-rmse:0.99873
[620]	train-rmse:0.99509	valid-rmse:0.99880
[440]	train-rmse:0.99629	valid-rmse:0.99953
[600]	train-rmse:0.99464	valid-rmse:0.99874
[980]	train-rmse:1.07887	valid-rmse:1.08452
[180]	train-rmse:1.01290	valid-rmse:1.01622
[640]	train-rmse:0.99499	valid-rmse:0.99877
[640]	train-rmse:0.99446	valid-rmse:0.99872
[460]	train-rmse:0.99607	valid-rmse:0.99937
[620]	train-rmse:0.99454	valid-rmse:0.99872
[200]	train-rmse:1.00983	valid-rmse:1.01308
[660]	train-rmse:0.99488	valid-rmse:0.99877
[480]	train-rmse:0.99588	valid-rmse:0.99925
[660]	train-rmse:0.99435	valid-rmse:0.99872
[640]	train-rmse:0.99445	valid-rmse:0.99872
[220]	train-rmse:1.00732	valid-rmse:1.01048
[680]	train-rmse:0.99479	valid-rmse:0.99876
[500]	train-rmse:0.99571	valid-rmse:0.99916
[660]	train-rmse:0.99434	valid-rmse:0.99872
[680]	train-rmse:0.99425	valid-rmse:0.99873
[240]	train-rmse:1.00526	valid-rmse:1.00838
[685]	train-rmse:0.99422	valid-rmse:0.99872
[32m[I 2022-04-15 08:33:30,733][0m Trial 60 finished with value: 0.998713 and parameters: {'colsample_bytree': 0.3418815000160369, 'eta': 0.006755633702747014, 'max_depth': 3, 'n_estimators': 1022, 'subsample': 0.902947297638899}. Best is trial 59 with value: 0.998688.[0m
[700]	train-rmse:0.99470	valid-rmse:0.99874
[520]	train-rmse:0.99556	valid-rmse:0.99909
[08:33:35] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09870	valid-rmse:1.10360
[999]	train-rmse:1.07851	valid-rmse:1.08417
[677]	train-rmse:0.99425	valid-rmse:0.99874
[32m[I 2022-04-15 08:33:41,916][0m Trial 61 finished with value: 0.99871 and parameters: {'colsample_bytree': 0.3425699553159452, 'eta': 0.006606892585704014, 'max_depth': 3, 'n_estimators': 961, 'subsample': 0.6190904281774519}. Best is trial 59 with value: 0.998688.[0m
[08:33:46] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[32m[I 2022-04-15 08:33:46,504][0m Trial 41 finished with value: 1.084174 and parameters: {'colsample_bytree': 0.4650292454758735, 'eta': 0.00011428367459524828, 'max_depth': 7, 'n_estimators': 937, 'subsample': 0.9856084787755668}. Best is trial 59 with value: 0.998688.[0m
[260]	train-rmse:1.00355	valid-rmse:1.00664
[0]	train-rmse:1.09929	valid-rmse:1.10420
[08:33:50] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09892	valid-rmse:1.10382
[720]	train-rmse:0.99461	valid-rmse:0.99872
[540]	train-rmse:0.99542	valid-rmse:0.99903
[20]	train-rmse:1.08205	valid-rmse:1.08669
[280]	train-rmse:1.00217	valid-rmse:1.00522
[20]	train-rmse:1.09326	valid-rmse:1.09809
[20]	train-rmse:1.08595	valid-rmse:1.09068
[40]	train-rmse:1.06803	valid-rmse:1.07245
[740]	train-rmse:0.99452	valid-rmse:0.99872
[560]	train-rmse:0.99529	valid-rmse:0.99897
[300]	train-rmse:1.00102	valid-rmse:1.00405
[40]	train-rmse:1.08757	valid-rmse:1.09231
[60]	train-rmse:1.05627	valid-rmse:1.06044
[40]	train-rmse:1.07457	valid-rmse:1.07915
[760]	train-rmse:0.99442	valid-rmse:0.99870
[580]	train-rmse:0.99516	valid-rmse:0.99891
[320]	train-rmse:1.00009	valid-rmse:1.00312
[80]	train-rmse:1.04640	valid-rmse:1.05038
[60]	train-rmse:1.08221	valid-rmse:1.08688
[60]	train-rmse:1.06462	valid-rmse:1.06903
[780]	train-rmse:0.99434	valid-rmse:0.99869
[600]	train-rmse:0.99505	valid-rmse:0.99887
[100]	train-rmse:1.03814	valid-rmse:1.04196
[340]	train-rmse:0.99931	valid-rmse:1.00235
[80]	train-rmse:1.07716	valid-rmse:1.08176
[80]	train-rmse:1.05592	valid-rmse:1.06018
[800]	train-rmse:0.99426	valid-rmse:0.99870
[620]	train-rmse:0.99494	valid-rmse:0.99885
[120]	train-rmse:1.03124	valid-rmse:1.03491
[100]	train-rmse:1.07239	valid-rmse:1.07691
[360]	train-rmse:0.99866	valid-rmse:1.00171
[100]	train-rmse:1.04829	valid-rmse:1.05240
[820]	train-rmse:0.99417	valid-rmse:0.99870
[140]	train-rmse:1.02545	valid-rmse:1.02900
[640]	train-rmse:0.99485	valid-rmse:0.99883
[823]	train-rmse:0.99417	valid-rmse:0.99870
[32m[I 2022-04-15 08:36:49,962][0m Trial 62 finished with value: 0.998695 and parameters: {'colsample_bytree': 0.3188118343806655, 'eta': 0.005613978546855285, 'max_depth': 3, 'n_estimators': 949, 'subsample': 0.6139487669212859}. Best is trial 59 with value: 0.998688.[0m
[08:36:54] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[120]	train-rmse:1.06790	valid-rmse:1.07235
[380]	train-rmse:0.99812	valid-rmse:1.00117
[0]	train-rmse:1.09877	valid-rmse:1.10367
[120]	train-rmse:1.04164	valid-rmse:1.04563
[160]	train-rmse:1.02063	valid-rmse:1.02406
[660]	train-rmse:0.99475	valid-rmse:0.99882
[140]	train-rmse:1.06365	valid-rmse:1.06804
[400]	train-rmse:0.99767	valid-rmse:1.00074
[20]	train-rmse:1.08322	valid-rmse:1.08792
[140]	train-rmse:1.03581	valid-rmse:1.03967
[180]	train-rmse:1.01659	valid-rmse:1.01990
[680]	train-rmse:0.99465	valid-rmse:0.99882
[160]	train-rmse:1.05966	valid-rmse:1.06399
[40]	train-rmse:1.06996	valid-rmse:1.07446
[420]	train-rmse:0.99729	valid-rmse:1.00037
[200]	train-rmse:1.01324	valid-rmse:1.01645
[160]	train-rmse:1.03073	valid-rmse:1.03447
[700]	train-rmse:0.99456	valid-rmse:0.99881
[220]	train-rmse:1.01042	valid-rmse:1.01355
[60]	train-rmse:1.05869	valid-rmse:1.06302
[180]	train-rmse:1.05590	valid-rmse:1.06014
[440]	train-rmse:0.99697	valid-rmse:1.00006
[180]	train-rmse:1.02628	valid-rmse:1.02990
[720]	train-rmse:0.99446	valid-rmse:0.99878
[240]	train-rmse:1.00807	valid-rmse:1.01113
[80]	train-rmse:1.04914	valid-rmse:1.05330
[460]	train-rmse:0.99669	valid-rmse:0.99983
[200]	train-rmse:1.05236	valid-rmse:1.05655
[200]	train-rmse:1.02242	valid-rmse:1.02596
[260]	train-rmse:1.00611	valid-rmse:1.00913
[740]	train-rmse:0.99437	valid-rmse:0.99877
[100]	train-rmse:1.04100	valid-rmse:1.04500
[480]	train-rmse:0.99644	valid-rmse:0.99962
[220]	train-rmse:1.01905	valid-rmse:1.02250
[220]	train-rmse:1.04903	valid-rmse:1.05315
[280]	train-rmse:1.00446	valid-rmse:1.00742
[760]	train-rmse:0.99428	valid-rmse:0.99876
[120]	train-rmse:1.03413	valid-rmse:1.03799
[240]	train-rmse:1.01611	valid-rmse:1.01949
[500]	train-rmse:0.99623	valid-rmse:0.99946
[240]	train-rmse:1.04589	valid-rmse:1.04996
[300]	train-rmse:1.00307	valid-rmse:1.00601
[780]	train-rmse:0.99420	valid-rmse:0.99876
[140]	train-rmse:1.02827	valid-rmse:1.03199
[260]	train-rmse:1.01354	valid-rmse:1.01687
[520]	train-rmse:0.99605	valid-rmse:0.99933
[320]	train-rmse:1.00192	valid-rmse:1.00483
[260]	train-rmse:1.04293	valid-rmse:1.04694
[800]	train-rmse:0.99411	valid-rmse:0.99876
[160]	train-rmse:1.02333	valid-rmse:1.02692
[340]	train-rmse:1.00095	valid-rmse:1.00383
[540]	train-rmse:0.99588	valid-rmse:0.99922
[280]	train-rmse:1.01130	valid-rmse:1.01458
[280]	train-rmse:1.04015	valid-rmse:1.04411
[360]	train-rmse:1.00013	valid-rmse:1.00301
[820]	train-rmse:0.99402	valid-rmse:0.99878
[180]	train-rmse:1.01913	valid-rmse:1.02259
[300]	train-rmse:1.00933	valid-rmse:1.01256
[560]	train-rmse:0.99573	valid-rmse:0.99913
[32m[I 2022-04-15 08:41:31,341][0m Trial 63 finished with value: 0.998756 and parameters: {'colsample_bytree': 0.32495792770837606, 'eta': 0.0058828679146413826, 'max_depth': 3, 'n_estimators': 940, 'subsample': 0.6176780130132884}. Best is trial 59 with value: 0.998688.[0m
[300]	train-rmse:1.03753	valid-rmse:1.04143
[08:41:36] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09889	valid-rmse:1.10379
[380]	train-rmse:0.99942	valid-rmse:1.00230
[320]	train-rmse:1.00765	valid-rmse:1.01084
[200]	train-rmse:1.01559	valid-rmse:1.01898
[580]	train-rmse:0.99559	valid-rmse:0.99905
[20]	train-rmse:1.08547	valid-rmse:1.09017
[320]	train-rmse:1.03507	valid-rmse:1.03893
[400]	train-rmse:0.99885	valid-rmse:1.00171
[340]	train-rmse:1.00616	valid-rmse:1.00931
[40]	train-rmse:1.07374	valid-rmse:1.07827
[600]	train-rmse:0.99547	valid-rmse:0.99897
[220]	train-rmse:1.01259	valid-rmse:1.01591
[340]	train-rmse:1.03276	valid-rmse:1.03655
[420]	train-rmse:0.99835	valid-rmse:1.00122
[60]	train-rmse:1.06355	valid-rmse:1.06788
[360]	train-rmse:1.00487	valid-rmse:1.00798
[240]	train-rmse:1.01005	valid-rmse:1.01330
[620]	train-rmse:0.99535	valid-rmse:0.99891
[440]	train-rmse:0.99792	valid-rmse:1.00081
[360]	train-rmse:1.03058	valid-rmse:1.03432
[80]	train-rmse:1.05469	valid-rmse:1.05888
[380]	train-rmse:1.00373	valid-rmse:1.00681
[260]	train-rmse:1.00790	valid-rmse:1.01110
[640]	train-rmse:0.99525	valid-rmse:0.99887
[460]	train-rmse:0.99756	valid-rmse:1.00046
[380]	train-rmse:1.02852	valid-rmse:1.03221
[100]	train-rmse:1.04695	valid-rmse:1.05101
[480]	train-rmse:0.99725	valid-rmse:1.00018
[400]	train-rmse:1.00275	valid-rmse:1.00579
[280]	train-rmse:1.00607	valid-rmse:1.00922
[660]	train-rmse:0.99514	valid-rmse:0.99884
[120]	train-rmse:1.04025	valid-rmse:1.04417
[400]	train-rmse:1.02660	valid-rmse:1.03023
[500]	train-rmse:0.99697	valid-rmse:0.99993
[420]	train-rmse:1.00187	valid-rmse:1.00489
[300]	train-rmse:1.00451	valid-rmse:1.00763
[140]	train-rmse:1.03439	valid-rmse:1.03821
[680]	train-rmse:0.99504	valid-rmse:0.99880
[420]	train-rmse:1.02478	valid-rmse:1.02837
[520]	train-rmse:0.99673	valid-rmse:0.99972
[160]	train-rmse:1.02932	valid-rmse:1.03302
[440]	train-rmse:1.00112	valid-rmse:1.00412
[320]	train-rmse:1.00322	valid-rmse:1.00631
[700]	train-rmse:0.99495	valid-rmse:0.99877
[440]	train-rmse:1.02308	valid-rmse:1.02663
[540]	train-rmse:0.99652	valid-rmse:0.99956
[180]	train-rmse:1.02491	valid-rmse:1.02850
[460]	train-rmse:1.00045	valid-rmse:1.00345
[340]	train-rmse:1.00210	valid-rmse:1.00516
[720]	train-rmse:0.99486	valid-rmse:0.99877
[560]	train-rmse:0.99634	valid-rmse:0.99942
[460]	train-rmse:1.02148	valid-rmse:1.02500
[200]	train-rmse:1.02110	valid-rmse:1.02460
[480]	train-rmse:0.99986	valid-rmse:1.00285
[360]	train-rmse:1.00116	valid-rmse:1.00420
[740]	train-rmse:0.99477	valid-rmse:0.99875
[580]	train-rmse:0.99617	valid-rmse:0.99929
[220]	train-rmse:1.01779	valid-rmse:1.02121
[480]	train-rmse:1.01997	valid-rmse:1.02344
[500]	train-rmse:0.99934	valid-rmse:1.00234
[600]	train-rmse:0.99603	valid-rmse:0.99919
[380]	train-rmse:1.00034	valid-rmse:1.00337
[240]	train-rmse:1.01492	valid-rmse:1.01827
[760]	train-rmse:0.99468	valid-rmse:0.99874
[500]	train-rmse:1.01855	valid-rmse:1.02199
[620]	train-rmse:0.99589	valid-rmse:0.99909
[260]	train-rmse:1.01242	valid-rmse:1.01572
[520]	train-rmse:0.99889	valid-rmse:1.00190
[400]	train-rmse:0.99965	valid-rmse:1.00267
[780]	train-rmse:0.99461	valid-rmse:0.99873
[520]	train-rmse:1.01721	valid-rmse:1.02062
[280]	train-rmse:1.01026	valid-rmse:1.01349
[640]	train-rmse:0.99577	valid-rmse:0.99902
[540]	train-rmse:0.99848	valid-rmse:1.00151
[420]	train-rmse:0.99905	valid-rmse:1.00206
[800]	train-rmse:0.99453	valid-rmse:0.99872
[300]	train-rmse:1.00838	valid-rmse:1.01155
[540]	train-rmse:1.01596	valid-rmse:1.01934
[660]	train-rmse:0.99566	valid-rmse:0.99895
[560]	train-rmse:0.99813	valid-rmse:1.00116
[440]	train-rmse:0.99855	valid-rmse:1.00155
[320]	train-rmse:1.00676	valid-rmse:1.00990
[820]	train-rmse:0.99444	valid-rmse:0.99872
[680]	train-rmse:0.99555	valid-rmse:0.99889
[560]	train-rmse:1.01478	valid-rmse:1.01813
[580]	train-rmse:0.99781	valid-rmse:1.00084
[460]	train-rmse:0.99811	valid-rmse:1.00114
[340]	train-rmse:1.00535	valid-rmse:1.00845
[700]	train-rmse:0.99545	valid-rmse:0.99884
[840]	train-rmse:0.99437	valid-rmse:0.99872
[580]	train-rmse:1.01367	valid-rmse:1.01698
[360]	train-rmse:1.00412	valid-rmse:1.00719
[600]	train-rmse:0.99752	valid-rmse:1.00056
[480]	train-rmse:0.99772	valid-rmse:1.00077
[720]	train-rmse:0.99535	valid-rmse:0.99880
[860]	train-rmse:0.99429	valid-rmse:0.99872
[600]	train-rmse:1.01262	valid-rmse:1.01589
[380]	train-rmse:1.00305	valid-rmse:1.00608
[500]	train-rmse:0.99739	valid-rmse:1.00047
[620]	train-rmse:0.99726	valid-rmse:1.00031
[740]	train-rmse:0.99527	valid-rmse:0.99877
[880]	train-rmse:0.99421	valid-rmse:0.99871
[400]	train-rmse:1.00213	valid-rmse:1.00513
[620]	train-rmse:1.01163	valid-rmse:1.01488
[760]	train-rmse:0.99518	valid-rmse:0.99874
[640]	train-rmse:0.99704	valid-rmse:1.00011
[520]	train-rmse:0.99710	valid-rmse:1.00023
[420]	train-rmse:1.00131	valid-rmse:1.00429
[900]	train-rmse:0.99413	valid-rmse:0.99871
[640]	train-rmse:1.01071	valid-rmse:1.01393
[780]	train-rmse:0.99511	valid-rmse:0.99871
[660]	train-rmse:0.99684	valid-rmse:0.99993
[540]	train-rmse:0.99685	valid-rmse:1.00001
[440]	train-rmse:1.00061	valid-rmse:1.00357
[920]	train-rmse:0.99405	valid-rmse:0.99871
[800]	train-rmse:0.99503	valid-rmse:0.99870
[660]	train-rmse:1.00984	valid-rmse:1.01303
[460]	train-rmse:0.99999	valid-rmse:1.00295
[680]	train-rmse:0.99665	valid-rmse:0.99977
[560]	train-rmse:0.99663	valid-rmse:0.99982
[820]	train-rmse:0.99495	valid-rmse:0.99868
[940]	train-rmse:0.99398	valid-rmse:0.99871
[480]	train-rmse:0.99945	valid-rmse:1.00241
[680]	train-rmse:1.00902	valid-rmse:1.01220
[700]	train-rmse:0.99649	valid-rmse:0.99962
[580]	train-rmse:0.99642	valid-rmse:0.99964
[840]	train-rmse:0.99488	valid-rmse:0.99868
[957]	train-rmse:0.99390	valid-rmse:0.99872
[32m[I 2022-04-15 08:51:16,564][0m Trial 64 finished with value: 0.998697 and parameters: {'colsample_bytree': 0.3187364442845215, 'eta': 0.005246391398429546, 'max_depth': 3, 'n_estimators': 866, 'subsample': 0.6018334036035815}. Best is trial 59 with value: 0.998688.[0m
[500]	train-rmse:0.99898	valid-rmse:1.00195
[08:51:21] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09883	valid-rmse:1.10373
[700]	train-rmse:1.00825	valid-rmse:1.01140
[720]	train-rmse:0.99633	valid-rmse:0.99950
[600]	train-rmse:0.99625	valid-rmse:0.99948
[860]	train-rmse:0.99481	valid-rmse:0.99867
[520]	train-rmse:0.99857	valid-rmse:1.00155
[20]	train-rmse:1.08438	valid-rmse:1.08908
[720]	train-rmse:1.00753	valid-rmse:1.01065
[740]	train-rmse:0.99620	valid-rmse:0.99941
[880]	train-rmse:0.99473	valid-rmse:0.99866
[620]	train-rmse:0.99609	valid-rmse:0.99935
[540]	train-rmse:0.99820	valid-rmse:1.00119
[40]	train-rmse:1.07190	valid-rmse:1.07642
[740]	train-rmse:1.00685	valid-rmse:1.00995
[900]	train-rmse:0.99466	valid-rmse:0.99865
[560]	train-rmse:0.99787	valid-rmse:1.00088
[760]	train-rmse:0.99607	valid-rmse:0.99931
[640]	train-rmse:0.99595	valid-rmse:0.99925
[580]	train-rmse:0.99758	valid-rmse:1.00060
[920]	train-rmse:0.99459	valid-rmse:0.99865
[60]	train-rmse:1.06117	valid-rmse:1.06551
[760]	train-rmse:1.00620	valid-rmse:1.00928
[780]	train-rmse:0.99595	valid-rmse:0.99923
[660]	train-rmse:0.99581	valid-rmse:0.99915
[600]	train-rmse:0.99733	valid-rmse:1.00034
[940]	train-rmse:0.99453	valid-rmse:0.99864
[80]	train-rmse:1.05195	valid-rmse:1.05614
[780]	train-rmse:1.00560	valid-rmse:1.00867
[800]	train-rmse:0.99585	valid-rmse:0.99916
[680]	train-rmse:0.99569	valid-rmse:0.99907
[620]	train-rmse:0.99709	valid-rmse:1.00013
[960]	train-rmse:0.99446	valid-rmse:0.99865
[100]	train-rmse:1.04400	valid-rmse:1.04802
[800]	train-rmse:1.00503	valid-rmse:1.00808
[820]	train-rmse:0.99574	valid-rmse:0.99909
[640]	train-rmse:0.99689	valid-rmse:0.99995
[700]	train-rmse:0.99558	valid-rmse:0.99899
[980]	train-rmse:0.99440	valid-rmse:0.99865
[120]	train-rmse:1.03719	valid-rmse:1.04107
[660]	train-rmse:0.99671	valid-rmse:0.99979
[820]	train-rmse:1.00450	valid-rmse:1.00753
[840]	train-rmse:0.99565	valid-rmse:0.99903
[999]	train-rmse:0.99433	valid-rmse:0.99865
[720]	train-rmse:0.99547	valid-rmse:0.99892
[32m[I 2022-04-15 08:54:23,754][0m Trial 65 finished with value: 0.998642 and parameters: {'colsample_bytree': 0.20679702129528355, 'eta': 0.004681900147299411, 'max_depth': 3, 'n_estimators': 931, 'subsample': 0.782589859331065}. Best is trial 65 with value: 0.998642.[0m
[08:54:28] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09935	valid-rmse:1.10426
[680]	train-rmse:0.99654	valid-rmse:0.99965
[140]	train-rmse:1.03131	valid-rmse:1.03508
[860]	train-rmse:0.99556	valid-rmse:0.99899
[840]	train-rmse:1.00399	valid-rmse:1.00701
[740]	train-rmse:0.99537	valid-rmse:0.99889
[20]	train-rmse:1.09443	valid-rmse:1.09927
[700]	train-rmse:0.99639	valid-rmse:0.99953
[160]	train-rmse:1.02628	valid-rmse:1.02994
[880]	train-rmse:0.99547	valid-rmse:0.99894
[860]	train-rmse:1.00352	valid-rmse:1.00652
[40]	train-rmse:1.08973	valid-rmse:1.09450
[760]	train-rmse:0.99528	valid-rmse:0.99884
[720]	train-rmse:0.99624	valid-rmse:0.99942
[180]	train-rmse:1.02196	valid-rmse:1.02550
[60]	train-rmse:1.08526	valid-rmse:1.08996
[900]	train-rmse:0.99539	valid-rmse:0.99891
[880]	train-rmse:1.00307	valid-rmse:1.00607
[780]	train-rmse:0.99519	valid-rmse:0.99881
[740]	train-rmse:0.99612	valid-rmse:0.99933
[80]	train-rmse:1.08100	valid-rmse:1.08564
[200]	train-rmse:1.01828	valid-rmse:1.02172
[760]	train-rmse:0.99600	valid-rmse:0.99924
[920]	train-rmse:0.99532	valid-rmse:0.99887
[900]	train-rmse:1.00265	valid-rmse:1.00564
[800]	train-rmse:0.99511	valid-rmse:0.99878
[100]	train-rmse:1.07693	valid-rmse:1.08150
[220]	train-rmse:1.01511	valid-rmse:1.01847
[780]	train-rmse:0.99590	valid-rmse:0.99917
[940]	train-rmse:0.99524	valid-rmse:0.99885
[920]	train-rmse:1.00225	valid-rmse:1.00523
[820]	train-rmse:0.99503	valid-rmse:0.99875
[120]	train-rmse:1.07306	valid-rmse:1.07756
[800]	train-rmse:0.99580	valid-rmse:0.99911
[240]	train-rmse:1.01240	valid-rmse:1.01569
[140]	train-rmse:1.06936	valid-rmse:1.07380
[960]	train-rmse:0.99517	valid-rmse:0.99883
[940]	train-rmse:1.00188	valid-rmse:1.00485
[840]	train-rmse:0.99495	valid-rmse:0.99872
[820]	train-rmse:0.99571	valid-rmse:0.99906
[260]	train-rmse:1.01006	valid-rmse:1.01329
[160]	train-rmse:1.06583	valid-rmse:1.07021
[980]	train-rmse:0.99510	valid-rmse:0.99881
[960]	train-rmse:1.00152	valid-rmse:1.00449
[860]	train-rmse:0.99487	valid-rmse:0.99871
[840]	train-rmse:0.99562	valid-rmse:0.99901
[180]	train-rmse:1.06247	valid-rmse:1.06679
[280]	train-rmse:1.00806	valid-rmse:1.01123
[999]	train-rmse:0.99503	valid-rmse:0.99879
[32m[I 2022-04-15 08:58:05,224][0m Trial 67 finished with value: 0.998791 and parameters: {'colsample_bytree': 0.31605788601220797, 'eta': 0.0035666416508123317, 'max_depth': 3, 'n_estimators': 949, 'subsample': 0.5853745289696385}. Best is trial 65 with value: 0.998642.[0m
[980]	train-rmse:1.00119	valid-rmse:1.00415
[860]	train-rmse:0.99554	valid-rmse:0.99897
[880]	train-rmse:0.99480	valid-rmse:0.99870
[08:58:10] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09936	valid-rmse:1.10426
[200]	train-rmse:1.05928	valid-rmse:1.06355
[300]	train-rmse:1.00633	valid-rmse:1.00946
[880]	train-rmse:0.99546	valid-rmse:0.99894
[999]	train-rmse:1.00089	valid-rmse:1.00385
[32m[I 2022-04-15 08:58:34,015][0m Trial 66 finished with value: 1.003848 and parameters: {'colsample_bytree': 0.32592562745518877, 'eta': 0.0015978716060074062, 'max_depth': 3, 'n_estimators': 951, 'subsample': 0.596716465410792}. Best is trial 65 with value: 0.998642.[0m
[20]	train-rmse:1.09452	valid-rmse:1.09936
[900]	train-rmse:0.99472	valid-rmse:0.99870
[08:58:39] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[220]	train-rmse:1.05623	valid-rmse:1.06045
[0]	train-rmse:1.09939	valid-rmse:1.10430
[900]	train-rmse:0.99538	valid-rmse:0.99889
[320]	train-rmse:1.00487	valid-rmse:1.00797
[40]	train-rmse:1.08990	valid-rmse:1.09467
[240]	train-rmse:1.05333	valid-rmse:1.05750
[920]	train-rmse:0.99466	valid-rmse:0.99869
[20]	train-rmse:1.09527	valid-rmse:1.10013
[920]	train-rmse:0.99531	valid-rmse:0.99886
[60]	train-rmse:1.08549	valid-rmse:1.09018
[340]	train-rmse:1.00361	valid-rmse:1.00667
[260]	train-rmse:1.05057	valid-rmse:1.05468
[40]	train-rmse:1.09131	valid-rmse:1.09611
[940]	train-rmse:0.99459	valid-rmse:0.99868
[940]	train-rmse:0.99524	valid-rmse:0.99884
[80]	train-rmse:1.08130	valid-rmse:1.08593
[280]	train-rmse:1.04793	valid-rmse:1.05200
[60]	train-rmse:1.08750	valid-rmse:1.09223
[360]	train-rmse:1.00252	valid-rmse:1.00557
[960]	train-rmse:0.99517	valid-rmse:0.99882
[960]	train-rmse:0.99452	valid-rmse:0.99868
[100]	train-rmse:1.07728	valid-rmse:1.08185
[300]	train-rmse:1.04542	valid-rmse:1.04944
[80]	train-rmse:1.08385	valid-rmse:1.08852
[380]	train-rmse:1.00157	valid-rmse:1.00460
[980]	train-rmse:0.99510	valid-rmse:0.99881
[120]	train-rmse:1.07346	valid-rmse:1.07797
[980]	train-rmse:0.99445	valid-rmse:0.99867
[100]	train-rmse:1.08033	valid-rmse:1.08495
[320]	train-rmse:1.04304	valid-rmse:1.04702
[999]	train-rmse:0.99504	valid-rmse:0.99881
[32m[I 2022-04-15 09:00:44,182][0m Trial 69 finished with value: 0.9988 and parameters: {'colsample_bytree': 0.21714574972489878, 'eta': 0.003704052659432432, 'max_depth': 3, 'n_estimators': 889, 'subsample': 0.5958120332543841}. Best is trial 65 with value: 0.998642.[0m
[400]	train-rmse:1.00078	valid-rmse:1.00377
[140]	train-rmse:1.06980	valid-rmse:1.07425
[09:00:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[120]	train-rmse:1.07695	valid-rmse:1.08152
[340]	train-rmse:1.04077	valid-rmse:1.04471
[0]	train-rmse:1.09939	valid-rmse:1.10430
[999]	train-rmse:0.99438	valid-rmse:0.99866
[32m[I 2022-04-15 09:00:56,894][0m Trial 68 finished with value: 0.998656 and parameters: {'colsample_bytree': 0.32120871842765425, 'eta': 0.004342026204849998, 'max_depth': 3, 'n_estimators': 952, 'subsample': 0.5849107521365405}. Best is trial 65 with value: 0.998642.[0m
[09:01:01] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09935	valid-rmse:1.10426
[160]	train-rmse:1.06632	valid-rmse:1.07071
[140]	train-rmse:1.07370	valid-rmse:1.07821
[420]	train-rmse:1.00007	valid-rmse:1.00305
[360]	train-rmse:1.03861	valid-rmse:1.04250
[20]	train-rmse:1.09527	valid-rmse:1.10013
[20]	train-rmse:1.09437	valid-rmse:1.09921
[180]	train-rmse:1.06299	valid-rmse:1.06733
[160]	train-rmse:1.07058	valid-rmse:1.07504
[380]	train-rmse:1.03655	valid-rmse:1.04039
[40]	train-rmse:1.09131	valid-rmse:1.09611
[440]	train-rmse:0.99947	valid-rmse:1.00243
[40]	train-rmse:1.08962	valid-rmse:1.09439
[200]	train-rmse:1.05983	valid-rmse:1.06411
[180]	train-rmse:1.06758	valid-rmse:1.07199
[400]	train-rmse:1.03459	valid-rmse:1.03839
[60]	train-rmse:1.08750	valid-rmse:1.09222
[460]	train-rmse:0.99894	valid-rmse:1.00191
[220]	train-rmse:1.05681	valid-rmse:1.06104
[60]	train-rmse:1.08510	valid-rmse:1.08979
[200]	train-rmse:1.06470	valid-rmse:1.06907
[420]	train-rmse:1.03273	valid-rmse:1.03649
[80]	train-rmse:1.08385	valid-rmse:1.08852
[480]	train-rmse:0.99849	valid-rmse:1.00146
[240]	train-rmse:1.05393	valid-rmse:1.05811
[80]	train-rmse:1.08080	valid-rmse:1.08543
[220]	train-rmse:1.06193	valid-rmse:1.06625
[440]	train-rmse:1.03096	valid-rmse:1.03468
[100]	train-rmse:1.08033	valid-rmse:1.08494
[260]	train-rmse:1.05119	valid-rmse:1.05532
[100]	train-rmse:1.07669	valid-rmse:1.08125
[240]	train-rmse:1.05928	valid-rmse:1.06356
[500]	train-rmse:0.99809	valid-rmse:1.00107
[460]	train-rmse:1.02928	valid-rmse:1.03295
[120]	train-rmse:1.07695	valid-rmse:1.08152
[280]	train-rmse:1.04857	valid-rmse:1.05266
[120]	train-rmse:1.07278	valid-rmse:1.07729
[260]	train-rmse:1.05673	valid-rmse:1.06097
[520]	train-rmse:0.99775	valid-rmse:1.00076
[480]	train-rmse:1.02767	valid-rmse:1.03130
[140]	train-rmse:1.07370	valid-rmse:1.07821
[300]	train-rmse:1.04607	valid-rmse:1.05011
[140]	train-rmse:1.06905	valid-rmse:1.07349
[280]	train-rmse:1.05428	valid-rmse:1.05848
[500]	train-rmse:1.02614	valid-rmse:1.02974
[160]	train-rmse:1.07058	valid-rmse:1.07503
[540]	train-rmse:0.99743	valid-rmse:1.00046
[320]	train-rmse:1.04370	valid-rmse:1.04770
[160]	train-rmse:1.06550	valid-rmse:1.06988
[300]	train-rmse:1.05191	valid-rmse:1.05607
[520]	train-rmse:1.02469	valid-rmse:1.02826
[180]	train-rmse:1.06758	valid-rmse:1.07198
[560]	train-rmse:0.99717	valid-rmse:1.00022
[340]	train-rmse:1.04144	valid-rmse:1.04539
[320]	train-rmse:1.04967	valid-rmse:1.05378
[180]	train-rmse:1.06212	valid-rmse:1.06644
[540]	train-rmse:1.02330	valid-rmse:1.02684
[200]	train-rmse:1.06470	valid-rmse:1.06906
[360]	train-rmse:1.03928	valid-rmse:1.04319
[340]	train-rmse:1.04750	valid-rmse:1.05157
[580]	train-rmse:0.99693	valid-rmse:1.00000
[200]	train-rmse:1.05890	valid-rmse:1.06318
[560]	train-rmse:1.02199	valid-rmse:1.02550
[220]	train-rmse:1.06193	valid-rmse:1.06624
[380]	train-rmse:1.03723	valid-rmse:1.04109
[360]	train-rmse:1.04542	valid-rmse:1.04945
[220]	train-rmse:1.05584	valid-rmse:1.06006
[600]	train-rmse:0.99671	valid-rmse:0.99980
[580]	train-rmse:1.02073	valid-rmse:1.02421
[240]	train-rmse:1.05927	valid-rmse:1.06355
[400]	train-rmse:1.03528	valid-rmse:1.03910
[380]	train-rmse:1.04342	valid-rmse:1.04740
[240]	train-rmse:1.05292	valid-rmse:1.05710
[600]	train-rmse:1.01954	valid-rmse:1.02297
[260]	train-rmse:1.05672	valid-rmse:1.06095
[620]	train-rmse:0.99652	valid-rmse:0.99964
[420]	train-rmse:1.03341	valid-rmse:1.03719
[400]	train-rmse:1.04151	valid-rmse:1.04546
[260]	train-rmse:1.05014	valid-rmse:1.05427
[620]	train-rmse:1.01840	valid-rmse:1.02180
[280]	train-rmse:1.05427	valid-rmse:1.05846
[440]	train-rmse:1.03164	valid-rmse:1.03538
[640]	train-rmse:0.99635	valid-rmse:0.99950
[420]	train-rmse:1.03967	valid-rmse:1.04357
[280]	train-rmse:1.04750	valid-rmse:1.05159
[300]	train-rmse:1.05191	valid-rmse:1.05606
[640]	train-rmse:1.01733	valid-rmse:1.02070
[460]	train-rmse:1.02995	valid-rmse:1.03365
[440]	train-rmse:1.03791	valid-rmse:1.04178
[660]	train-rmse:0.99619	valid-rmse:0.99939
[300]	train-rmse:1.04497	valid-rmse:1.04901
[320]	train-rmse:1.04966	valid-rmse:1.05377
[660]	train-rmse:1.01629	valid-rmse:1.01964
[480]	train-rmse:1.02834	valid-rmse:1.03200
[460]	train-rmse:1.03622	valid-rmse:1.04005
[320]	train-rmse:1.04259	valid-rmse:1.04658
[680]	train-rmse:0.99605	valid-rmse:0.99930
[340]	train-rmse:1.04750	valid-rmse:1.05156
[680]	train-rmse:1.01532	valid-rmse:1.01863
[500]	train-rmse:1.02680	valid-rmse:1.03043
[480]	train-rmse:1.03459	valid-rmse:1.03838
[340]	train-rmse:1.04032	valid-rmse:1.04426
[700]	train-rmse:1.01439	valid-rmse:1.01767
[360]	train-rmse:1.04541	valid-rmse:1.04944
[700]	train-rmse:0.99592	valid-rmse:0.99920
[520]	train-rmse:1.02535	valid-rmse:1.02894
[500]	train-rmse:1.03303	valid-rmse:1.03679
[360]	train-rmse:1.03815	valid-rmse:1.04205
[380]	train-rmse:1.04341	valid-rmse:1.04740
[720]	train-rmse:1.01351	valid-rmse:1.01676
[540]	train-rmse:1.02395	valid-rmse:1.02752
[720]	train-rmse:0.99579	valid-rmse:0.99913
[520]	train-rmse:1.03154	valid-rmse:1.03527
[380]	train-rmse:1.03609	valid-rmse:1.03995
[400]	train-rmse:1.04151	valid-rmse:1.04546
[740]	train-rmse:1.01267	valid-rmse:1.01590
[560]	train-rmse:1.02263	valid-rmse:1.02617
[540]	train-rmse:1.03010	valid-rmse:1.03380
[740]	train-rmse:0.99569	valid-rmse:0.99906
[400]	train-rmse:1.03414	valid-rmse:1.03795
[420]	train-rmse:1.03966	valid-rmse:1.04357
[760]	train-rmse:1.01187	valid-rmse:1.01508
[580]	train-rmse:1.02137	valid-rmse:1.02486
[560]	train-rmse:1.02873	valid-rmse:1.03240
[420]	train-rmse:1.03227	valid-rmse:1.03604
[760]	train-rmse:0.99558	valid-rmse:0.99901
[780]	train-rmse:1.01111	valid-rmse:1.01430
[440]	train-rmse:1.03790	valid-rmse:1.04178
[600]	train-rmse:1.02016	valid-rmse:1.02362
[580]	train-rmse:1.02740	valid-rmse:1.03103
[440]	train-rmse:1.03051	valid-rmse:1.03423
[800]	train-rmse:1.01038	valid-rmse:1.01355
[460]	train-rmse:1.03621	valid-rmse:1.04005
[620]	train-rmse:1.01902	valid-rmse:1.02244
[780]	train-rmse:0.99550	valid-rmse:0.99896
[600]	train-rmse:1.02613	valid-rmse:1.02972
[460]	train-rmse:1.02882	valid-rmse:1.03251
[820]	train-rmse:1.00969	valid-rmse:1.01284
[640]	train-rmse:1.01793	valid-rmse:1.02133
[480]	train-rmse:1.03458	valid-rmse:1.03838
[800]	train-rmse:0.99541	valid-rmse:0.99892
[620]	train-rmse:1.02491	valid-rmse:1.02846
[480]	train-rmse:1.02722	valid-rmse:1.03086
[660]	train-rmse:1.01689	valid-rmse:1.02025
[840]	train-rmse:1.00903	valid-rmse:1.01216
[500]	train-rmse:1.03302	valid-rmse:1.03680
[640]	train-rmse:1.02374	valid-rmse:1.02727
[820]	train-rmse:0.99532	valid-rmse:0.99888
[500]	train-rmse:1.02569	valid-rmse:1.02931
[860]	train-rmse:1.00841	valid-rmse:1.01151
[680]	train-rmse:1.01591	valid-rmse:1.01923
[520]	train-rmse:1.03153	valid-rmse:1.03527
[660]	train-rmse:1.02262	valid-rmse:1.02612
[520]	train-rmse:1.02425	valid-rmse:1.02783
[840]	train-rmse:0.99524	valid-rmse:0.99884
[700]	train-rmse:1.01496	valid-rmse:1.01826
[880]	train-rmse:1.00782	valid-rmse:1.01091
[540]	train-rmse:1.03009	valid-rmse:1.03381
[680]	train-rmse:1.02155	valid-rmse:1.02501
[540]	train-rmse:1.02287	valid-rmse:1.02642
[720]	train-rmse:1.01407	valid-rmse:1.01734
[900]	train-rmse:1.00725	valid-rmse:1.01032
[560]	train-rmse:1.02872	valid-rmse:1.03240
[860]	train-rmse:0.99516	valid-rmse:0.99882
[700]	train-rmse:1.02052	valid-rmse:1.02395
[560]	train-rmse:1.02156	valid-rmse:1.02508
[740]	train-rmse:1.01321	valid-rmse:1.01647
[920]	train-rmse:1.00671	valid-rmse:1.00976
[580]	train-rmse:1.02740	valid-rmse:1.03104
[720]	train-rmse:1.01953	valid-rmse:1.02294
[880]	train-rmse:0.99508	valid-rmse:0.99879
[580]	train-rmse:1.02031	valid-rmse:1.02379
[760]	train-rmse:1.01240	valid-rmse:1.01562
[940]	train-rmse:1.00619	valid-rmse:1.00924
[600]	train-rmse:1.02612	valid-rmse:1.02973
[740]	train-rmse:1.01858	valid-rmse:1.02197
[900]	train-rmse:0.99500	valid-rmse:0.99878
[600]	train-rmse:1.01912	valid-rmse:1.02257
[780]	train-rmse:1.01163	valid-rmse:1.01483
[960]	train-rmse:1.00571	valid-rmse:1.00874
[760]	train-rmse:1.01767	valid-rmse:1.02103
[620]	train-rmse:1.02490	valid-rmse:1.02848
[620]	train-rmse:1.01799	valid-rmse:1.02140
[800]	train-rmse:1.01089	valid-rmse:1.01407
[920]	train-rmse:0.99493	valid-rmse:0.99877
[980]	train-rmse:1.00524	valid-rmse:1.00826
[780]	train-rmse:1.01680	valid-rmse:1.02013
[640]	train-rmse:1.02374	valid-rmse:1.02729
[640]	train-rmse:1.01693	valid-rmse:1.02031
[820]	train-rmse:1.01019	valid-rmse:1.01335
[999]	train-rmse:1.00482	valid-rmse:1.00782
[800]	train-rmse:1.01596	valid-rmse:1.01927
[32m[I 2022-04-15 09:13:27,968][0m Trial 71 finished with value: 1.007825 and parameters: {'colsample_bytree': 0.21716538086435988, 'eta': 0.0012966787432572163, 'max_depth': 3, 'n_estimators': 1002, 'subsample': 0.5840672391662249}. Best is trial 65 with value: 0.998642.[0m
[660]	train-rmse:1.02262	valid-rmse:1.02613
[940]	train-rmse:0.99486	valid-rmse:0.99876
[09:13:33] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09788	valid-rmse:1.10277
[660]	train-rmse:1.01590	valid-rmse:1.01925
[840]	train-rmse:1.00952	valid-rmse:1.01266
[820]	train-rmse:1.01516	valid-rmse:1.01845
[680]	train-rmse:1.02154	valid-rmse:1.02503
[20]	train-rmse:1.06852	valid-rmse:1.07298
[960]	train-rmse:0.99479	valid-rmse:0.99875
[680]	train-rmse:1.01494	valid-rmse:1.01825
[860]	train-rmse:1.00888	valid-rmse:1.01200
[840]	train-rmse:1.01438	valid-rmse:1.01765
[700]	train-rmse:1.02051	valid-rmse:1.02396
[40]	train-rmse:1.04747	valid-rmse:1.05160
[980]	train-rmse:0.99473	valid-rmse:0.99874
[700]	train-rmse:1.01401	valid-rmse:1.01730
[880]	train-rmse:1.00828	valid-rmse:1.01138
[860]	train-rmse:1.01364	valid-rmse:1.01690
[720]	train-rmse:1.01952	valid-rmse:1.02295
[60]	train-rmse:1.03251	valid-rmse:1.03630
[900]	train-rmse:1.00770	valid-rmse:1.01079
[720]	train-rmse:1.01313	valid-rmse:1.01640
[880]	train-rmse:1.01294	valid-rmse:1.01617
[999]	train-rmse:0.99466	valid-rmse:0.99873
[32m[I 2022-04-15 09:14:56,006][0m Trial 70 finished with value: 0.998729 and parameters: {'colsample_bytree': 0.3090530210611952, 'eta': 0.004009623307253773, 'max_depth': 3, 'n_estimators': 1004, 'subsample': 0.5987933657450584}. Best is trial 65 with value: 0.998642.[0m
[740]	train-rmse:1.01857	valid-rmse:1.02197
[09:15:00] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09920	valid-rmse:1.10411
[80]	train-rmse:1.02192	valid-rmse:1.02551
[920]	train-rmse:1.00714	valid-rmse:1.01022
[740]	train-rmse:1.01230	valid-rmse:1.01554
[900]	train-rmse:1.01225	valid-rmse:1.01547
[760]	train-rmse:1.01766	valid-rmse:1.02103
[100]	train-rmse:1.01439	valid-rmse:1.01778
[20]	train-rmse:1.09147	valid-rmse:1.09628
[940]	train-rmse:1.00662	valid-rmse:1.00968
[920]	train-rmse:1.01160	valid-rmse:1.01479
[760]	train-rmse:1.01151	valid-rmse:1.01472
[780]	train-rmse:1.01679	valid-rmse:1.02014
[120]	train-rmse:1.00909	valid-rmse:1.01235
[40]	train-rmse:1.08430	valid-rmse:1.08901
[960]	train-rmse:1.00612	valid-rmse:1.00917
[940]	train-rmse:1.01097	valid-rmse:1.01415
[780]	train-rmse:1.01076	valid-rmse:1.01395
[800]	train-rmse:1.01595	valid-rmse:1.01928
[140]	train-rmse:1.00527	valid-rmse:1.00842
[60]	train-rmse:1.07766	valid-rmse:1.08225
[980]	train-rmse:1.00564	valid-rmse:1.00868
[960]	train-rmse:1.01037	valid-rmse:1.01353
[800]	train-rmse:1.01004	valid-rmse:1.01321
[820]	train-rmse:1.01515	valid-rmse:1.01846
[160]	train-rmse:1.00259	valid-rmse:1.00569
[80]	train-rmse:1.07152	valid-rmse:1.07603
[999]	train-rmse:1.00521	valid-rmse:1.00824
[32m[I 2022-04-15 09:16:40,150][0m Trial 72 finished with value: 1.008236 and parameters: {'colsample_bytree': 0.21705981733222637, 'eta': 0.001274035826727054, 'max_depth': 3, 'n_estimators': 885, 'subsample': 0.5496601838010127}. Best is trial 65 with value: 0.998642.[0m
[980]	train-rmse:1.00979	valid-rmse:1.01294
[820]	train-rmse:1.00936	valid-rmse:1.01252
[09:16:44] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09913	valid-rmse:1.10403
[840]	train-rmse:1.01438	valid-rmse:1.01766
[180]	train-rmse:1.00065	valid-rmse:1.00371
[100]	train-rmse:1.06582	valid-rmse:1.07023
[999]	train-rmse:1.00926	valid-rmse:1.01240
[32m[I 2022-04-15 09:17:05,637][0m Trial 73 finished with value: 1.012398 and parameters: {'colsample_bytree': 0.2186712207981328, 'eta': 0.0010814589697468264, 'max_depth': 3, 'n_estimators': 1005, 'subsample': 0.5473712250290337}. Best is trial 65 with value: 0.998642.[0m
[840]	train-rmse:1.00871	valid-rmse:1.01185
[09:17:10] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09912	valid-rmse:1.10403
[860]	train-rmse:1.01364	valid-rmse:1.01690
[200]	train-rmse:0.99927	valid-rmse:1.00232
[120]	train-rmse:1.06055	valid-rmse:1.06487
[20]	train-rmse:1.08994	valid-rmse:1.09473
[860]	train-rmse:1.00809	valid-rmse:1.01121
[880]	train-rmse:1.01293	valid-rmse:1.01618
[220]	train-rmse:0.99826	valid-rmse:1.00129
[20]	train-rmse:1.08983	valid-rmse:1.09459
[140]	train-rmse:1.05566	valid-rmse:1.05989
[880]	train-rmse:1.00751	valid-rmse:1.01062
[40]	train-rmse:1.08154	valid-rmse:1.08620
[900]	train-rmse:1.01225	valid-rmse:1.01548
[240]	train-rmse:0.99751	valid-rmse:1.00057
[160]	train-rmse:1.05114	valid-rmse:1.05529
[40]	train-rmse:1.08133	valid-rmse:1.08596
[900]	train-rmse:1.00695	valid-rmse:1.01004
[920]	train-rmse:1.01159	valid-rmse:1.01480
[260]	train-rmse:0.99694	valid-rmse:1.00006
[60]	train-rmse:1.07389	valid-rmse:1.07843
[180]	train-rmse:1.04695	valid-rmse:1.05102
[60]	train-rmse:1.07360	valid-rmse:1.07810
[920]	train-rmse:1.00642	valid-rmse:1.00950
[940]	train-rmse:1.01096	valid-rmse:1.01416
[280]	train-rmse:0.99651	valid-rmse:0.99967
[200]	train-rmse:1.04309	valid-rmse:1.04708
[80]	train-rmse:1.06691	valid-rmse:1.07135
[940]	train-rmse:1.00591	valid-rmse:1.00897
[80]	train-rmse:1.06658	valid-rmse:1.07096
[960]	train-rmse:1.01036	valid-rmse:1.01354
[300]	train-rmse:0.99617	valid-rmse:0.99938
[220]	train-rmse:1.03951	valid-rmse:1.04343
[960]	train-rmse:1.00543	valid-rmse:1.00848
[100]	train-rmse:1.06054	valid-rmse:1.06487
[980]	train-rmse:1.00978	valid-rmse:1.01295
[320]	train-rmse:0.99591	valid-rmse:0.99919
[100]	train-rmse:1.06016	valid-rmse:1.06443
[240]	train-rmse:1.03621	valid-rmse:1.04007
[980]	train-rmse:1.00497	valid-rmse:1.00801
[999]	train-rmse:1.00926	valid-rmse:1.01240
[32m[I 2022-04-15 09:19:53,952][0m Trial 74 finished with value: 1.012404 and parameters: {'colsample_bytree': 0.23087423486579287, 'eta': 0.0010814423450732618, 'max_depth': 3, 'n_estimators': 833, 'subsample': 0.5477947207020273}. Best is trial 65 with value: 0.998642.[0m
[340]	train-rmse:0.99568	valid-rmse:0.99906
[09:19:58] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[260]	train-rmse:1.03316	valid-rmse:1.03695
[120]	train-rmse:1.05474	valid-rmse:1.05898
[120]	train-rmse:1.05432	valid-rmse:1.05849
[0]	train-rmse:1.09188	valid-rmse:1.09671
[999]	train-rmse:1.00456	valid-rmse:1.00758
[32m[I 2022-04-15 09:20:11,382][0m Trial 75 finished with value: 1.007583 and parameters: {'colsample_bytree': 0.2322129383642631, 'eta': 0.0013121608184514014, 'max_depth': 3, 'n_estimators': 1005, 'subsample': 0.5532722495539474}. Best is trial 65 with value: 0.998642.[0m
[09:20:15] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[360]	train-rmse:0.99547	valid-rmse:0.99898
[0]	train-rmse:1.09913	valid-rmse:1.10404
[280]	train-rmse:1.03033	valid-rmse:1.03407
[20]	train-rmse:1.01589	valid-rmse:1.01913
[140]	train-rmse:1.04899	valid-rmse:1.05308
[140]	train-rmse:1.04944	valid-rmse:1.05358
[380]	train-rmse:0.99528	valid-rmse:0.99891
[300]	train-rmse:1.02771	valid-rmse:1.03138
[40]	train-rmse:1.00017	valid-rmse:1.00315
[20]	train-rmse:1.09008	valid-rmse:1.09487
[160]	train-rmse:1.04415	valid-rmse:1.04814
[400]	train-rmse:0.99512	valid-rmse:0.99885
[320]	train-rmse:1.02531	valid-rmse:1.02893
[160]	train-rmse:1.04462	valid-rmse:1.04866
[60]	train-rmse:0.99669	valid-rmse:0.99991
[420]	train-rmse:0.99496	valid-rmse:0.99880
[40]	train-rmse:1.08179	valid-rmse:1.08645
[180]	train-rmse:1.03975	valid-rmse:1.04364
[340]	train-rmse:1.02309	valid-rmse:1.02665
[80]	train-rmse:0.99549	valid-rmse:0.99924
[180]	train-rmse:1.04022	valid-rmse:1.04417
[440]	train-rmse:0.99482	valid-rmse:0.99878
[360]	train-rmse:1.02103	valid-rmse:1.02455
[100]	train-rmse:0.99475	valid-rmse:0.99914
[200]	train-rmse:1.03575	valid-rmse:1.03958
[60]	train-rmse:1.07424	valid-rmse:1.07876
[460]	train-rmse:0.99469	valid-rmse:0.99878
[200]	train-rmse:1.03623	valid-rmse:1.04010
[380]	train-rmse:1.01913	valid-rmse:1.02259
[120]	train-rmse:0.99414	valid-rmse:0.99919
[220]	train-rmse:1.03211	valid-rmse:1.03587
[80]	train-rmse:1.06733	valid-rmse:1.07174
[480]	train-rmse:0.99455	valid-rmse:0.99876
[400]	train-rmse:1.01739	valid-rmse:1.02079
[140]	train-rmse:0.99355	valid-rmse:0.99920
[143]	train-rmse:0.99347	valid-rmse:0.99924
[32m[I 2022-04-15 09:22:44,775][0m Trial 80 finished with value: 0.999097 and parameters: {'colsample_bytree': 0.2505630894610299, 'eta': 0.04060951737429295, 'max_depth': 3, 'n_estimators': 1023, 'subsample': 0.5038036780125158}. Best is trial 65 with value: 0.998642.[0m
[220]	train-rmse:1.03259	valid-rmse:1.03639
[09:22:49] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[240]	train-rmse:1.02881	valid-rmse:1.03251
[0]	train-rmse:1.09910	valid-rmse:1.10400
[420]	train-rmse:1.01577	valid-rmse:1.01913
[500]	train-rmse:0.99442	valid-rmse:0.99873
[100]	train-rmse:1.06103	valid-rmse:1.06532
[240]	train-rmse:1.02929	valid-rmse:1.03302
[440]	train-rmse:1.01428	valid-rmse:1.01760
[260]	train-rmse:1.02581	valid-rmse:1.02943
[520]	train-rmse:0.99429	valid-rmse:0.99875
[20]	train-rmse:1.08946	valid-rmse:1.09423
[120]	train-rmse:1.05528	valid-rmse:1.05948
[460]	train-rmse:1.01290	valid-rmse:1.01619
[540]	train-rmse:0.99416	valid-rmse:0.99880
[280]	train-rmse:1.02308	valid-rmse:1.02664
[260]	train-rmse:1.02627	valid-rmse:1.02994
[550]	train-rmse:0.99410	valid-rmse:0.99880
[32m[I 2022-04-15 09:23:57,721][0m Trial 76 finished with value: 0.99873 and parameters: {'colsample_bytree': 0.24079233165085817, 'eta': 0.008965247747586374, 'max_depth': 3, 'n_estimators': 998, 'subsample': 0.5436841633844631}. Best is trial 65 with value: 0.998642.[0m
[40]	train-rmse:1.08068	valid-rmse:1.08532
[09:24:02] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[480]	train-rmse:1.01162	valid-rmse:1.01487
[140]	train-rmse:1.05000	valid-rmse:1.05411
[0]	train-rmse:1.09908	valid-rmse:1.10398
[300]	train-rmse:1.02059	valid-rmse:1.02410
[280]	train-rmse:1.02354	valid-rmse:1.02715
[500]	train-rmse:1.01044	valid-rmse:1.01365
[60]	train-rmse:1.07272	valid-rmse:1.07723
[20]	train-rmse:1.08903	valid-rmse:1.09381
[160]	train-rmse:1.04520	valid-rmse:1.04922
[320]	train-rmse:1.01835	valid-rmse:1.02181
[520]	train-rmse:1.00935	valid-rmse:1.01255
[300]	train-rmse:1.02104	valid-rmse:1.02458
[80]	train-rmse:1.06550	valid-rmse:1.06988
[40]	train-rmse:1.07993	valid-rmse:1.08456
[180]	train-rmse:1.04082	valid-rmse:1.04474
[540]	train-rmse:1.00834	valid-rmse:1.01151
[340]	train-rmse:1.01632	valid-rmse:1.01972
[320]	train-rmse:1.01878	valid-rmse:1.02227
[100]	train-rmse:1.05894	valid-rmse:1.06320
[560]	train-rmse:1.00742	valid-rmse:1.01056
[360]	train-rmse:1.01446	valid-rmse:1.01782
[60]	train-rmse:1.07171	valid-rmse:1.07621
[200]	train-rmse:1.03684	valid-rmse:1.04069
[580]	train-rmse:1.00656	valid-rmse:1.00967
[340]	train-rmse:1.01672	valid-rmse:1.02016
[120]	train-rmse:1.05300	valid-rmse:1.05716
[380]	train-rmse:1.01277	valid-rmse:1.01608
[80]	train-rmse:1.06428	valid-rmse:1.06866
[220]	train-rmse:1.03320	valid-rmse:1.03698
[600]	train-rmse:1.00575	valid-rmse:1.00883
[360]	train-rmse:1.01485	valid-rmse:1.01824
[140]	train-rmse:1.04759	valid-rmse:1.05167
[400]	train-rmse:1.01126	valid-rmse:1.01451
[620]	train-rmse:1.00501	valid-rmse:1.00806
[100]	train-rmse:1.05757	valid-rmse:1.06182
[240]	train-rmse:1.02989	valid-rmse:1.03361
[640]	train-rmse:1.00434	valid-rmse:1.00737
[380]	train-rmse:1.01314	valid-rmse:1.01647
[420]	train-rmse:1.00985	valid-rmse:1.01307
[160]	train-rmse:1.04270	valid-rmse:1.04668
[120]	train-rmse:1.05151	valid-rmse:1.05567
[260]	train-rmse:1.02687	valid-rmse:1.03053
[660]	train-rmse:1.00371	valid-rmse:1.00671
[440]	train-rmse:1.00860	valid-rmse:1.01179
[400]	train-rmse:1.01160	valid-rmse:1.01488
[180]	train-rmse:1.03826	valid-rmse:1.04215
[140]	train-rmse:1.04602	valid-rmse:1.05008
[680]	train-rmse:1.00313	valid-rmse:1.00612
[280]	train-rmse:1.02412	valid-rmse:1.02772
[460]	train-rmse:1.00746	valid-rmse:1.01061
[420]	train-rmse:1.01019	valid-rmse:1.01343
[200]	train-rmse:1.03426	valid-rmse:1.03807
[700]	train-rmse:1.00259	valid-rmse:1.00557
[160]	train-rmse:1.04108	valid-rmse:1.04504
[300]	train-rmse:1.02161	valid-rmse:1.02514
[480]	train-rmse:1.00641	valid-rmse:1.00953
[720]	train-rmse:1.00209	valid-rmse:1.00506
[440]	train-rmse:1.00891	valid-rmse:1.01211
[220]	train-rmse:1.03063	valid-rmse:1.03437
[180]	train-rmse:1.03662	valid-rmse:1.04048
[740]	train-rmse:1.00163	valid-rmse:1.00459
[320]	train-rmse:1.01934	valid-rmse:1.02282
[500]	train-rmse:1.00546	valid-rmse:1.00856
[460]	train-rmse:1.00774	valid-rmse:1.01092
[240]	train-rmse:1.02734	valid-rmse:1.03103
[760]	train-rmse:1.00120	valid-rmse:1.00414
[200]	train-rmse:1.03261	valid-rmse:1.03638
[520]	train-rmse:1.00460	valid-rmse:1.00769
[340]	train-rmse:1.01726	valid-rmse:1.02069
[780]	train-rmse:1.00081	valid-rmse:1.00374
[480]	train-rmse:1.00668	valid-rmse:1.00982
[260]	train-rmse:1.02436	valid-rmse:1.02798
[220]	train-rmse:1.02899	valid-rmse:1.03269
[540]	train-rmse:1.00381	valid-rmse:1.00690
[360]	train-rmse:1.01537	valid-rmse:1.01875
[800]	train-rmse:1.00044	valid-rmse:1.00337
[500]	train-rmse:1.00572	valid-rmse:1.00884
[280]	train-rmse:1.02167	valid-rmse:1.02523
[560]	train-rmse:1.00310	valid-rmse:1.00617
[820]	train-rmse:1.00010	valid-rmse:1.00302
[240]	train-rmse:1.02573	valid-rmse:1.02936
[380]	train-rmse:1.01364	valid-rmse:1.01696
[840]	train-rmse:0.99978	valid-rmse:1.00270
[520]	train-rmse:1.00484	valid-rmse:1.00794
[300]	train-rmse:1.01922	valid-rmse:1.02272
[580]	train-rmse:1.00245	valid-rmse:1.00549
[260]	train-rmse:1.02278	valid-rmse:1.02636
[400]	train-rmse:1.01207	valid-rmse:1.01536
[860]	train-rmse:0.99949	valid-rmse:1.00240
[540]	train-rmse:1.00404	valid-rmse:1.00712
[320]	train-rmse:1.01703	valid-rmse:1.02048
[600]	train-rmse:1.00185	valid-rmse:1.00487
[280]	train-rmse:1.02013	valid-rmse:1.02365
[880]	train-rmse:0.99921	valid-rmse:1.00213
[420]	train-rmse:1.01064	valid-rmse:1.01389
[560]	train-rmse:1.00331	valid-rmse:1.00638
[620]	train-rmse:1.00131	valid-rmse:1.00432
[340]	train-rmse:1.01504	valid-rmse:1.01843
[900]	train-rmse:0.99896	valid-rmse:1.00188
[300]	train-rmse:1.01774	valid-rmse:1.02120
[440]	train-rmse:1.00934	valid-rmse:1.01255
[640]	train-rmse:1.00082	valid-rmse:1.00382
[920]	train-rmse:0.99872	valid-rmse:1.00164
[580]	train-rmse:1.00263	valid-rmse:1.00569
[360]	train-rmse:1.01323	valid-rmse:1.01657
[320]	train-rmse:1.01560	valid-rmse:1.01900
[940]	train-rmse:0.99849	valid-rmse:1.00142
[460]	train-rmse:1.00815	valid-rmse:1.01133
[660]	train-rmse:1.00036	valid-rmse:1.00336
[600]	train-rmse:1.00202	valid-rmse:1.00506
[380]	train-rmse:1.01159	valid-rmse:1.01488
[960]	train-rmse:0.99829	valid-rmse:1.00122
[340]	train-rmse:1.01366	valid-rmse:1.01701
[680]	train-rmse:0.99996	valid-rmse:1.00295
[480]	train-rmse:1.00707	valid-rmse:1.01022
[620]	train-rmse:1.00147	valid-rmse:1.00450
[980]	train-rmse:0.99809	valid-rmse:1.00104
[400]	train-rmse:1.01012	valid-rmse:1.01336
[360]	train-rmse:1.01192	valid-rmse:1.01522
[700]	train-rmse:0.99958	valid-rmse:1.00257
[500]	train-rmse:1.00609	valid-rmse:1.00921
[999]	train-rmse:0.99793	valid-rmse:1.00088
[32m[I 2022-04-15 09:34:44,167][0m Trial 77 finished with value: 1.000876 and parameters: {'colsample_bytree': 0.23701645839658222, 'eta': 0.002067403186239875, 'max_depth': 3, 'n_estimators': 1003, 'subsample': 0.5371785733475928}. Best is trial 65 with value: 0.998642.[0m
[09:34:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[640]	train-rmse:1.00097	valid-rmse:1.00399
[420]	train-rmse:1.00878	valid-rmse:1.01197
[0]	train-rmse:1.09960	valid-rmse:1.10451
[720]	train-rmse:0.99923	valid-rmse:1.00223
[380]	train-rmse:1.01033	valid-rmse:1.01360
[520]	train-rmse:1.00520	valid-rmse:1.00829
[660]	train-rmse:1.00050	valid-rmse:1.00351
[440]	train-rmse:1.00757	valid-rmse:1.01074
[20]	train-rmse:1.09960	valid-rmse:1.10451
[740]	train-rmse:0.99892	valid-rmse:1.00192
[400]	train-rmse:1.00892	valid-rmse:1.01214
[540]	train-rmse:1.00437	valid-rmse:1.00744
[680]	train-rmse:1.00008	valid-rmse:1.00309
[460]	train-rmse:1.00647	valid-rmse:1.00961
[40]	train-rmse:1.09960	valid-rmse:1.10451
[760]	train-rmse:0.99863	valid-rmse:1.00163
[420]	train-rmse:1.00764	valid-rmse:1.01082
[560]	train-rmse:1.00362	valid-rmse:1.00669
[700]	train-rmse:0.99969	valid-rmse:1.00269
[480]	train-rmse:1.00547	valid-rmse:1.00860
[780]	train-rmse:0.99836	valid-rmse:1.00137
[60]	train-rmse:1.09960	valid-rmse:1.10451
[440]	train-rmse:1.00649	valid-rmse:1.00964
[580]	train-rmse:1.00293	valid-rmse:1.00597
[500]	train-rmse:1.00458	valid-rmse:1.00768
[800]	train-rmse:0.99812	valid-rmse:1.00113
[720]	train-rmse:0.99934	valid-rmse:1.00234
[80]	train-rmse:1.09960	valid-rmse:1.10451
[460]	train-rmse:1.00546	valid-rmse:1.00857
[600]	train-rmse:1.00231	valid-rmse:1.00533
[820]	train-rmse:0.99790	valid-rmse:1.00091
[520]	train-rmse:1.00377	valid-rmse:1.00685
[740]	train-rmse:0.99901	valid-rmse:1.00202
[100]	train-rmse:1.09960	valid-rmse:1.10451
[480]	train-rmse:1.00452	valid-rmse:1.00761
[620]	train-rmse:1.00174	valid-rmse:1.00475
[840]	train-rmse:0.99769	valid-rmse:1.00072
[540]	train-rmse:1.00302	valid-rmse:1.00608
[760]	train-rmse:0.99871	valid-rmse:1.00173
[120]	train-rmse:1.09959	valid-rmse:1.10451
[500]	train-rmse:1.00367	valid-rmse:1.00676
[860]	train-rmse:0.99750	valid-rmse:1.00054
[640]	train-rmse:1.00122	valid-rmse:1.00423
[560]	train-rmse:1.00235	valid-rmse:1.00540
[780]	train-rmse:0.99844	valid-rmse:1.00145
[140]	train-rmse:1.09960	valid-rmse:1.10451
[520]	train-rmse:1.00292	valid-rmse:1.00598
[880]	train-rmse:0.99732	valid-rmse:1.00039
[660]	train-rmse:1.00075	valid-rmse:1.00374
[580]	train-rmse:1.00174	valid-rmse:1.00476
[160]	train-rmse:1.09959	valid-rmse:1.10450
[800]	train-rmse:0.99820	valid-rmse:1.00121
[900]	train-rmse:0.99715	valid-rmse:1.00024
[540]	train-rmse:1.00222	valid-rmse:1.00527
[680]	train-rmse:1.00031	valid-rmse:1.00330
[600]	train-rmse:1.00118	valid-rmse:1.00418
[180]	train-rmse:1.09959	valid-rmse:1.10450
[820]	train-rmse:0.99796	valid-rmse:1.00098
[920]	train-rmse:0.99700	valid-rmse:1.00010
[560]	train-rmse:1.00159	valid-rmse:1.00464
[700]	train-rmse:0.99991	valid-rmse:1.00289
[620]	train-rmse:1.00067	valid-rmse:1.00367
[200]	train-rmse:1.09959	valid-rmse:1.10450
[840]	train-rmse:0.99775	valid-rmse:1.00078
[940]	train-rmse:0.99685	valid-rmse:0.99996
[580]	train-rmse:1.00102	valid-rmse:1.00406
[720]	train-rmse:0.99954	valid-rmse:1.00253
[640]	train-rmse:1.00022	valid-rmse:1.00321
[960]	train-rmse:0.99672	valid-rmse:0.99984
[220]	train-rmse:1.09959	valid-rmse:1.10450
[860]	train-rmse:0.99755	valid-rmse:1.00059
[600]	train-rmse:1.00051	valid-rmse:1.00354
[740]	train-rmse:0.99921	valid-rmse:1.00220
[660]	train-rmse:0.99980	valid-rmse:1.00279
[980]	train-rmse:0.99660	valid-rmse:0.99974
[240]	train-rmse:1.09959	valid-rmse:1.10450
[880]	train-rmse:0.99737	valid-rmse:1.00042
[620]	train-rmse:1.00005	valid-rmse:1.00307
[999]	train-rmse:0.99648	valid-rmse:0.99966
[760]	train-rmse:0.99890	valid-rmse:1.00189
[32m[I 2022-04-15 09:42:09,344][0m Trial 79 finished with value: 0.99966 and parameters: {'colsample_bytree': 0.3484790066892749, 'eta': 0.002506252101955175, 'max_depth': 3, 'n_estimators': 1022, 'subsample': 0.5120636014288571}. Best is trial 65 with value: 0.998642.[0m
[680]	train-rmse:0.99942	valid-rmse:1.00242
[09:42:14] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[260]	train-rmse:1.09959	valid-rmse:1.10450
[900]	train-rmse:0.99720	valid-rmse:1.00027
[0]	train-rmse:1.09960	valid-rmse:1.10451
[640]	train-rmse:0.99963	valid-rmse:1.00265
[780]	train-rmse:0.99862	valid-rmse:1.00161
[700]	train-rmse:0.99907	valid-rmse:1.00207
[20]	train-rmse:1.09960	valid-rmse:1.10451
[280]	train-rmse:1.09959	valid-rmse:1.10450
[920]	train-rmse:0.99705	valid-rmse:1.00013
[660]	train-rmse:0.99924	valid-rmse:1.00225
[800]	train-rmse:0.99836	valid-rmse:1.00135
[720]	train-rmse:0.99875	valid-rmse:1.00175
[40]	train-rmse:1.09960	valid-rmse:1.10451
[300]	train-rmse:1.09959	valid-rmse:1.10450
[940]	train-rmse:0.99690	valid-rmse:1.00000
[680]	train-rmse:0.99890	valid-rmse:1.00192
[60]	train-rmse:1.09960	valid-rmse:1.10451
[740]	train-rmse:0.99846	valid-rmse:1.00146
[820]	train-rmse:0.99812	valid-rmse:1.00111
[320]	train-rmse:1.09959	valid-rmse:1.10450
[960]	train-rmse:0.99676	valid-rmse:0.99988
[80]	train-rmse:1.09960	valid-rmse:1.10451
[700]	train-rmse:0.99858	valid-rmse:1.00160
[760]	train-rmse:0.99819	valid-rmse:1.00119
[840]	train-rmse:0.99790	valid-rmse:1.00090
[340]	train-rmse:1.09958	valid-rmse:1.10450
[980]	train-rmse:0.99663	valid-rmse:0.99978
[100]	train-rmse:1.09960	valid-rmse:1.10451
[720]	train-rmse:0.99829	valid-rmse:1.00133
[780]	train-rmse:0.99795	valid-rmse:1.00095
[860]	train-rmse:0.99770	valid-rmse:1.00070
[360]	train-rmse:1.09958	valid-rmse:1.10450
[999]	train-rmse:0.99652	valid-rmse:0.99969
[32m[I 2022-04-15 09:45:21,922][0m Trial 78 finished with value: 0.999693 and parameters: {'colsample_bytree': 0.3589666751179413, 'eta': 0.002475042827482163, 'max_depth': 3, 'n_estimators': 999, 'subsample': 0.6549162226970296}. Best is trial 65 with value: 0.998642.[0m
[120]	train-rmse:1.09960	valid-rmse:1.10451
[09:45:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09793	valid-rmse:1.10282
[740]	train-rmse:0.99803	valid-rmse:1.00107
[800]	train-rmse:0.99773	valid-rmse:1.00074
[880]	train-rmse:0.99750	valid-rmse:1.00052
[380]	train-rmse:1.09958	valid-rmse:1.10449
[140]	train-rmse:1.09960	valid-rmse:1.10451
[20]	train-rmse:1.06915	valid-rmse:1.07366
[760]	train-rmse:0.99778	valid-rmse:1.00084
[900]	train-rmse:0.99733	valid-rmse:1.00037
[820]	train-rmse:0.99753	valid-rmse:1.00055
[400]	train-rmse:1.09958	valid-rmse:1.10449
[160]	train-rmse:1.09959	valid-rmse:1.10451
[40]	train-rmse:1.04834	valid-rmse:1.05243
[780]	train-rmse:0.99757	valid-rmse:1.00063
[920]	train-rmse:0.99717	valid-rmse:1.00022
[840]	train-rmse:0.99734	valid-rmse:1.00037
[420]	train-rmse:1.09958	valid-rmse:1.10449
[180]	train-rmse:1.09960	valid-rmse:1.10451
[60]	train-rmse:1.03345	valid-rmse:1.03720
[800]	train-rmse:0.99737	valid-rmse:1.00045
[860]	train-rmse:0.99716	valid-rmse:1.00021
[940]	train-rmse:0.99701	valid-rmse:1.00007
[200]	train-rmse:1.09960	valid-rmse:1.10451
[80]	train-rmse:1.02280	valid-rmse:1.02635
[440]	train-rmse:1.09958	valid-rmse:1.10449
[820]	train-rmse:0.99719	valid-rmse:1.00028
[100]	train-rmse:1.01517	valid-rmse:1.01852
[220]	train-rmse:1.09959	valid-rmse:1.10450
[880]	train-rmse:0.99700	valid-rmse:1.00006
[960]	train-rmse:0.99687	valid-rmse:0.99995
[460]	train-rmse:1.09958	valid-rmse:1.10449
[840]	train-rmse:0.99702	valid-rmse:1.00012
[120]	train-rmse:1.00973	valid-rmse:1.01295
[240]	train-rmse:1.09959	valid-rmse:1.10450
[900]	train-rmse:0.99685	valid-rmse:0.99993
[980]	train-rmse:0.99674	valid-rmse:0.99984
[480]	train-rmse:1.09958	valid-rmse:1.10449
[140]	train-rmse:1.00581	valid-rmse:1.00891
[260]	train-rmse:1.09959	valid-rmse:1.10450
[860]	train-rmse:0.99686	valid-rmse:0.99999
[920]	train-rmse:0.99672	valid-rmse:0.99981
[999]	train-rmse:0.99662	valid-rmse:0.99975
[32m[I 2022-04-15 09:49:21,486][0m Trial 81 finished with value: 0.999747 and parameters: {'colsample_bytree': 0.3575609291382624, 'eta': 0.002435917517543672, 'max_depth': 3, 'n_estimators': 981, 'subsample': 0.6584646026136501}. Best is trial 65 with value: 0.998642.[0m
[500]	train-rmse:1.09958	valid-rmse:1.10449
[09:49:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09815	valid-rmse:1.10305
[160]	train-rmse:1.00301	valid-rmse:1.00603
[280]	train-rmse:1.09959	valid-rmse:1.10450
[880]	train-rmse:0.99671	valid-rmse:0.99986
[940]	train-rmse:0.99659	valid-rmse:0.99970
[520]	train-rmse:1.09958	valid-rmse:1.10449
[20]	train-rmse:1.07273	valid-rmse:1.07726
[180]	train-rmse:1.00098	valid-rmse:1.00396
[300]	train-rmse:1.09959	valid-rmse:1.10450
[900]	train-rmse:0.99658	valid-rmse:0.99975
[960]	train-rmse:0.99647	valid-rmse:0.99961
[40]	train-rmse:1.05350	valid-rmse:1.05767
[540]	train-rmse:1.09958	valid-rmse:1.10448
[200]	train-rmse:0.99953	valid-rmse:1.00250
[320]	train-rmse:1.09959	valid-rmse:1.10450
[920]	train-rmse:0.99646	valid-rmse:0.99965
[980]	train-rmse:0.99635	valid-rmse:0.99952
[60]	train-rmse:1.03908	valid-rmse:1.04292
[220]	train-rmse:0.99846	valid-rmse:1.00142
[560]	train-rmse:1.09958	valid-rmse:1.10448
[340]	train-rmse:1.09959	valid-rmse:1.10450
[80]	train-rmse:1.02827	valid-rmse:1.03188
[940]	train-rmse:0.99634	valid-rmse:0.99956
[999]	train-rmse:0.99625	valid-rmse:0.99944
[32m[I 2022-04-15 09:51:22,206][0m Trial 82 finished with value: 0.999441 and parameters: {'colsample_bytree': 0.3557911946620233, 'eta': 0.002605666749608959, 'max_depth': 3, 'n_estimators': 987, 'subsample': 0.6339251043271231}. Best is trial 65 with value: 0.998642.[0m
[09:51:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[240]	train-rmse:0.99767	valid-rmse:1.00067
[0]	train-rmse:1.09749	valid-rmse:1.10238
[580]	train-rmse:1.09957	valid-rmse:1.10448
[360]	train-rmse:1.09959	valid-rmse:1.10450
[100]	train-rmse:1.02017	valid-rmse:1.02357
[960]	train-rmse:0.99623	valid-rmse:0.99948
[260]	train-rmse:0.99705	valid-rmse:1.00010
[20]	train-rmse:1.06268	valid-rmse:1.06700
[380]	train-rmse:1.09959	valid-rmse:1.10450
[600]	train-rmse:1.09957	valid-rmse:1.10448
[120]	train-rmse:1.01411	valid-rmse:1.01737
[980]	train-rmse:0.99612	valid-rmse:0.99940
[280]	train-rmse:0.99658	valid-rmse:0.99972
[40]	train-rmse:1.03966	valid-rmse:1.04360
[400]	train-rmse:1.09959	valid-rmse:1.10450
[620]	train-rmse:1.09957	valid-rmse:1.10448
[140]	train-rmse:1.00955	valid-rmse:1.01271
[300]	train-rmse:0.99620	valid-rmse:0.99943
[999]	train-rmse:0.99603	valid-rmse:0.99935
[60]	train-rmse:1.02460	valid-rmse:1.02815
[32m[I 2022-04-15 09:52:56,275][0m Trial 83 finished with value: 0.999345 and parameters: {'colsample_bytree': 0.3589387796976735, 'eta': 0.0027198862975997737, 'max_depth': 3, 'n_estimators': 975, 'subsample': 0.6528636748062766}. Best is trial 65 with value: 0.998642.[0m
[420]	train-rmse:1.09959	valid-rmse:1.10450
[09:53:00] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09822	valid-rmse:1.10312
[160]	train-rmse:1.00615	valid-rmse:1.00921
[640]	train-rmse:1.09957	valid-rmse:1.10448
[320]	train-rmse:0.99590	valid-rmse:0.99922
[80]	train-rmse:1.01473	valid-rmse:1.01807
[440]	train-rmse:1.09959	valid-rmse:1.10450
[180]	train-rmse:1.00359	valid-rmse:1.00659
[20]	train-rmse:1.07384	valid-rmse:1.07838
[660]	train-rmse:1.09957	valid-rmse:1.10448
[340]	train-rmse:0.99566	valid-rmse:0.99907
[100]	train-rmse:1.00829	valid-rmse:1.01145
[460]	train-rmse:1.09959	valid-rmse:1.10450
[200]	train-rmse:1.00168	valid-rmse:1.00464
[40]	train-rmse:1.05516	valid-rmse:1.05935
[680]	train-rmse:1.09957	valid-rmse:1.10448
[120]	train-rmse:1.00407	valid-rmse:1.00714
[360]	train-rmse:0.99545	valid-rmse:0.99896
[480]	train-rmse:1.09958	valid-rmse:1.10450
[220]	train-rmse:1.00023	valid-rmse:1.00317
[60]	train-rmse:1.04094	valid-rmse:1.04483
[140]	train-rmse:1.00126	valid-rmse:1.00426
[700]	train-rmse:1.09957	valid-rmse:1.10448
[380]	train-rmse:0.99526	valid-rmse:0.99885
[500]	train-rmse:1.09958	valid-rmse:1.10449
[240]	train-rmse:0.99913	valid-rmse:1.00204
[80]	train-rmse:1.03011	valid-rmse:1.03377
[160]	train-rmse:0.99940	valid-rmse:1.00238
[400]	train-rmse:0.99510	valid-rmse:0.99877
[720]	train-rmse:1.09957	valid-rmse:1.10448
[520]	train-rmse:1.09958	valid-rmse:1.10449
[260]	train-rmse:0.99826	valid-rmse:1.00123
[100]	train-rmse:1.02190	valid-rmse:1.02537
[180]	train-rmse:0.99812	valid-rmse:1.00113
[420]	train-rmse:0.99493	valid-rmse:0.99871
[540]	train-rmse:1.09958	valid-rmse:1.10449
[280]	train-rmse:0.99761	valid-rmse:1.00061
[740]	train-rmse:1.09957	valid-rmse:1.10448
[120]	train-rmse:1.01568	valid-rmse:1.01901
[200]	train-rmse:0.99727	valid-rmse:1.00030
[440]	train-rmse:0.99477	valid-rmse:0.99870
[560]	train-rmse:1.09958	valid-rmse:1.10449
[300]	train-rmse:0.99709	valid-rmse:1.00012
[760]	train-rmse:1.09956	valid-rmse:1.10447
[140]	train-rmse:1.01093	valid-rmse:1.01415
[220]	train-rmse:0.99664	valid-rmse:0.99977
[460]	train-rmse:0.99462	valid-rmse:0.99868
[320]	train-rmse:0.99668	valid-rmse:0.99977
[580]	train-rmse:1.09958	valid-rmse:1.10449
[780]	train-rmse:1.09956	valid-rmse:1.10447
[160]	train-rmse:1.00733	valid-rmse:1.01046
[240]	train-rmse:0.99620	valid-rmse:0.99940
[480]	train-rmse:0.99448	valid-rmse:0.99868
[340]	train-rmse:0.99635	valid-rmse:0.99950
[600]	train-rmse:1.09958	valid-rmse:1.10449
[800]	train-rmse:1.09956	valid-rmse:1.10447
[180]	train-rmse:1.00459	valid-rmse:1.00764
[260]	train-rmse:0.99584	valid-rmse:0.99916
[360]	train-rmse:0.99608	valid-rmse:0.99929
[500]	train-rmse:0.99434	valid-rmse:0.99871
[620]	train-rmse:1.09958	valid-rmse:1.10449
[820]	train-rmse:1.09956	valid-rmse:1.10447
[200]	train-rmse:1.00254	valid-rmse:1.00551
[280]	train-rmse:0.99555	valid-rmse:0.99900
[518]	train-rmse:0.99422	valid-rmse:0.99873
[32m[I 2022-04-15 09:58:04,340][0m Trial 86 finished with value: 0.998668 and parameters: {'colsample_bytree': 0.3006708191168077, 'eta': 0.008744467123822087, 'max_depth': 3, 'n_estimators': 971, 'subsample': 0.6312214738821191}. Best is trial 65 with value: 0.998642.[0m
[380]	train-rmse:0.99583	valid-rmse:0.99911
[09:58:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[640]	train-rmse:1.09958	valid-rmse:1.10449
[0]	train-rmse:1.09764	valid-rmse:1.10254
[400]	train-rmse:0.99565	valid-rmse:0.99897
[220]	train-rmse:1.00095	valid-rmse:1.00386
[300]	train-rmse:0.99531	valid-rmse:0.99890
[840]	train-rmse:1.09956	valid-rmse:1.10447
[660]	train-rmse:1.09958	valid-rmse:1.10449
[20]	train-rmse:1.06495	valid-rmse:1.06936
[420]	train-rmse:0.99546	valid-rmse:0.99887
[320]	train-rmse:0.99511	valid-rmse:0.99882
[240]	train-rmse:0.99974	valid-rmse:1.00261
[860]	train-rmse:1.09956	valid-rmse:1.10447
[680]	train-rmse:1.09958	valid-rmse:1.10449
[40]	train-rmse:1.04262	valid-rmse:1.04662
[440]	train-rmse:0.99529	valid-rmse:0.99880
[340]	train-rmse:0.99491	valid-rmse:0.99877
[260]	train-rmse:0.99878	valid-rmse:1.00168
[700]	train-rmse:1.09958	valid-rmse:1.10449
[880]	train-rmse:1.09956	valid-rmse:1.10447
[60]	train-rmse:1.02752	valid-rmse:1.03116
[460]	train-rmse:0.99514	valid-rmse:0.99874
[360]	train-rmse:0.99475	valid-rmse:0.99875
[280]	train-rmse:0.99804	valid-rmse:1.00097
[720]	train-rmse:1.09958	valid-rmse:1.10448
[900]	train-rmse:1.09956	valid-rmse:1.10447
[80]	train-rmse:1.01730	valid-rmse:1.02069
[480]	train-rmse:0.99501	valid-rmse:0.99871
[380]	train-rmse:0.99456	valid-rmse:0.99871
[300]	train-rmse:0.99746	valid-rmse:1.00042
[740]	train-rmse:1.09958	valid-rmse:1.10448
[920]	train-rmse:1.09956	valid-rmse:1.10447
[100]	train-rmse:1.01041	valid-rmse:1.01362
[500]	train-rmse:0.99488	valid-rmse:0.99870
[400]	train-rmse:0.99440	valid-rmse:0.99868
[320]	train-rmse:0.99701	valid-rmse:1.00002
[760]	train-rmse:1.09957	valid-rmse:1.10448
[120]	train-rmse:1.00576	valid-rmse:1.00887
[940]	train-rmse:1.09956	valid-rmse:1.10447
[520]	train-rmse:0.99476	valid-rmse:0.99871
[420]	train-rmse:0.99423	valid-rmse:0.99868
[340]	train-rmse:0.99663	valid-rmse:0.99971
[780]	train-rmse:1.09957	valid-rmse:1.10448
[140]	train-rmse:1.00258	valid-rmse:1.00560
[540]	train-rmse:0.99463	valid-rmse:0.99869
[960]	train-rmse:1.09955	valid-rmse:1.10446
[440]	train-rmse:0.99404	valid-rmse:0.99868
[360]	train-rmse:0.99632	valid-rmse:0.99948
[800]	train-rmse:1.09957	valid-rmse:1.10448
[560]	train-rmse:0.99452	valid-rmse:0.99869
[160]	train-rmse:1.00042	valid-rmse:1.00341
[980]	train-rmse:1.09955	valid-rmse:1.10446
[460]	train-rmse:0.99389	valid-rmse:0.99872
[380]	train-rmse:0.99605	valid-rmse:0.99927
[820]	train-rmse:1.09957	valid-rmse:1.10448
[580]	train-rmse:0.99440	valid-rmse:0.99868
[180]	train-rmse:0.99891	valid-rmse:1.00191
[999]	train-rmse:1.09955	valid-rmse:1.10446
[32m[I 2022-04-15 10:02:48,386][0m Trial 84 finished with value: 1.104461 and parameters: {'colsample_bytree': 0.3572383520456499, 'eta': 2.551224022019553e-07, 'max_depth': 3, 'n_estimators': 960, 'subsample': 0.6474980179537565}. Best is trial 65 with value: 0.998642.[0m
[480]	train-rmse:0.99374	valid-rmse:0.99872
[10:02:53] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[400]	train-rmse:0.99584	valid-rmse:0.99911
[840]	train-rmse:1.09957	valid-rmse:1.10448
[0]	train-rmse:1.09785	valid-rmse:1.10275
[491]	train-rmse:0.99365	valid-rmse:0.99875
[600]	train-rmse:0.99428	valid-rmse:0.99868
[32m[I 2022-04-15 10:03:06,300][0m Trial 88 finished with value: 0.998672 and parameters: {'colsample_bytree': 0.27692229093004883, 'eta': 0.01103435647187005, 'max_depth': 3, 'n_estimators': 957, 'subsample': 0.7273358050654878}. Best is trial 65 with value: 0.998642.[0m
[10:03:10] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[200]	train-rmse:0.99788	valid-rmse:1.00089
[0]	train-rmse:1.08963	valid-rmse:1.09451
[420]	train-rmse:0.99564	valid-rmse:0.99900
[860]	train-rmse:1.09957	valid-rmse:1.10448
[20]	train-rmse:1.06806	valid-rmse:1.07248
[620]	train-rmse:0.99417	valid-rmse:0.99868
[220]	train-rmse:0.99713	valid-rmse:1.00019
[20]	train-rmse:1.00781	valid-rmse:1.01086
[880]	train-rmse:1.09957	valid-rmse:1.10448
[440]	train-rmse:0.99546	valid-rmse:0.99893
[40]	train-rmse:1.04685	valid-rmse:1.05085
[640]	train-rmse:0.99406	valid-rmse:0.99868
[40]	train-rmse:0.99733	valid-rmse:1.00052
[240]	train-rmse:0.99659	valid-rmse:0.99970
[900]	train-rmse:1.09957	valid-rmse:1.10448
[460]	train-rmse:0.99531	valid-rmse:0.99886
[660]	train-rmse:0.99396	valid-rmse:0.99869
[60]	train-rmse:1.03187	valid-rmse:1.03556
[60]	train-rmse:0.99544	valid-rmse:0.99909
[260]	train-rmse:0.99617	valid-rmse:0.99940
[920]	train-rmse:1.09957	valid-rmse:1.10448
[480]	train-rmse:0.99517	valid-rmse:0.99881
[680]	train-rmse:0.99384	valid-rmse:0.99872
[32m[I 2022-04-15 10:04:56,705][0m Trial 87 finished with value: 0.998669 and parameters: {'colsample_bytree': 0.28126739219775104, 'eta': 0.007552432554787973, 'max_depth': 3, 'n_estimators': 956, 'subsample': 0.6279655161517947}. Best is trial 65 with value: 0.998642.[0m
[80]	train-rmse:1.02128	valid-rmse:1.02474
[10:05:01] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:0.99445	valid-rmse:0.99884
[0]	train-rmse:1.08943	valid-rmse:1.09423
[280]	train-rmse:0.99584	valid-rmse:0.99916
[940]	train-rmse:1.09957	valid-rmse:1.10448
[500]	train-rmse:0.99503	valid-rmse:0.99878
[100]	train-rmse:1.01384	valid-rmse:1.01711
[100]	train-rmse:0.99368	valid-rmse:0.99883
[20]	train-rmse:1.00727	valid-rmse:1.01045
[300]	train-rmse:0.99557	valid-rmse:0.99901
[960]	train-rmse:1.09957	valid-rmse:1.10448
[520]	train-rmse:0.99491	valid-rmse:0.99877
[120]	train-rmse:1.00860	valid-rmse:1.01178
[120]	train-rmse:0.99306	valid-rmse:0.99897
[40]	train-rmse:0.99714	valid-rmse:1.00032
[320]	train-rmse:0.99535	valid-rmse:0.99892
[980]	train-rmse:1.09957	valid-rmse:1.10448
[540]	train-rmse:0.99478	valid-rmse:0.99877
[140]	train-rmse:1.00488	valid-rmse:1.00797
[140]	train-rmse:0.99232	valid-rmse:0.99896
[143]	train-rmse:0.99220	valid-rmse:0.99893
[32m[I 2022-04-15 10:06:32,013][0m Trial 92 finished with value: 0.998757 and parameters: {'colsample_bytree': 0.27289112149658484, 'eta': 0.05297047665018507, 'max_depth': 3, 'n_estimators': 930, 'subsample': 0.677930636932821}. Best is trial 65 with value: 0.998642.[0m
[60]	train-rmse:0.99529	valid-rmse:0.99913
[10:06:36] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[999]	train-rmse:1.09957	valid-rmse:1.10448
[340]	train-rmse:0.99513	valid-rmse:0.99882
[0]	train-rmse:1.09753	valid-rmse:1.10242
[32m[I 2022-04-15 10:06:40,834][0m Trial 85 finished with value: 1.104475 and parameters: {'colsample_bytree': 0.29981805013678925, 'eta': 1.8149492892114333e-07, 'max_depth': 3, 'n_estimators': 972, 'subsample': 0.6532283751359842}. Best is trial 65 with value: 0.998642.[0m
[10:06:45] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09772	valid-rmse:1.10261
[160]	train-rmse:1.00225	valid-rmse:1.00528
[560]	train-rmse:0.99467	valid-rmse:0.99874
[80]	train-rmse:0.99437	valid-rmse:0.99912
[360]	train-rmse:0.99495	valid-rmse:0.99878
[20]	train-rmse:1.06326	valid-rmse:1.06767
[180]	train-rmse:1.00036	valid-rmse:1.00336
[580]	train-rmse:0.99455	valid-rmse:0.99874
[20]	train-rmse:1.06609	valid-rmse:1.07047
[100]	train-rmse:0.99363	valid-rmse:0.99928
[40]	train-rmse:1.04040	valid-rmse:1.04439
[380]	train-rmse:0.99477	valid-rmse:0.99873
[200]	train-rmse:0.99903	valid-rmse:1.00201
[600]	train-rmse:0.99443	valid-rmse:0.99872
[40]	train-rmse:1.04414	valid-rmse:1.04810
[120]	train-rmse:0.99296	valid-rmse:0.99946
[60]	train-rmse:1.02531	valid-rmse:1.02896
[400]	train-rmse:0.99461	valid-rmse:0.99869
[123]	train-rmse:0.99286	valid-rmse:0.99941
[32m[I 2022-04-15 10:08:13,006][0m Trial 93 finished with value: 0.999041 and parameters: {'colsample_bytree': 0.29420399203433417, 'eta': 0.05406187313745826, 'max_depth': 3, 'n_estimators': 819, 'subsample': 0.7386261689047949}. Best is trial 65 with value: 0.998642.[0m
[10:08:17] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09778	valid-rmse:1.10267
[220]	train-rmse:0.99805	valid-rmse:1.00104
[620]	train-rmse:0.99432	valid-rmse:0.99873
[80]	train-rmse:1.01535	valid-rmse:1.01875
[420]	train-rmse:0.99446	valid-rmse:0.99868
[60]	train-rmse:1.02905	valid-rmse:1.03269
[20]	train-rmse:1.06703	valid-rmse:1.07146
[240]	train-rmse:0.99734	valid-rmse:1.00037
[640]	train-rmse:0.99421	valid-rmse:0.99874
[100]	train-rmse:1.00879	valid-rmse:1.01200
[440]	train-rmse:0.99429	valid-rmse:0.99869
[650]	train-rmse:0.99415	valid-rmse:0.99875
[40]	train-rmse:1.04539	valid-rmse:1.04938
[32m[I 2022-04-15 10:09:11,697][0m Trial 89 finished with value: 0.99872 and parameters: {'colsample_bytree': 0.2989084685468926, 'eta': 0.007188460069951086, 'max_depth': 3, 'n_estimators': 43, 'subsample': 0.7182815213677857}. Best is trial 65 with value: 0.998642.[0m
[10:09:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:1.01867	valid-rmse:1.02209
[0]	train-rmse:1.09756	valid-rmse:1.10244
[260]	train-rmse:0.99679	valid-rmse:0.99990
[120]	train-rmse:1.00445	valid-rmse:1.00755
[60]	train-rmse:1.03035	valid-rmse:1.03398
[460]	train-rmse:0.99414	valid-rmse:0.99872
[280]	train-rmse:0.99637	valid-rmse:0.99953
[469]	train-rmse:0.99407	valid-rmse:0.99871
[32m[I 2022-04-15 10:09:55,400][0m Trial 90 finished with value: 0.998677 and parameters: {'colsample_bytree': 0.2991732093784343, 'eta': 0.010203533632647513, 'max_depth': 3, 'n_estimators': 938, 'subsample': 0.72605447949055}. Best is trial 65 with value: 0.998642.[0m
[100]	train-rmse:1.01158	valid-rmse:1.01480
[10:09:59] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:1.01991	valid-rmse:1.02330
[20]	train-rmse:1.06367	valid-rmse:1.06807
[0]	train-rmse:1.09740	valid-rmse:1.10229
[140]	train-rmse:1.00156	valid-rmse:1.00457
[300]	train-rmse:0.99604	valid-rmse:0.99929
[100]	train-rmse:1.01265	valid-rmse:1.01586
[160]	train-rmse:0.99962	valid-rmse:1.00262
[120]	train-rmse:1.00670	valid-rmse:1.00983
[40]	train-rmse:1.04093	valid-rmse:1.04495
[20]	train-rmse:1.06154	valid-rmse:1.06585
[120]	train-rmse:1.00761	valid-rmse:1.01070
[320]	train-rmse:0.99577	valid-rmse:0.99911
[180]	train-rmse:0.99830	valid-rmse:1.00131
[140]	train-rmse:1.00406	valid-rmse:1.00711
[140]	train-rmse:1.00331	valid-rmse:1.00636
[60]	train-rmse:1.02582	valid-rmse:1.02950
[340]	train-rmse:0.99553	valid-rmse:0.99897
[40]	train-rmse:1.03820	valid-rmse:1.04214
[200]	train-rmse:0.99741	valid-rmse:1.00046
[160]	train-rmse:1.00160	valid-rmse:1.00459
[360]	train-rmse:0.99533	valid-rmse:0.99887
[160]	train-rmse:1.00098	valid-rmse:1.00400
[80]	train-rmse:1.01578	valid-rmse:1.01925
[60]	train-rmse:1.02315	valid-rmse:1.02677
[180]	train-rmse:0.99985	valid-rmse:1.00284
[220]	train-rmse:0.99676	valid-rmse:0.99987
[380]	train-rmse:0.99514	valid-rmse:0.99879
[200]	train-rmse:0.99865	valid-rmse:1.00163
[180]	train-rmse:0.99935	valid-rmse:1.00237
[240]	train-rmse:0.99629	valid-rmse:0.99948
[100]	train-rmse:1.00913	valid-rmse:1.01241
[80]	train-rmse:1.01345	valid-rmse:1.01686
[400]	train-rmse:0.99498	valid-rmse:0.99875
[220]	train-rmse:0.99775	valid-rmse:1.00077
[260]	train-rmse:0.99591	valid-rmse:0.99925
[200]	train-rmse:0.99823	valid-rmse:1.00125
[120]	train-rmse:1.00472	valid-rmse:1.00790
[240]	train-rmse:0.99710	valid-rmse:1.00016
[100]	train-rmse:1.00723	valid-rmse:1.01047
[420]	train-rmse:0.99482	valid-rmse:0.99872
[280]	train-rmse:0.99561	valid-rmse:0.99907
[260]	train-rmse:0.99658	valid-rmse:0.99974
[220]	train-rmse:0.99741	valid-rmse:1.00045
[440]	train-rmse:0.99466	valid-rmse:0.99871
[140]	train-rmse:1.00176	valid-rmse:1.00486
[120]	train-rmse:1.00323	valid-rmse:1.00637
[300]	train-rmse:0.99537	valid-rmse:0.99898
[280]	train-rmse:0.99621	valid-rmse:0.99944
[460]	train-rmse:0.99452	valid-rmse:0.99869
[240]	train-rmse:0.99681	valid-rmse:0.99992
[320]	train-rmse:0.99515	valid-rmse:0.99891
[300]	train-rmse:0.99590	valid-rmse:0.99920
[160]	train-rmse:0.99977	valid-rmse:1.00282
[140]	train-rmse:1.00061	valid-rmse:1.00368
[480]	train-rmse:0.99439	valid-rmse:0.99867
[320]	train-rmse:0.99565	valid-rmse:0.99905
[340]	train-rmse:0.99496	valid-rmse:0.99888
[260]	train-rmse:0.99634	valid-rmse:0.99953
[180]	train-rmse:0.99840	valid-rmse:1.00142
[160]	train-rmse:0.99889	valid-rmse:1.00194
[340]	train-rmse:0.99544	valid-rmse:0.99893
[500]	train-rmse:0.99423	valid-rmse:0.99866
[360]	train-rmse:0.99477	valid-rmse:0.99887
[280]	train-rmse:0.99599	valid-rmse:0.99926
[360]	train-rmse:0.99525	valid-rmse:0.99887
[200]	train-rmse:0.99747	valid-rmse:1.00054
[520]	train-rmse:0.99409	valid-rmse:0.99867
[180]	train-rmse:0.99772	valid-rmse:1.00075
[380]	train-rmse:0.99459	valid-rmse:0.99883
[380]	train-rmse:0.99506	valid-rmse:0.99879
[300]	train-rmse:0.99569	valid-rmse:0.99907
[540]	train-rmse:0.99396	valid-rmse:0.99871
[400]	train-rmse:0.99442	valid-rmse:0.99882
[220]	train-rmse:0.99679	valid-rmse:0.99994
[548]	train-rmse:0.99390	valid-rmse:0.99871
[400]	train-rmse:0.99490	valid-rmse:0.99874
[32m[I 2022-04-15 10:16:37,577][0m Trial 91 finished with value: 0.998661 and parameters: {'colsample_bytree': 0.30218315465068624, 'eta': 0.0091079809238235, 'max_depth': 3, 'n_estimators': 931, 'subsample': 0.7323333377871556}. Best is trial 65 with value: 0.998642.[0m
[200]	train-rmse:0.99694	valid-rmse:1.00005
[10:16:42] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09743	valid-rmse:1.10232
[320]	train-rmse:0.99544	valid-rmse:0.99895
[420]	train-rmse:0.99427	valid-rmse:0.99882
[420]	train-rmse:0.99474	valid-rmse:0.99871
[240]	train-rmse:0.99630	valid-rmse:0.99951
[20]	train-rmse:1.06194	valid-rmse:1.06631
[220]	train-rmse:0.99637	valid-rmse:0.99956
[440]	train-rmse:0.99460	valid-rmse:0.99871
[440]	train-rmse:0.99410	valid-rmse:0.99882
[340]	train-rmse:0.99523	valid-rmse:0.99887
[40]	train-rmse:1.03872	valid-rmse:1.04268
[260]	train-rmse:0.99592	valid-rmse:0.99920
[460]	train-rmse:0.99444	valid-rmse:0.99872
[240]	train-rmse:0.99596	valid-rmse:0.99921
[460]	train-rmse:0.99395	valid-rmse:0.99886
[60]	train-rmse:1.02366	valid-rmse:1.02726
[360]	train-rmse:0.99504	valid-rmse:0.99884
[478]	train-rmse:0.99433	valid-rmse:0.99871
[32m[I 2022-04-15 10:18:17,385][0m Trial 96 finished with value: 0.998697 and parameters: {'colsample_bytree': 0.2607316522045632, 'eta': 0.009480350125903324, 'max_depth': 3, 'n_estimators': 883, 'subsample': 0.6215567414195604}. Best is trial 65 with value: 0.998642.[0m
[10:18:21] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09948	valid-rmse:1.10439
[480]	train-rmse:0.99379	valid-rmse:0.99885
[280]	train-rmse:0.99560	valid-rmse:0.99899
[260]	train-rmse:0.99562	valid-rmse:0.99900
[80]	train-rmse:1.01390	valid-rmse:1.01727
[490]	train-rmse:0.99372	valid-rmse:0.99887
[32m[I 2022-04-15 10:18:47,108][0m Trial 94 finished with value: 0.998816 and parameters: {'colsample_bytree': 0.29318249922010503, 'eta': 0.010821495569329065, 'max_depth': 3, 'n_estimators': 822, 'subsample': 0.7214610237255592}. Best is trial 65 with value: 0.998642.[0m
[380]	train-rmse:0.99486	valid-rmse:0.99880
[10:18:51] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09361	valid-rmse:1.09846
[20]	train-rmse:1.09699	valid-rmse:1.10186
[100]	train-rmse:1.00761	valid-rmse:1.01080
[300]	train-rmse:0.99535	valid-rmse:0.99890
[280]	train-rmse:0.99533	valid-rmse:0.99886
[20]	train-rmse:1.02484	valid-rmse:1.02853
[400]	train-rmse:0.99470	valid-rmse:0.99876
[40]	train-rmse:1.09455	valid-rmse:1.09939
[120]	train-rmse:1.00354	valid-rmse:1.00663
[320]	train-rmse:0.99512	valid-rmse:0.99882
[40]	train-rmse:1.00449	valid-rmse:1.00757
[300]	train-rmse:0.99510	valid-rmse:0.99879
[60]	train-rmse:1.09217	valid-rmse:1.09697
[140]	train-rmse:1.00086	valid-rmse:1.00387
[420]	train-rmse:0.99453	valid-rmse:0.99873
[60]	train-rmse:0.99847	valid-rmse:1.00143
[80]	train-rmse:1.08985	valid-rmse:1.09460
[160]	train-rmse:0.99910	valid-rmse:1.00211
[340]	train-rmse:0.99491	valid-rmse:0.99879
[320]	train-rmse:0.99487	valid-rmse:0.99873
[440]	train-rmse:0.99437	valid-rmse:0.99873
[80]	train-rmse:0.99643	valid-rmse:0.99959
[100]	train-rmse:1.08759	valid-rmse:1.09230
[180]	train-rmse:0.99791	valid-rmse:1.00093
[360]	train-rmse:0.99473	valid-rmse:0.99878
[340]	train-rmse:0.99466	valid-rmse:0.99874
[100]	train-rmse:0.99551	valid-rmse:0.99902
[460]	train-rmse:0.99423	valid-rmse:0.99871
[200]	train-rmse:0.99710	valid-rmse:1.00021
[120]	train-rmse:1.08537	valid-rmse:1.09004
[120]	train-rmse:0.99496	valid-rmse:0.99882
[380]	train-rmse:0.99454	valid-rmse:0.99876
[220]	train-rmse:0.99652	valid-rmse:0.99970
[140]	train-rmse:1.08321	valid-rmse:1.08784
[360]	train-rmse:0.99449	valid-rmse:0.99873
[480]	train-rmse:0.99408	valid-rmse:0.99870
[140]	train-rmse:0.99445	valid-rmse:0.99880
[240]	train-rmse:0.99610	valid-rmse:0.99939
[160]	train-rmse:1.08110	valid-rmse:1.08570
[400]	train-rmse:0.99439	valid-rmse:0.99872
[380]	train-rmse:0.99430	valid-rmse:0.99869
[500]	train-rmse:0.99393	valid-rmse:0.99869
[160]	train-rmse:0.99400	valid-rmse:0.99891
[260]	train-rmse:0.99576	valid-rmse:0.99915
[180]	train-rmse:1.07904	valid-rmse:1.08360
[420]	train-rmse:0.99423	valid-rmse:0.99871
[180]	train-rmse:0.99353	valid-rmse:0.99902
[280]	train-rmse:0.99546	valid-rmse:0.99901
[400]	train-rmse:0.99415	valid-rmse:0.99867
[520]	train-rmse:0.99378	valid-rmse:0.99870
[200]	train-rmse:1.07703	valid-rmse:1.08156
[186]	train-rmse:0.99341	valid-rmse:0.99905
[32m[I 2022-04-15 10:23:21,338][0m Trial 101 finished with value: 0.998759 and parameters: {'colsample_bytree': 0.2711858260331703, 'eta': 0.03153794930604317, 'max_depth': 3, 'n_estimators': 903, 'subsample': 0.7855854711130912}. Best is trial 65 with value: 0.998642.[0m
[10:23:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09720	valid-rmse:1.10209
[528]	train-rmse:0.99373	valid-rmse:0.99871
[32m[I 2022-04-15 10:23:34,548][0m Trial 95 finished with value: 0.998688 and parameters: {'colsample_bytree': 0.41719270573766076, 'eta': 0.009796581058207118, 'max_depth': 3, 'n_estimators': 14, 'subsample': 0.7176081301577221}. Best is trial 65 with value: 0.998642.[0m
[10:23:39] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[300]	train-rmse:0.99524	valid-rmse:0.99894
[0]	train-rmse:1.09702	valid-rmse:1.10189
[220]	train-rmse:1.07506	valid-rmse:1.07956
[440]	train-rmse:0.99406	valid-rmse:0.99871
[420]	train-rmse:0.99398	valid-rmse:0.99867
[20]	train-rmse:1.05881	valid-rmse:1.06317
[320]	train-rmse:0.99504	valid-rmse:0.99889
[240]	train-rmse:1.07315	valid-rmse:1.07761
[20]	train-rmse:1.05632	valid-rmse:1.06061
[40]	train-rmse:1.03482	valid-rmse:1.03870
[460]	train-rmse:0.99390	valid-rmse:0.99872
[440]	train-rmse:0.99381	valid-rmse:0.99865
[340]	train-rmse:0.99484	valid-rmse:0.99885
[260]	train-rmse:1.07127	valid-rmse:1.07570
[60]	train-rmse:1.01999	valid-rmse:1.02355
[40]	train-rmse:1.03187	valid-rmse:1.03569
[360]	train-rmse:0.99466	valid-rmse:0.99886
[480]	train-rmse:0.99375	valid-rmse:0.99873
[280]	train-rmse:1.06945	valid-rmse:1.07384
[460]	train-rmse:0.99365	valid-rmse:0.99867
[80]	train-rmse:1.01083	valid-rmse:1.01412
[490]	train-rmse:0.99368	valid-rmse:0.99875
[380]	train-rmse:0.99449	valid-rmse:0.99883
[32m[I 2022-04-15 10:25:32,264][0m Trial 97 finished with value: 0.998699 and parameters: {'colsample_bytree': 0.41881108429342034, 'eta': 0.010673475828193255, 'max_depth': 3, 'n_estimators': 888, 'subsample': 0.7748123299604368}. Best is trial 65 with value: 0.998642.[0m
[10:25:36] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.01733	valid-rmse:1.02085
[0]	train-rmse:1.09709	valid-rmse:1.10197
[300]	train-rmse:1.06766	valid-rmse:1.07203
[100]	train-rmse:1.00518	valid-rmse:1.00828
[480]	train-rmse:0.99349	valid-rmse:0.99869
[400]	train-rmse:0.99434	valid-rmse:0.99881
[20]	train-rmse:1.05727	valid-rmse:1.06152
[320]	train-rmse:1.06592	valid-rmse:1.07026
[120]	train-rmse:1.00169	valid-rmse:1.00470
[80]	train-rmse:1.00867	valid-rmse:1.01195
[491]	train-rmse:0.99340	valid-rmse:0.99870
[32m[I 2022-04-15 10:26:18,816][0m Trial 98 finished with value: 0.998643 and parameters: {'colsample_bytree': 0.4188498175113946, 'eta': 0.011465427211816306, 'max_depth': 3, 'n_estimators': 894, 'subsample': 0.78230986462611}. Best is trial 65 with value: 0.998642.[0m
[10:26:23] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[420]	train-rmse:0.99419	valid-rmse:0.99880
[0]	train-rmse:1.09614	valid-rmse:1.10100
[40]	train-rmse:1.03298	valid-rmse:1.03679
[340]	train-rmse:1.06422	valid-rmse:1.06853
[140]	train-rmse:0.99946	valid-rmse:1.00244
[100]	train-rmse:1.00353	valid-rmse:1.00664
[440]	train-rmse:0.99402	valid-rmse:0.99878
[60]	train-rmse:1.01833	valid-rmse:1.02181
[360]	train-rmse:1.06256	valid-rmse:1.06684
[160]	train-rmse:0.99805	valid-rmse:1.00103
[20]	train-rmse:1.04615	valid-rmse:1.05018
[460]	train-rmse:0.99387	valid-rmse:0.99878
[120]	train-rmse:1.00045	valid-rmse:1.00349
[80]	train-rmse:1.00949	valid-rmse:1.01273
[180]	train-rmse:0.99709	valid-rmse:1.00014
[380]	train-rmse:1.06094	valid-rmse:1.06519
[480]	train-rmse:0.99371	valid-rmse:0.99881
[482]	train-rmse:0.99369	valid-rmse:0.99881
[32m[I 2022-04-15 10:28:12,970][0m Trial 99 finished with value: 0.998773 and parameters: {'colsample_bytree': 0.2622264741431673, 'eta': 0.011317427677192163, 'max_depth': 3, 'n_estimators': 908, 'subsample': 0.7844026593121353}. Best is trial 65 with value: 0.998642.[0m
[40]	train-rmse:1.02098	valid-rmse:1.02458
[10:28:17] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[100]	train-rmse:1.00417	valid-rmse:1.00722
[200]	train-rmse:0.99646	valid-rmse:0.99963
[0]	train-rmse:1.09336	valid-rmse:1.09823
[140]	train-rmse:0.99854	valid-rmse:1.00157
[400]	train-rmse:1.05936	valid-rmse:1.06357
[120]	train-rmse:1.00094	valid-rmse:1.00392
[220]	train-rmse:0.99599	valid-rmse:0.99927
[420]	train-rmse:1.05781	valid-rmse:1.06200
[160]	train-rmse:0.99735	valid-rmse:1.00044
[60]	train-rmse:1.00845	valid-rmse:1.01171
[20]	train-rmse:1.02334	valid-rmse:1.02699
[140]	train-rmse:0.99892	valid-rmse:1.00186
[240]	train-rmse:0.99565	valid-rmse:0.99903
[440]	train-rmse:1.05631	valid-rmse:1.06047
[180]	train-rmse:0.99655	valid-rmse:0.99974
[160]	train-rmse:0.99765	valid-rmse:1.00063
[260]	train-rmse:0.99536	valid-rmse:0.99887
[80]	train-rmse:1.00218	valid-rmse:1.00534
[460]	train-rmse:1.05484	valid-rmse:1.05897
[40]	train-rmse:1.00364	valid-rmse:1.00670
[180]	train-rmse:0.99679	valid-rmse:0.99985
[280]	train-rmse:0.99509	valid-rmse:0.99879
[200]	train-rmse:0.99603	valid-rmse:0.99931
[480]	train-rmse:1.05340	valid-rmse:1.05752
[100]	train-rmse:0.99900	valid-rmse:1.00212
[60]	train-rmse:0.99799	valid-rmse:1.00094
[200]	train-rmse:0.99623	valid-rmse:0.99939
[300]	train-rmse:0.99488	valid-rmse:0.99877
[500]	train-rmse:1.05201	valid-rmse:1.05609
[220]	train-rmse:0.99562	valid-rmse:0.99905
[220]	train-rmse:0.99581	valid-rmse:0.99912
[320]	train-rmse:0.99468	valid-rmse:0.99876
[120]	train-rmse:0.99734	valid-rmse:1.00054
[520]	train-rmse:1.05064	valid-rmse:1.05470
[80]	train-rmse:0.99608	valid-rmse:0.99936
[240]	train-rmse:0.99531	valid-rmse:0.99889
[340]	train-rmse:0.99448	valid-rmse:0.99874
[240]	train-rmse:0.99550	valid-rmse:0.99894
[540]	train-rmse:1.04931	valid-rmse:1.05334
[140]	train-rmse:0.99638	valid-rmse:0.99969
[360]	train-rmse:0.99430	valid-rmse:0.99876
[260]	train-rmse:0.99522	valid-rmse:0.99882
[260]	train-rmse:0.99504	valid-rmse:0.99882
[100]	train-rmse:0.99526	valid-rmse:0.99885
[560]	train-rmse:1.04801	valid-rmse:1.05202
[380]	train-rmse:0.99411	valid-rmse:0.99871
[280]	train-rmse:0.99498	valid-rmse:0.99874
[280]	train-rmse:0.99480	valid-rmse:0.99874
[160]	train-rmse:0.99576	valid-rmse:0.99927
[580]	train-rmse:1.04673	valid-rmse:1.05072
[120]	train-rmse:0.99472	valid-rmse:0.99870
[400]	train-rmse:0.99395	valid-rmse:0.99870
[300]	train-rmse:0.99478	valid-rmse:0.99874
[600]	train-rmse:1.04549	valid-rmse:1.04946
[300]	train-rmse:0.99459	valid-rmse:0.99872
[420]	train-rmse:0.99379	valid-rmse:0.99871
[320]	train-rmse:0.99456	valid-rmse:0.99870
[180]	train-rmse:0.99531	valid-rmse:0.99903
[140]	train-rmse:0.99421	valid-rmse:0.99868
[620]	train-rmse:1.04428	valid-rmse:1.04822
[440]	train-rmse:0.99362	valid-rmse:0.99871
[340]	train-rmse:0.99437	valid-rmse:0.99869
[320]	train-rmse:0.99436	valid-rmse:0.99868
[200]	train-rmse:0.99497	valid-rmse:0.99898
[640]	train-rmse:1.04310	valid-rmse:1.04702
[460]	train-rmse:0.99346	valid-rmse:0.99873
[360]	train-rmse:0.99417	valid-rmse:0.99874
[160]	train-rmse:0.99373	valid-rmse:0.99876
[340]	train-rmse:0.99414	valid-rmse:0.99870
[660]	train-rmse:1.04195	valid-rmse:1.04585
[480]	train-rmse:0.99328	valid-rmse:0.99876
[380]	train-rmse:0.99397	valid-rmse:0.99871
[482]	train-rmse:0.99326	valid-rmse:0.99877
[32m[I 2022-04-15 10:35:42,625][0m Trial 102 finished with value: 0.998694 and parameters: {'colsample_bytree': 0.25843032736213256, 'eta': 0.012522900475166411, 'max_depth': 3, 'n_estimators': 887, 'subsample': 0.7882785234981913}. Best is trial 65 with value: 0.998642.[0m
[10:35:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[220]	train-rmse:0.99466	valid-rmse:0.99892
[0]	train-rmse:1.09658	valid-rmse:1.10144
[178]	train-rmse:0.99330	valid-rmse:0.99879
[392]	train-rmse:0.99387	valid-rmse:0.99873
[32m[I 2022-04-15 10:36:01,963][0m Trial 106 finished with value: 0.99866 and parameters: {'colsample_bytree': 0.4899240078322725, 'eta': 0.03278588859774441, 'max_depth': 3, 'n_estimators': 848, 'subsample': 0.8160307516110793}. Best is trial 65 with value: 0.998642.[0m
[32m[I 2022-04-15 10:36:02,901][0m Trial 104 finished with value: 0.998683 and parameters: {'colsample_bytree': 0.2734904537374719, 'eta': 0.013130967464599567, 'max_depth': 3, 'n_estimators': 913, 'subsample': 0.7494342182911978}. Best is trial 65 with value: 0.998642.[0m
[680]	train-rmse:1.04083	valid-rmse:1.04470
[10:36:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[10:36:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09369	valid-rmse:1.09852
[360]	train-rmse:0.99394	valid-rmse:0.99874
[0]	train-rmse:1.09276	valid-rmse:1.09758
[370]	train-rmse:0.99384	valid-rmse:0.99876
[32m[I 2022-04-15 10:36:36,915][0m Trial 103 finished with value: 0.998669 and parameters: {'colsample_bytree': 0.41257807923839207, 'eta': 0.013506229861917228, 'max_depth': 3, 'n_estimators': 165, 'subsample': 0.7560095581020128}. Best is trial 65 with value: 0.998642.[0m
[240]	train-rmse:0.99440	valid-rmse:0.99890
[700]	train-rmse:1.03973	valid-rmse:1.04358
[10:36:42] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09427	valid-rmse:1.09911
[20]	train-rmse:1.01993	valid-rmse:1.02340
[20]	train-rmse:1.02538	valid-rmse:1.02905
[720]	train-rmse:1.03866	valid-rmse:1.04249
[20]	train-rmse:1.05108	valid-rmse:1.05511
[260]	train-rmse:0.99413	valid-rmse:0.99889
[20]	train-rmse:1.02930	valid-rmse:1.03299
[740]	train-rmse:1.03762	valid-rmse:1.04143
[40]	train-rmse:1.00186	valid-rmse:1.00491
[40]	train-rmse:1.00481	valid-rmse:1.00791
[760]	train-rmse:1.03660	valid-rmse:1.04039
[280]	train-rmse:0.99383	valid-rmse:0.99887
[40]	train-rmse:1.00720	valid-rmse:1.01043
[60]	train-rmse:0.99720	valid-rmse:1.00025
[60]	train-rmse:0.99850	valid-rmse:1.00150
[780]	train-rmse:1.03561	valid-rmse:1.03937
[40]	train-rmse:1.02600	valid-rmse:1.02958
[300]	train-rmse:0.99357	valid-rmse:0.99890
[80]	train-rmse:0.99570	valid-rmse:0.99920
[60]	train-rmse:0.99970	valid-rmse:1.00272
[800]	train-rmse:1.03464	valid-rmse:1.03838
[80]	train-rmse:0.99636	valid-rmse:0.99965
[820]	train-rmse:1.03370	valid-rmse:1.03742
[100]	train-rmse:0.99497	valid-rmse:0.99892
[320]	train-rmse:0.99331	valid-rmse:0.99894
[80]	train-rmse:0.99698	valid-rmse:1.00016
[321]	train-rmse:0.99330	valid-rmse:0.99894
[32m[I 2022-04-15 10:40:17,986][0m Trial 105 finished with value: 0.998856 and parameters: {'colsample_bytree': 0.48718861075279823, 'eta': 0.018046844594839184, 'max_depth': 3, 'n_estimators': 185, 'subsample': 0.816432800090316}. Best is trial 65 with value: 0.998642.[0m
[10:40:22] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[100]	train-rmse:0.99544	valid-rmse:0.99905
[0]	train-rmse:1.09317	valid-rmse:1.09799
[60]	train-rmse:1.01233	valid-rmse:1.01561
[840]	train-rmse:1.03277	valid-rmse:1.03648
[120]	train-rmse:0.99439	valid-rmse:0.99892
[100]	train-rmse:0.99583	valid-rmse:0.99922
[860]	train-rmse:1.03187	valid-rmse:1.03556
[20]	train-rmse:1.02211	valid-rmse:1.02559
[120]	train-rmse:0.99487	valid-rmse:0.99885
[880]	train-rmse:1.03100	valid-rmse:1.03467
[140]	train-rmse:0.99386	valid-rmse:0.99900
[120]	train-rmse:0.99518	valid-rmse:0.99891
[80]	train-rmse:1.00485	valid-rmse:1.00801
[140]	train-rmse:0.99434	valid-rmse:0.99882
[40]	train-rmse:1.00295	valid-rmse:1.00606
[900]	train-rmse:1.03014	valid-rmse:1.03379
[157]	train-rmse:0.99341	valid-rmse:0.99910
[32m[I 2022-04-15 10:42:28,700][0m Trial 109 finished with value: 0.998871 and parameters: {'colsample_bytree': 0.4259309523554826, 'eta': 0.03600733549880409, 'max_depth': 3, 'n_estimators': 222, 'subsample': 0.8276550886943445}. Best is trial 65 with value: 0.998642.[0m
[10:42:33] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[140]	train-rmse:0.99465	valid-rmse:0.99876
[920]	train-rmse:1.02930	valid-rmse:1.03293
[160]	train-rmse:0.99386	valid-rmse:0.99886
[60]	train-rmse:0.99765	valid-rmse:1.00075
[940]	train-rmse:1.02849	valid-rmse:1.03210
[160]	train-rmse:0.99417	valid-rmse:0.99875
[20]	train-rmse:1.09960	valid-rmse:1.10451
[100]	train-rmse:1.00076	valid-rmse:1.00381
[176]	train-rmse:0.99354	valid-rmse:0.99885
[32m[I 2022-04-15 10:43:38,399][0m Trial 108 finished with value: 0.9988 and parameters: {'colsample_bytree': 0.4849308855881854, 'eta': 0.031051992362144537, 'max_depth': 3, 'n_estimators': 704, 'subsample': 0.8153547874873232}. Best is trial 65 with value: 0.998642.[0m
[10:43:42] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[960]	train-rmse:1.02769	valid-rmse:1.03129
[80]	train-rmse:0.99587	valid-rmse:0.99931
[0]	train-rmse:1.08619	valid-rmse:1.09091
[180]	train-rmse:0.99374	valid-rmse:0.99870
[40]	train-rmse:1.09960	valid-rmse:1.10451
[980]	train-rmse:1.02692	valid-rmse:1.03050
[20]	train-rmse:1.00131	valid-rmse:1.00418
[100]	train-rmse:0.99503	valid-rmse:0.99892
[999]	train-rmse:1.02620	valid-rmse:1.02976
[32m[I 2022-04-15 10:44:44,618][0m Trial 100 finished with value: 1.029762 and parameters: {'colsample_bytree': 0.2788722940195848, 'eta': 0.000648168537621453, 'max_depth': 3, 'n_estimators': 899, 'subsample': 0.7874047290733}. Best is trial 65 with value: 0.998642.[0m
[120]	train-rmse:0.99847	valid-rmse:1.00151
[10:44:49] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09960	valid-rmse:1.10451
[200]	train-rmse:0.99331	valid-rmse:0.99872
[60]	train-rmse:1.09960	valid-rmse:1.10451
[40]	train-rmse:0.99568	valid-rmse:0.99913
[120]	train-rmse:0.99443	valid-rmse:0.99889
[74]	train-rmse:1.09960	valid-rmse:1.10451
[32m[I 2022-04-15 10:45:48,224][0m Trial 112 finished with value: 1.104512 and parameters: {'colsample_bytree': 0.538358450481262, 'eta': 1.2717648360994502e-08, 'max_depth': 3, 'n_estimators': 924, 'subsample': 0.7672300967873718}. Best is trial 65 with value: 0.998642.[0m
[60]	train-rmse:0.99440	valid-rmse:0.99881
[220]	train-rmse:0.99291	valid-rmse:0.99873
[10:45:53] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09593	valid-rmse:1.10082
[20]	train-rmse:1.09960	valid-rmse:1.10451
[140]	train-rmse:0.99713	valid-rmse:1.00024
[80]	train-rmse:0.99336	valid-rmse:0.99908
[20]	train-rmse:1.04388	valid-rmse:1.04789
[140]	train-rmse:0.99389	valid-rmse:0.99893
[240]	train-rmse:0.99251	valid-rmse:0.99881
[32m[I 2022-04-15 10:46:49,412][0m Trial 110 finished with value: 0.998658 and parameters: {'colsample_bytree': 0.4934832655303232, 'eta': 0.028000308765852338, 'max_depth': 3, 'n_estimators': 115, 'subsample': 0.7560371852695829}. Best is trial 65 with value: 0.998642.[0m
[10:46:54] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[40]	train-rmse:1.01883	valid-rmse:1.02227
[40]	train-rmse:1.09960	valid-rmse:1.10451
[0]	train-rmse:1.08473	valid-rmse:1.08943
[100]	train-rmse:0.99243	valid-rmse:0.99926
[160]	train-rmse:0.99335	valid-rmse:0.99899
[60]	train-rmse:1.00696	valid-rmse:1.01005
[110]	train-rmse:0.99196	valid-rmse:0.99936
[163]	train-rmse:0.99328	valid-rmse:0.99899
[32m[I 2022-04-15 10:47:40,490][0m Trial 113 finished with value: 0.9988 and parameters: {'colsample_bytree': 0.37434528214401935, 'eta': 0.07181720836980578, 'max_depth': 3, 'n_estimators': 847, 'subsample': 0.7549677403257671}. Best is trial 65 with value: 0.998642.[0m
[32m[I 2022-04-15 10:47:41,059][0m Trial 111 finished with value: 0.998862 and parameters: {'colsample_bytree': 0.5432466126477073, 'eta': 0.033885254203839824, 'max_depth': 3, 'n_estimators': 932, 'subsample': 0.7554156025784372}. Best is trial 65 with value: 0.998642.[0m
[10:47:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[10:47:45] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09675	valid-rmse:1.10163
[0]	train-rmse:1.09678	valid-rmse:1.10167
[160]	train-rmse:0.99628	valid-rmse:0.99953
[20]	train-rmse:0.99975	valid-rmse:1.00267
[60]	train-rmse:1.09960	valid-rmse:1.10451
[80]	train-rmse:1.00127	valid-rmse:1.00419
[64]	train-rmse:1.09960	valid-rmse:1.10451
[32m[I 2022-04-15 10:48:14,750][0m Trial 114 finished with value: 1.104512 and parameters: {'colsample_bytree': 0.5435192476139614, 'eta': 1.3523736420271945e-08, 'max_depth': 3, 'n_estimators': 842, 'subsample': 0.850223124525561}. Best is trial 65 with value: 0.998642.[0m
[10:48:19] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09563	valid-rmse:1.10048
[100]	train-rmse:0.99847	valid-rmse:1.00136
[20]	train-rmse:1.05341	valid-rmse:1.05761
[20]	train-rmse:1.05307	valid-rmse:1.05729
[40]	train-rmse:0.99531	valid-rmse:0.99926
[120]	train-rmse:0.99704	valid-rmse:1.00003
[20]	train-rmse:1.04077	valid-rmse:1.04469
[180]	train-rmse:0.99571	valid-rmse:0.99911
[140]	train-rmse:0.99620	valid-rmse:0.99932
[40]	train-rmse:1.02854	valid-rmse:1.03224
[40]	train-rmse:1.02817	valid-rmse:1.03184
[60]	train-rmse:0.99392	valid-rmse:0.99909
[160]	train-rmse:0.99566	valid-rmse:0.99898
[40]	train-rmse:1.01596	valid-rmse:1.01941
[180]	train-rmse:0.99526	valid-rmse:0.99882
[60]	train-rmse:1.01446	valid-rmse:1.01785
[60]	train-rmse:1.01414	valid-rmse:1.01750
[80]	train-rmse:0.99278	valid-rmse:0.99952
[200]	train-rmse:0.99493	valid-rmse:0.99874
[60]	train-rmse:1.00493	valid-rmse:1.00803
[200]	train-rmse:0.99529	valid-rmse:0.99890
[80]	train-rmse:1.00647	valid-rmse:1.00962
[220]	train-rmse:0.99463	valid-rmse:0.99868
[80]	train-rmse:1.00622	valid-rmse:1.00939
[100]	train-rmse:0.99180	valid-rmse:0.99961
[80]	train-rmse:0.99993	valid-rmse:1.00300
[240]	train-rmse:0.99440	valid-rmse:0.99875
[110]	train-rmse:0.99122	valid-rmse:0.99970
[32m[I 2022-04-15 10:52:03,866][0m Trial 116 finished with value: 0.999088 and parameters: {'colsample_bytree': 0.539583747522389, 'eta': 0.07989879091974579, 'max_depth': 3, 'n_estimators': 158, 'subsample': 0.7507742336855124}. Best is trial 65 with value: 0.998642.[0m
[100]	train-rmse:1.00192	valid-rmse:1.00497
[10:52:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09651	valid-rmse:1.10137
[260]	train-rmse:0.99413	valid-rmse:0.99879
[100]	train-rmse:1.00173	valid-rmse:1.00479
[268]	train-rmse:0.99402	valid-rmse:0.99879
[220]	train-rmse:0.99496	valid-rmse:0.99873
[100]	train-rmse:0.99761	valid-rmse:1.00065
[32m[I 2022-04-15 10:52:37,209][0m Trial 115 finished with value: 0.998679 and parameters: {'colsample_bytree': 0.20546768914019994, 'eta': 0.019203858256510938, 'max_depth': 3, 'n_estimators': 849, 'subsample': 0.8480245513141487}. Best is trial 65 with value: 0.998642.[0m
[10:52:41] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09665	valid-rmse:1.10152
[120]	train-rmse:0.99930	valid-rmse:1.00233
[20]	train-rmse:1.05014	valid-rmse:1.05422
[120]	train-rmse:0.99915	valid-rmse:1.00226
[120]	train-rmse:0.99640	valid-rmse:0.99958
[20]	train-rmse:1.05188	valid-rmse:1.05602
[140]	train-rmse:0.99771	valid-rmse:1.00077
[40]	train-rmse:1.02499	valid-rmse:1.02858
[240]	train-rmse:0.99466	valid-rmse:0.99871
[40]	train-rmse:1.02684	valid-rmse:1.03054
[140]	train-rmse:0.99567	valid-rmse:0.99906
[140]	train-rmse:0.99760	valid-rmse:1.00071
[160]	train-rmse:0.99672	valid-rmse:0.99990
[60]	train-rmse:1.01304	valid-rmse:1.01637
[60]	train-rmse:1.01156	valid-rmse:1.01475
[160]	train-rmse:0.99518	valid-rmse:0.99884
[160]	train-rmse:0.99662	valid-rmse:0.99985
[180]	train-rmse:0.99607	valid-rmse:0.99937
[80]	train-rmse:1.00544	valid-rmse:1.00866
[260]	train-rmse:0.99438	valid-rmse:0.99869
[80]	train-rmse:1.00433	valid-rmse:1.00742
[180]	train-rmse:0.99477	valid-rmse:0.99873
[180]	train-rmse:0.99598	valid-rmse:0.99933
[100]	train-rmse:1.00120	valid-rmse:1.00430
[200]	train-rmse:0.99560	valid-rmse:0.99912
[100]	train-rmse:1.00044	valid-rmse:1.00340
[200]	train-rmse:0.99441	valid-rmse:0.99883
[120]	train-rmse:0.99880	valid-rmse:1.00188
[200]	train-rmse:0.99553	valid-rmse:0.99903
[220]	train-rmse:0.99525	valid-rmse:0.99893
[280]	train-rmse:0.99410	valid-rmse:0.99865
[140]	train-rmse:0.99735	valid-rmse:1.00049
[120]	train-rmse:0.99828	valid-rmse:1.00127
[220]	train-rmse:0.99406	valid-rmse:0.99884
[240]	train-rmse:0.99497	valid-rmse:0.99883
[220]	train-rmse:0.99516	valid-rmse:0.99887
[231]	train-rmse:0.99387	valid-rmse:0.99889
[32m[I 2022-04-15 10:57:48,135][0m Trial 119 finished with value: 0.998724 and parameters: {'colsample_bytree': 0.5118188343438569, 'eta': 0.020819177580911237, 'max_depth': 3, 'n_estimators': 107, 'subsample': 0.6972231760105584}. Best is trial 65 with value: 0.998642.[0m
[10:57:52] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[160]	train-rmse:0.99647	valid-rmse:0.99975
[0]	train-rmse:1.09641	valid-rmse:1.10129
[140]	train-rmse:0.99699	valid-rmse:1.00009
[300]	train-rmse:0.99384	valid-rmse:0.99868
[260]	train-rmse:0.99470	valid-rmse:0.99877
[180]	train-rmse:0.99587	valid-rmse:0.99930
[240]	train-rmse:0.99487	valid-rmse:0.99875
[20]	train-rmse:1.04907	valid-rmse:1.05318
[160]	train-rmse:0.99620	valid-rmse:0.99944
[200]	train-rmse:0.99546	valid-rmse:0.99909
[280]	train-rmse:0.99446	valid-rmse:0.99873
[260]	train-rmse:0.99459	valid-rmse:0.99869
[40]	train-rmse:1.02389	valid-rmse:1.02751
[220]	train-rmse:0.99511	valid-rmse:0.99897
[319]	train-rmse:0.99360	valid-rmse:0.99869
[180]	train-rmse:0.99565	valid-rmse:0.99906
[32m[I 2022-04-15 10:59:42,938][0m Trial 107 finished with value: 0.998639 and parameters: {'colsample_bytree': 0.9622094492522866, 'eta': 0.01573125023853601, 'max_depth': 3, 'n_estimators': 142, 'subsample': 0.8156168642648772}. Best is trial 107 with value: 0.998639.[0m
[10:59:47] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09669	valid-rmse:1.10159
[300]	train-rmse:0.99423	valid-rmse:0.99874
[280]	train-rmse:0.99435	valid-rmse:0.99864
[240]	train-rmse:0.99482	valid-rmse:0.99889
[60]	train-rmse:1.01065	valid-rmse:1.01391
[200]	train-rmse:0.99527	valid-rmse:0.99891
[320]	train-rmse:0.99399	valid-rmse:0.99873
[260]	train-rmse:0.99455	valid-rmse:0.99885
[300]	train-rmse:0.99411	valid-rmse:0.99865
[20]	train-rmse:1.05234	valid-rmse:1.05648
[80]	train-rmse:1.00368	valid-rmse:1.00680
[336]	train-rmse:0.99381	valid-rmse:0.99875
[220]	train-rmse:0.99493	valid-rmse:0.99879
[32m[I 2022-04-15 11:01:17,983][0m Trial 118 finished with value: 0.998703 and parameters: {'colsample_bytree': 0.5032063967500237, 'eta': 0.014727099454964218, 'max_depth': 3, 'n_estimators': 110, 'subsample': 0.7431787599223871}. Best is trial 107 with value: 0.998639.[0m
[11:01:23] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[280]	train-rmse:0.99432	valid-rmse:0.99883
[0]	train-rmse:1.09884	valid-rmse:1.10375
[100]	train-rmse:0.99997	valid-rmse:1.00301
[320]	train-rmse:0.99385	valid-rmse:0.99865
[300]	train-rmse:0.99409	valid-rmse:0.99883
[240]	train-rmse:0.99465	valid-rmse:0.99877
[326]	train-rmse:0.99377	valid-rmse:0.99866
[32m[I 2022-04-15 11:02:07,935][0m Trial 117 finished with value: 0.998633 and parameters: {'colsample_bytree': 0.5661475189819565, 'eta': 0.014870874504292239, 'max_depth': 3, 'n_estimators': 113, 'subsample': 0.735240002277884}. Best is trial 117 with value: 0.998633.[0m
[40]	train-rmse:1.02733	valid-rmse:1.03100
[11:02:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.07261	valid-rmse:1.07780
[120]	train-rmse:0.99796	valid-rmse:1.00101
[320]	train-rmse:0.99386	valid-rmse:0.99886
[260]	train-rmse:0.99437	valid-rmse:0.99874
[336]	train-rmse:0.99367	valid-rmse:0.99890
[32m[I 2022-04-15 11:03:12,518][0m Trial 121 finished with value: 0.998809 and parameters: {'colsample_bytree': 0.40143218784989076, 'eta': 0.015398223162288055, 'max_depth': 3, 'n_estimators': 764, 'subsample': 0.6821187514422197}. Best is trial 117 with value: 0.998633.[0m
[11:03:17] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.01342	valid-rmse:1.01684
[140]	train-rmse:0.99679	valid-rmse:0.99995
[0]	train-rmse:1.09094	valid-rmse:1.09570
[20]	train-rmse:1.08445	valid-rmse:1.08941
[280]	train-rmse:0.99412	valid-rmse:0.99877
[160]	train-rmse:0.99606	valid-rmse:0.99936
[300]	train-rmse:0.99389	valid-rmse:0.99881
[80]	train-rmse:1.00567	valid-rmse:1.00895
[20]	train-rmse:0.98950	valid-rmse:1.00002
[20]	train-rmse:1.01188	valid-rmse:1.01518
[180]	train-rmse:0.99556	valid-rmse:0.99904
[310]	train-rmse:0.99377	valid-rmse:0.99884
[32m[I 2022-04-15 11:04:54,761][0m Trial 120 finished with value: 0.998733 and parameters: {'colsample_bytree': 0.5637711738344126, 'eta': 0.016171012965277246, 'max_depth': 3, 'n_estimators': 68, 'subsample': 0.7000391887558043}. Best is trial 117 with value: 0.998633.[0m
[11:04:59] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09876	valid-rmse:1.10366
[40]	train-rmse:1.07197	valid-rmse:1.07701
[100]	train-rmse:1.00132	valid-rmse:1.00448
[200]	train-rmse:0.99518	valid-rmse:0.99893
[40]	train-rmse:0.99851	valid-rmse:1.00154
[20]	train-rmse:1.08312	valid-rmse:1.08777
[220]	train-rmse:0.99489	valid-rmse:0.99886
[40]	train-rmse:0.98246	valid-rmse:1.00067
[120]	train-rmse:0.99884	valid-rmse:1.00201
[40]	train-rmse:1.06981	valid-rmse:1.07423
[60]	train-rmse:0.99581	valid-rmse:0.99920
[240]	train-rmse:0.99463	valid-rmse:0.99882
[60]	train-rmse:1.06114	valid-rmse:1.06625
[60]	train-rmse:1.05849	valid-rmse:1.06273
[140]	train-rmse:0.99733	valid-rmse:1.00058
[260]	train-rmse:0.99437	valid-rmse:0.99881
[80]	train-rmse:0.99465	valid-rmse:0.99887
[80]	train-rmse:1.04888	valid-rmse:1.05296
[280]	train-rmse:0.99408	valid-rmse:0.99879
[160]	train-rmse:0.99641	valid-rmse:0.99976
[60]	train-rmse:0.97534	valid-rmse:1.00137
[100]	train-rmse:1.04074	valid-rmse:1.04466
[300]	train-rmse:0.99384	valid-rmse:0.99878
[80]	train-rmse:1.05176	valid-rmse:1.05695
[100]	train-rmse:0.99394	valid-rmse:0.99878
[68]	train-rmse:0.97222	valid-rmse:1.00224
[32m[I 2022-04-15 11:10:08,777][0m Trial 125 finished with value: 0.999958 and parameters: {'colsample_bytree': 0.9473163714578839, 'eta': 0.14667169063954014, 'max_depth': 5, 'n_estimators': 76, 'subsample': 0.8071906894753437}. Best is trial 117 with value: 0.998633.[0m
[11:10:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[180]	train-rmse:0.99578	valid-rmse:0.99929
[0]	train-rmse:1.09884	valid-rmse:1.10374
[320]	train-rmse:0.99357	valid-rmse:0.99883
[120]	train-rmse:1.03385	valid-rmse:1.03765
[120]	train-rmse:0.99332	valid-rmse:0.99888
[340]	train-rmse:0.99333	valid-rmse:0.99888
[20]	train-rmse:1.08449	valid-rmse:1.08917
[140]	train-rmse:1.02800	valid-rmse:1.03170
[200]	train-rmse:0.99532	valid-rmse:0.99905
[347]	train-rmse:0.99325	valid-rmse:0.99890
[32m[I 2022-04-15 11:11:27,664][0m Trial 122 finished with value: 0.998759 and parameters: {'colsample_bytree': 0.5110223396737993, 'eta': 0.016663999075705167, 'max_depth': 3, 'n_estimators': 121, 'subsample': 0.8029580766817149}. Best is trial 117 with value: 0.998633.[0m
[11:11:32] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09042	valid-rmse:1.09521
[100]	train-rmse:1.04364	valid-rmse:1.04891
[40]	train-rmse:1.07209	valid-rmse:1.07658
[160]	train-rmse:1.02306	valid-rmse:1.02665
[140]	train-rmse:0.99268	valid-rmse:0.99898
[20]	train-rmse:1.01011	valid-rmse:1.01325
[220]	train-rmse:0.99495	valid-rmse:0.99893
[60]	train-rmse:1.06141	valid-rmse:1.06571
[149]	train-rmse:0.99236	valid-rmse:0.99902
[32m[I 2022-04-15 11:13:01,568][0m Trial 126 finished with value: 0.998775 and parameters: {'colsample_bytree': 0.9354552924071725, 'eta': 0.04577956882193327, 'max_depth': 3, 'n_estimators': 116, 'subsample': 0.799761331788525}. Best is trial 117 with value: 0.998633.[0m
[180]	train-rmse:1.01887	valid-rmse:1.02235
[11:13:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09469	valid-rmse:1.09954
[40]	train-rmse:0.99790	valid-rmse:1.00092
[80]	train-rmse:1.05220	valid-rmse:1.05634
[240]	train-rmse:0.99462	valid-rmse:0.99886
[120]	train-rmse:1.03662	valid-rmse:1.04201
[200]	train-rmse:1.01535	valid-rmse:1.01875
[60]	train-rmse:0.99560	valid-rmse:0.99894
[20]	train-rmse:1.03258	valid-rmse:1.03632
[100]	train-rmse:1.04428	valid-rmse:1.04828
[80]	train-rmse:0.99461	valid-rmse:0.99866
[220]	train-rmse:1.01236	valid-rmse:1.01567
[40]	train-rmse:1.00947	valid-rmse:1.01272
[260]	train-rmse:0.99433	valid-rmse:0.99884
[120]	train-rmse:1.03747	valid-rmse:1.04135
[100]	train-rmse:0.99390	valid-rmse:0.99890
[60]	train-rmse:1.00095	valid-rmse:1.00394
[240]	train-rmse:1.00984	valid-rmse:1.01307
[140]	train-rmse:1.03053	valid-rmse:1.03602
[280]	train-rmse:0.99406	valid-rmse:0.99882
[140]	train-rmse:1.03159	valid-rmse:1.03539
[120]	train-rmse:0.99320	valid-rmse:0.99897
[80]	train-rmse:0.99763	valid-rmse:1.00071
[260]	train-rmse:1.00771	valid-rmse:1.01090
[128]	train-rmse:0.99294	valid-rmse:0.99898
[32m[I 2022-04-15 11:16:52,202][0m Trial 129 finished with value: 0.998608 and parameters: {'colsample_bytree': 0.5767472439671071, 'eta': 0.048579631770603864, 'max_depth': 3, 'n_estimators': 150, 'subsample': 0.7297237737210818}. Best is trial 129 with value: 0.998608.[0m
[11:16:56] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[160]	train-rmse:1.02655	valid-rmse:1.03024
[0]	train-rmse:1.09468	valid-rmse:1.09955
[300]	train-rmse:0.99383	valid-rmse:0.99882
[100]	train-rmse:0.99620	valid-rmse:0.99950
[280]	train-rmse:1.00589	valid-rmse:1.00906
[20]	train-rmse:1.03252	valid-rmse:1.03633
[180]	train-rmse:1.02221	valid-rmse:1.02580
[160]	train-rmse:1.02526	valid-rmse:1.03087
[120]	train-rmse:0.99542	valid-rmse:0.99906
[300]	train-rmse:1.00436	valid-rmse:1.00749
[320]	train-rmse:0.99358	valid-rmse:0.99886
[40]	train-rmse:1.00937	valid-rmse:1.01263
[200]	train-rmse:1.01851	valid-rmse:1.02201
[140]	train-rmse:0.99489	valid-rmse:0.99884
[320]	train-rmse:1.00306	valid-rmse:1.00614
[60]	train-rmse:1.00084	valid-rmse:1.00400
[220]	train-rmse:1.01532	valid-rmse:1.01873
[340]	train-rmse:0.99333	valid-rmse:0.99888
[180]	train-rmse:1.02068	valid-rmse:1.02642
[160]	train-rmse:0.99443	valid-rmse:0.99880
[340]	train-rmse:1.00195	valid-rmse:1.00502
[240]	train-rmse:1.01260	valid-rmse:1.01593
[80]	train-rmse:0.99756	valid-rmse:1.00079
[353]	train-rmse:0.99318	valid-rmse:0.99887
[32m[I 2022-04-15 11:20:56,942][0m Trial 123 finished with value: 0.998808 and parameters: {'colsample_bytree': 0.9299193410254273, 'eta': 0.01518469562228257, 'max_depth': 3, 'n_estimators': 89, 'subsample': 0.6748390971322322}. Best is trial 129 with value: 0.998608.[0m
[11:21:02] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09469	valid-rmse:1.09953
[180]	train-rmse:0.99403	valid-rmse:0.99869
[360]	train-rmse:1.00100	valid-rmse:1.00406
[260]	train-rmse:1.01024	valid-rmse:1.01352
[100]	train-rmse:0.99614	valid-rmse:0.99958
[200]	train-rmse:0.99361	valid-rmse:0.99869
[20]	train-rmse:1.03258	valid-rmse:1.03632
[380]	train-rmse:1.00019	valid-rmse:1.00324
[280]	train-rmse:1.00822	valid-rmse:1.01145
[120]	train-rmse:0.99540	valid-rmse:0.99917
[200]	train-rmse:1.01673	valid-rmse:1.02261
[220]	train-rmse:0.99320	valid-rmse:0.99872
[300]	train-rmse:1.00648	valid-rmse:1.00967
[140]	train-rmse:0.99485	valid-rmse:0.99900
[400]	train-rmse:0.99952	valid-rmse:1.00256
[40]	train-rmse:1.00946	valid-rmse:1.01269
[240]	train-rmse:0.99280	valid-rmse:0.99875
[160]	train-rmse:0.99440	valid-rmse:0.99894
[320]	train-rmse:1.00500	valid-rmse:1.00815
[420]	train-rmse:0.99892	valid-rmse:1.00196
[250]	train-rmse:0.99262	valid-rmse:0.99874
[220]	train-rmse:1.01333	valid-rmse:1.01931
[32m[I 2022-04-15 11:24:57,626][0m Trial 130 finished with value: 0.998669 and parameters: {'colsample_bytree': 0.6071797230121726, 'eta': 0.02573751189292882, 'max_depth': 3, 'n_estimators': 188, 'subsample': 0.7325935360704777}. Best is trial 129 with value: 0.998608.[0m
[11:25:03] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.00089	valid-rmse:1.00389
[0]	train-rmse:1.09486	valid-rmse:1.09971
[180]	train-rmse:0.99400	valid-rmse:0.99889
[340]	train-rmse:1.00371	valid-rmse:1.00683
[440]	train-rmse:0.99841	valid-rmse:1.00146
[20]	train-rmse:1.03399	valid-rmse:1.03771
[360]	train-rmse:1.00261	valid-rmse:1.00570
[80]	train-rmse:0.99752	valid-rmse:1.00059
[200]	train-rmse:0.99359	valid-rmse:0.99896
[460]	train-rmse:0.99798	valid-rmse:1.00104
2022-04-15 11:30:57.899 | WARNING  | qlib.tests.data:qlib_data:150 - Data already exists: ~/igorlima/igor_tcc/qlib_data/br_data, the data download will be skipped
	If downloading is required: `exists_skip=False` or `change target_dir`
[115868:MainThread](2022-04-15 11:30:57,899) INFO - qlib.Initialization - [config.py:402] - default_conf: client.
[115868:MainThread](2022-04-15 11:30:58,231) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.
[115868:MainThread](2022-04-15 11:30:58,231) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/lisa/igorlima/igor_tcc/qlib_data/br_data')}
[115868:MainThread](2022-04-15 11:30:58,231) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:83] - Dataset intialization
[115868:MainThread](2022-04-15 11:31:06,878) INFO - qlib.timer - [log.py:113] - Time cost: 8.643s | Loading data Done
[115868:MainThread](2022-04-15 11:31:07,054) INFO - qlib.timer - [log.py:113] - Time cost: 0.063s | DropnaLabel Done
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/data/dataset/processor.py:347: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[cols] = t
[115868:MainThread](2022-04-15 11:31:07,218) INFO - qlib.timer - [log.py:113] - Time cost: 0.163s | CSRankNorm Done
[115868:MainThread](2022-04-15 11:31:07,218) INFO - qlib.timer - [log.py:113] - Time cost: 0.340s | fit & process data Done
[115868:MainThread](2022-04-15 11:31:07,219) INFO - qlib.timer - [log.py:113] - Time cost: 8.985s | Init data Done
[115868:MainThread](2022-04-15 11:31:07,219) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:86] - Start parameter tuning
[11:31:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[11:31:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[11:31:14] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[11:31:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[11:31:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09920	valid-rmse:1.10400
[11:31:17] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09920	valid-rmse:1.10400
[0]	train-rmse:1.09601	valid-rmse:1.10084
[0]	train-rmse:1.09909	valid-rmse:1.10390
[0]	train-rmse:1.09653	valid-rmse:1.10142
[0]	train-rmse:1.09920	valid-rmse:1.10400
[20]	train-rmse:1.09920	valid-rmse:1.10400
[40]	train-rmse:1.09920	valid-rmse:1.10400
[20]	train-rmse:1.04828	valid-rmse:1.05360
[20]	train-rmse:1.09918	valid-rmse:1.10399
[60]	train-rmse:1.09920	valid-rmse:1.10400
[20]	train-rmse:1.05428	valid-rmse:1.06123
[80]	train-rmse:1.09920	valid-rmse:1.10400
[20]	train-rmse:1.09916	valid-rmse:1.10397
[100]	train-rmse:1.09919	valid-rmse:1.10400
[40]	train-rmse:1.02222	valid-rmse:1.02810
[20]	train-rmse:1.09680	valid-rmse:1.10181
[40]	train-rmse:1.09917	valid-rmse:1.10397
[40]	train-rmse:1.02750	valid-rmse:1.03679
[120]	train-rmse:1.09919	valid-rmse:1.10400
[140]	train-rmse:1.09919	valid-rmse:1.10400
[60]	train-rmse:1.00804	valid-rmse:1.01445
[160]	train-rmse:1.09919	valid-rmse:1.10400
[60]	train-rmse:1.01042	valid-rmse:1.02186
[60]	train-rmse:1.09915	valid-rmse:1.10396
[180]	train-rmse:1.09919	valid-rmse:1.10400
[40]	train-rmse:1.09913	valid-rmse:1.10393
[200]	train-rmse:1.09919	valid-rmse:1.10400
[80]	train-rmse:1.00013	valid-rmse:1.00719
[220]	train-rmse:1.09919	valid-rmse:1.10400
[40]	train-rmse:1.09456	valid-rmse:1.09976
[80]	train-rmse:0.99933	valid-rmse:1.01288
[80]	train-rmse:1.09914	valid-rmse:1.10394
[240]	train-rmse:1.09919	valid-rmse:1.10400
[100]	train-rmse:0.99558	valid-rmse:1.00336
[260]	train-rmse:1.09919	valid-rmse:1.10399
[60]	train-rmse:1.09909	valid-rmse:1.10390
[280]	train-rmse:1.09919	valid-rmse:1.10399
[100]	train-rmse:0.99222	valid-rmse:1.00742
[100]	train-rmse:1.09912	valid-rmse:1.10393
[300]	train-rmse:1.09919	valid-rmse:1.10399
[120]	train-rmse:0.99281	valid-rmse:1.00120
[320]	train-rmse:1.09919	valid-rmse:1.10399
[60]	train-rmse:1.09234	valid-rmse:1.09775
[120]	train-rmse:0.98741	valid-rmse:1.00412
[340]	train-rmse:1.09919	valid-rmse:1.10399
[120]	train-rmse:1.09910	valid-rmse:1.10391
[140]	train-rmse:0.99096	valid-rmse:1.00009
[360]	train-rmse:1.09919	valid-rmse:1.10399
[80]	train-rmse:1.09905	valid-rmse:1.10386
[380]	train-rmse:1.09919	valid-rmse:1.10399
[140]	train-rmse:0.98382	valid-rmse:1.00218
[140]	train-rmse:1.09909	valid-rmse:1.10390
[400]	train-rmse:1.09919	valid-rmse:1.10399
[160]	train-rmse:0.98954	valid-rmse:0.99952
[420]	train-rmse:1.09918	valid-rmse:1.10399
[440]	train-rmse:1.09918	valid-rmse:1.10399
[160]	train-rmse:0.98115	valid-rmse:1.00099
[80]	train-rmse:1.09016	valid-rmse:1.09578
[100]	train-rmse:1.09902	valid-rmse:1.10383
[160]	train-rmse:1.09908	valid-rmse:1.10388
[180]	train-rmse:0.98834	valid-rmse:0.99923
[460]	train-rmse:1.09918	valid-rmse:1.10399
[480]	train-rmse:1.09918	valid-rmse:1.10399
[180]	train-rmse:0.97885	valid-rmse:1.00024
[500]	train-rmse:1.09918	valid-rmse:1.10398
[200]	train-rmse:0.98719	valid-rmse:0.99909
[180]	train-rmse:1.09906	valid-rmse:1.10387
[520]	train-rmse:1.09918	valid-rmse:1.10398
[120]	train-rmse:1.09898	valid-rmse:1.10379
[540]	train-rmse:1.09918	valid-rmse:1.10398
[200]	train-rmse:0.97691	valid-rmse:0.99984
[100]	train-rmse:1.08802	valid-rmse:1.09385
[220]	train-rmse:0.98630	valid-rmse:0.99898
[560]	train-rmse:1.09918	valid-rmse:1.10398
[200]	train-rmse:1.09904	valid-rmse:1.10385
[580]	train-rmse:1.09918	valid-rmse:1.10398
[220]	train-rmse:0.97510	valid-rmse:0.99957
[600]	train-rmse:1.09918	valid-rmse:1.10398
[240]	train-rmse:0.98535	valid-rmse:0.99894
[220]	train-rmse:1.09903	valid-rmse:1.10384
[140]	train-rmse:1.09895	valid-rmse:1.10376
[620]	train-rmse:1.09918	valid-rmse:1.10398
[640]	train-rmse:1.09918	valid-rmse:1.10398
[240]	train-rmse:0.97356	valid-rmse:0.99942
[120]	train-rmse:1.08590	valid-rmse:1.09196
[260]	train-rmse:0.98446	valid-rmse:0.99886
[660]	train-rmse:1.09918	valid-rmse:1.10398
[240]	train-rmse:1.09901	valid-rmse:1.10382
[680]	train-rmse:1.09918	valid-rmse:1.10398
[700]	train-rmse:1.09917	valid-rmse:1.10398
[260]	train-rmse:0.97224	valid-rmse:0.99934
[160]	train-rmse:1.09891	valid-rmse:1.10372
[280]	train-rmse:0.98361	valid-rmse:0.99888
[720]	train-rmse:1.09917	valid-rmse:1.10398
[260]	train-rmse:1.09899	valid-rmse:1.10381
[740]	train-rmse:1.09917	valid-rmse:1.10397
[300]	train-rmse:0.98269	valid-rmse:0.99892
[280]	train-rmse:0.97064	valid-rmse:0.99933
[760]	train-rmse:1.09917	valid-rmse:1.10397
[140]	train-rmse:1.08384	valid-rmse:1.09010
[780]	train-rmse:1.09917	valid-rmse:1.10397
[280]	train-rmse:1.09898	valid-rmse:1.10379
[312]	train-rmse:0.98208	valid-rmse:0.99890
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import MultiIndex, Int64Index
[32m[I 2022-04-15 11:51:48,998][0m Trial 2 finished with value: 0.998858 and parameters: {'colsample_bytree': 0.5179882902095794, 'eta': 0.016418908893338465, 'max_depth': 5, 'n_estimators': 939, 'subsample': 0.7725605196130021}. Best is trial 2 with value: 0.998858.[0m
[180]	train-rmse:1.09887	valid-rmse:1.10369
[11:51:54] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[800]	train-rmse:1.09917	valid-rmse:1.10397
[0]	train-rmse:1.07707	valid-rmse:1.08193
[300]	train-rmse:0.96902	valid-rmse:0.99935
[820]	train-rmse:1.09917	valid-rmse:1.10397
[840]	train-rmse:1.09917	valid-rmse:1.10397
[300]	train-rmse:1.09896	valid-rmse:1.10377
[860]	train-rmse:1.09917	valid-rmse:1.10397
[320]	train-rmse:0.96741	valid-rmse:0.99935
[160]	train-rmse:1.08181	valid-rmse:1.08828
[880]	train-rmse:1.09917	valid-rmse:1.10397
[324]	train-rmse:0.96714	valid-rmse:0.99935
[200]	train-rmse:1.09884	valid-rmse:1.10365
[32m[I 2022-04-15 11:54:05,696][0m Trial 5 finished with value: 0.999315 and parameters: {'colsample_bytree': 0.2739470667224804, 'eta': 0.013187324364481324, 'max_depth': 7, 'n_estimators': 569, 'subsample': 0.9849582588433994}. Best is trial 2 with value: 0.998858.[0m
[11:54:11] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09920	valid-rmse:1.10400
[20]	train-rmse:0.98992	valid-rmse:1.00023
[320]	train-rmse:1.09895	valid-rmse:1.10376
[900]	train-rmse:1.09917	valid-rmse:1.10397
[920]	train-rmse:1.09917	valid-rmse:1.10397
[940]	train-rmse:1.09917	valid-rmse:1.10397
[340]	train-rmse:1.09893	valid-rmse:1.10374
[960]	train-rmse:1.09916	valid-rmse:1.10397
[220]	train-rmse:1.09880	valid-rmse:1.10362
[980]	train-rmse:1.09916	valid-rmse:1.10397
[40]	train-rmse:0.98294	valid-rmse:0.99994
[180]	train-rmse:1.07981	valid-rmse:1.08649
[20]	train-rmse:1.09920	valid-rmse:1.10400
[999]	train-rmse:1.09916	valid-rmse:1.10397
[32m[I 2022-04-15 11:57:20,307][0m Trial 0 finished with value: 1.103966 and parameters: {'colsample_bytree': 0.3764805413071612, 'eta': 1.9063905308326283e-07, 'max_depth': 3, 'n_estimators': 700, 'subsample': 0.5126241680999286}. Best is trial 2 with value: 0.998858.[0m
[11:57:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09920	valid-rmse:1.10400
[360]	train-rmse:1.09892	valid-rmse:1.10373
[240]	train-rmse:1.09876	valid-rmse:1.10358
[60]	train-rmse:0.97681	valid-rmse:1.00057
[380]	train-rmse:1.09890	valid-rmse:1.10371
[40]	train-rmse:1.09919	valid-rmse:1.10400
[200]	train-rmse:1.07786	valid-rmse:1.08474
[20]	train-rmse:1.09918	valid-rmse:1.10399
[400]	train-rmse:1.09889	valid-rmse:1.10370
[260]	train-rmse:1.09873	valid-rmse:1.10355
[73]	train-rmse:0.97229	valid-rmse:1.00093
[32m[I 2022-04-15 12:00:54,916][0m Trial 6 finished with value: 0.999719 and parameters: {'colsample_bytree': 0.9256810278687844, 'eta': 0.1184032940256081, 'max_depth': 5, 'n_estimators': 1013, 'subsample': 0.8884646970899595}. Best is trial 2 with value: 0.998858.[0m
[12:00:59] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09919	valid-rmse:1.10399
[60]	train-rmse:1.09919	valid-rmse:1.10400
[420]	train-rmse:1.09887	valid-rmse:1.10368
[220]	train-rmse:1.07593	valid-rmse:1.08303
[40]	train-rmse:1.09916	valid-rmse:1.10397
[280]	train-rmse:1.09869	valid-rmse:1.10351
[20]	train-rmse:1.09888	valid-rmse:1.10371
[440]	train-rmse:1.09885	valid-rmse:1.10367
[80]	train-rmse:1.09919	valid-rmse:1.10400
[460]	train-rmse:1.09884	valid-rmse:1.10365
[300]	train-rmse:1.09866	valid-rmse:1.10348
[240]	train-rmse:1.07403	valid-rmse:1.08134
[60]	train-rmse:1.09914	valid-rmse:1.10395
[40]	train-rmse:1.09858	valid-rmse:1.10343
[480]	train-rmse:1.09882	valid-rmse:1.10364
[100]	train-rmse:1.09919	valid-rmse:1.10399
[320]	train-rmse:1.09862	valid-rmse:1.10344
[500]	train-rmse:1.09881	valid-rmse:1.10362
[60]	train-rmse:1.09828	valid-rmse:1.10315
[80]	train-rmse:1.09912	valid-rmse:1.10393
[260]	train-rmse:1.07216	valid-rmse:1.07970
[120]	train-rmse:1.09919	valid-rmse:1.10399
[520]	train-rmse:1.09879	valid-rmse:1.10361
[340]	train-rmse:1.09858	valid-rmse:1.10341
[80]	train-rmse:1.09798	valid-rmse:1.10287
[100]	train-rmse:1.09911	valid-rmse:1.10392
[540]	train-rmse:1.09878	valid-rmse:1.10359
[280]	train-rmse:1.07036	valid-rmse:1.07808
[140]	train-rmse:1.09919	valid-rmse:1.10399
[360]	train-rmse:1.09855	valid-rmse:1.10337
[560]	train-rmse:1.09876	valid-rmse:1.10358
[100]	train-rmse:1.09768	valid-rmse:1.10259
[120]	train-rmse:1.09909	valid-rmse:1.10390
[580]	train-rmse:1.09875	valid-rmse:1.10356
[300]	train-rmse:1.06858	valid-rmse:1.07649
[160]	train-rmse:1.09918	valid-rmse:1.10399
[380]	train-rmse:1.09851	valid-rmse:1.10334
[120]	train-rmse:1.09738	valid-rmse:1.10232
[600]	train-rmse:1.09873	valid-rmse:1.10355
[140]	train-rmse:1.09907	valid-rmse:1.10388
[400]	train-rmse:1.09848	valid-rmse:1.10330
[620]	train-rmse:1.09871	valid-rmse:1.10353
[180]	train-rmse:1.09918	valid-rmse:1.10398
[320]	train-rmse:1.06682	valid-rmse:1.07493
[140]	train-rmse:1.09708	valid-rmse:1.10204
[640]	train-rmse:1.09870	valid-rmse:1.10352
[160]	train-rmse:1.09905	valid-rmse:1.10386
[420]	train-rmse:1.09844	valid-rmse:1.10327
[200]	train-rmse:1.09918	valid-rmse:1.10398
[340]	train-rmse:1.06509	valid-rmse:1.07341
[660]	train-rmse:1.09868	valid-rmse:1.10350
[160]	train-rmse:1.09678	valid-rmse:1.10176
[440]	train-rmse:1.09840	valid-rmse:1.10323
[680]	train-rmse:1.09867	valid-rmse:1.10349
[180]	train-rmse:1.09903	valid-rmse:1.10385
[220]	train-rmse:1.09918	valid-rmse:1.10398
[180]	train-rmse:1.09649	valid-rmse:1.10149
[360]	train-rmse:1.06338	valid-rmse:1.07192
[700]	train-rmse:1.09865	valid-rmse:1.10347
[460]	train-rmse:1.09837	valid-rmse:1.10320
[200]	train-rmse:1.09901	valid-rmse:1.10383
[240]	train-rmse:1.09918	valid-rmse:1.10398
[720]	train-rmse:1.09864	valid-rmse:1.10346
[200]	train-rmse:1.09620	valid-rmse:1.10122
[380]	train-rmse:1.06171	valid-rmse:1.07046
[480]	train-rmse:1.09833	valid-rmse:1.10316
[740]	train-rmse:1.09862	valid-rmse:1.10344
[260]	train-rmse:1.09917	valid-rmse:1.10398
[220]	train-rmse:1.09899	valid-rmse:1.10381
[220]	train-rmse:1.09590	valid-rmse:1.10094
[760]	train-rmse:1.09860	valid-rmse:1.10343
[500]	train-rmse:1.09830	valid-rmse:1.10313
[400]	train-rmse:1.06007	valid-rmse:1.06902
[780]	train-rmse:1.09859	valid-rmse:1.10341
[280]	train-rmse:1.09917	valid-rmse:1.10397
[240]	train-rmse:1.09898	valid-rmse:1.10380
[240]	train-rmse:1.09560	valid-rmse:1.10067
[520]	train-rmse:1.09826	valid-rmse:1.10309
[800]	train-rmse:1.09857	valid-rmse:1.10339
[420]	train-rmse:1.05846	valid-rmse:1.06761
[300]	train-rmse:1.09917	valid-rmse:1.10397
[820]	train-rmse:1.09856	valid-rmse:1.10338
[260]	train-rmse:1.09896	valid-rmse:1.10378
[260]	train-rmse:1.09531	valid-rmse:1.10040
[540]	train-rmse:1.09822	valid-rmse:1.10306
[840]	train-rmse:1.09854	valid-rmse:1.10336
[440]	train-rmse:1.05688	valid-rmse:1.06623
[320]	train-rmse:1.09917	valid-rmse:1.10397
[280]	train-rmse:1.09894	valid-rmse:1.10376
[280]	train-rmse:1.09502	valid-rmse:1.10012
[560]	train-rmse:1.09819	valid-rmse:1.10303
[860]	train-rmse:1.09853	valid-rmse:1.10335
[880]	train-rmse:1.09851	valid-rmse:1.10333
[340]	train-rmse:1.09916	valid-rmse:1.10397
[460]	train-rmse:1.05532	valid-rmse:1.06489
[300]	train-rmse:1.09472	valid-rmse:1.09985
[300]	train-rmse:1.09892	valid-rmse:1.10374
[580]	train-rmse:1.09815	valid-rmse:1.10299
[900]	train-rmse:1.09850	valid-rmse:1.10332
[920]	train-rmse:1.09848	valid-rmse:1.10330
[600]	train-rmse:1.09812	valid-rmse:1.10296
[320]	train-rmse:1.09443	valid-rmse:1.09958
[360]	train-rmse:1.09916	valid-rmse:1.10397
[320]	train-rmse:1.09890	valid-rmse:1.10373
[480]	train-rmse:1.05378	valid-rmse:1.06356
[940]	train-rmse:1.09847	valid-rmse:1.10329
[620]	train-rmse:1.09808	valid-rmse:1.10292
[340]	train-rmse:1.09414	valid-rmse:1.09931
[380]	train-rmse:1.09916	valid-rmse:1.10396
[340]	train-rmse:1.09888	valid-rmse:1.10371
[960]	train-rmse:1.09845	valid-rmse:1.10327
[500]	train-rmse:1.05227	valid-rmse:1.06226
[980]	train-rmse:1.09843	valid-rmse:1.10326
[640]	train-rmse:1.09804	valid-rmse:1.10289
[360]	train-rmse:1.09385	valid-rmse:1.09904
[400]	train-rmse:1.09916	valid-rmse:1.10396
[360]	train-rmse:1.09886	valid-rmse:1.10369
[999]	train-rmse:1.09842	valid-rmse:1.10324
[32m[I 2022-04-15 12:46:01,894][0m Trial 4 finished with value: 1.103244 and parameters: {'colsample_bytree': 0.6263177982520836, 'eta': 3.905621699908462e-06, 'max_depth': 7, 'n_estimators': 935, 'subsample': 0.3291197103715723}. Best is trial 2 with value: 0.998858.[0m
[12:46:07] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[520]	train-rmse:1.05080	valid-rmse:1.06098
[0]	train-rmse:1.09917	valid-rmse:1.10397
[660]	train-rmse:1.09801	valid-rmse:1.10285
[380]	train-rmse:1.09356	valid-rmse:1.09878
[420]	train-rmse:1.09916	valid-rmse:1.10396
[380]	train-rmse:1.09885	valid-rmse:1.10367
[20]	train-rmse:1.09853	valid-rmse:1.10339
[540]	train-rmse:1.04934	valid-rmse:1.05973
[680]	train-rmse:1.09797	valid-rmse:1.10282
[400]	train-rmse:1.09327	valid-rmse:1.09851
[440]	train-rmse:1.09915	valid-rmse:1.10396
[40]	train-rmse:1.09789	valid-rmse:1.10280
[400]	train-rmse:1.09883	valid-rmse:1.10366
[700]	train-rmse:1.09794	valid-rmse:1.10278
[560]	train-rmse:1.04791	valid-rmse:1.05851
[420]	train-rmse:1.09299	valid-rmse:1.09824
[60]	train-rmse:1.09726	valid-rmse:1.10222
[460]	train-rmse:1.09915	valid-rmse:1.10396
[420]	train-rmse:1.09881	valid-rmse:1.10364
[720]	train-rmse:1.09790	valid-rmse:1.10275
[440]	train-rmse:1.09270	valid-rmse:1.09798
[80]	train-rmse:1.09663	valid-rmse:1.10164
[580]	train-rmse:1.04649	valid-rmse:1.05731
[480]	train-rmse:1.09915	valid-rmse:1.10395
[740]	train-rmse:1.09787	valid-rmse:1.10271
[440]	train-rmse:1.09879	valid-rmse:1.10362
[100]	train-rmse:1.09600	valid-rmse:1.10107
[460]	train-rmse:1.09241	valid-rmse:1.09771
[600]	train-rmse:1.04513	valid-rmse:1.05614
[500]	train-rmse:1.09915	valid-rmse:1.10395
[760]	train-rmse:1.09783	valid-rmse:1.10268
[460]	train-rmse:1.09877	valid-rmse:1.10360
[120]	train-rmse:1.09537	valid-rmse:1.10050
[480]	train-rmse:1.09213	valid-rmse:1.09745
[520]	train-rmse:1.09914	valid-rmse:1.10395
[780]	train-rmse:1.09779	valid-rmse:1.10264
[620]	train-rmse:1.04378	valid-rmse:1.05497
[140]	train-rmse:1.09475	valid-rmse:1.09993
[480]	train-rmse:1.09875	valid-rmse:1.10359
[500]	train-rmse:1.09184	valid-rmse:1.09718
[540]	train-rmse:1.09914	valid-rmse:1.10395
[800]	train-rmse:1.09776	valid-rmse:1.10261
[160]	train-rmse:1.09413	valid-rmse:1.09937
[640]	train-rmse:1.04244	valid-rmse:1.05385
[500]	train-rmse:1.09873	valid-rmse:1.10357
[520]	train-rmse:1.09156	valid-rmse:1.09692
[820]	train-rmse:1.09772	valid-rmse:1.10258
[180]	train-rmse:1.09352	valid-rmse:1.09881
[560]	train-rmse:1.09914	valid-rmse:1.10394
[660]	train-rmse:1.04113	valid-rmse:1.05274
[520]	train-rmse:1.09872	valid-rmse:1.10355
[540]	train-rmse:1.09127	valid-rmse:1.09666
[200]	train-rmse:1.09291	valid-rmse:1.09825
[840]	train-rmse:1.09769	valid-rmse:1.10254
[580]	train-rmse:1.09914	valid-rmse:1.10394
[560]	train-rmse:1.09099	valid-rmse:1.09640
[680]	train-rmse:1.03983	valid-rmse:1.05166
[540]	train-rmse:1.09870	valid-rmse:1.10353
[220]	train-rmse:1.09229	valid-rmse:1.09769
[860]	train-rmse:1.09765	valid-rmse:1.10251
[600]	train-rmse:1.09913	valid-rmse:1.10394
[580]	train-rmse:1.09071	valid-rmse:1.09614
[240]	train-rmse:1.09168	valid-rmse:1.09714
[560]	train-rmse:1.09868	valid-rmse:1.10352
[880]	train-rmse:1.09761	valid-rmse:1.10247
[700]	train-rmse:1.03855	valid-rmse:1.05060
[620]	train-rmse:1.09913	valid-rmse:1.10394
[600]	train-rmse:1.09043	valid-rmse:1.09587
[260]	train-rmse:1.09108	valid-rmse:1.09659
[900]	train-rmse:1.09758	valid-rmse:1.10244
[580]	train-rmse:1.09866	valid-rmse:1.10350
[720]	train-rmse:1.03729	valid-rmse:1.04956
[640]	train-rmse:1.09913	valid-rmse:1.10394
[280]	train-rmse:1.09048	valid-rmse:1.09604
[620]	train-rmse:1.09014	valid-rmse:1.09561
[920]	train-rmse:1.09754	valid-rmse:1.10240
[600]	train-rmse:1.09864	valid-rmse:1.10348
[300]	train-rmse:1.08988	valid-rmse:1.09550
[740]	train-rmse:1.03607	valid-rmse:1.04853
[660]	train-rmse:1.09913	valid-rmse:1.10393
[640]	train-rmse:1.08986	valid-rmse:1.09536
[940]	train-rmse:1.09751	valid-rmse:1.10237
[620]	train-rmse:1.09862	valid-rmse:1.10346
[320]	train-rmse:1.08928	valid-rmse:1.09496
[680]	train-rmse:1.09912	valid-rmse:1.10393
[760]	train-rmse:1.03488	valid-rmse:1.04753
[660]	train-rmse:1.08958	valid-rmse:1.09510
[960]	train-rmse:1.09747	valid-rmse:1.10233
[640]	train-rmse:1.09861	valid-rmse:1.10345
[340]	train-rmse:1.08869	valid-rmse:1.09442
[700]	train-rmse:1.09912	valid-rmse:1.10393
[680]	train-rmse:1.08930	valid-rmse:1.09484
[780]	train-rmse:1.03369	valid-rmse:1.04656
[980]	train-rmse:1.09744	valid-rmse:1.10230
[360]	train-rmse:1.08810	valid-rmse:1.09389
[660]	train-rmse:1.09859	valid-rmse:1.10343
[720]	train-rmse:1.09912	valid-rmse:1.10393
[999]	train-rmse:1.09740	valid-rmse:1.10227
[32m[I 2022-04-15 13:27:26,507][0m Trial 3 finished with value: 1.102266 and parameters: {'colsample_bytree': 0.9736196164484279, 'eta': 8.969072266104698e-06, 'max_depth': 7, 'n_estimators': 93, 'subsample': 0.3955161961841041}. Best is trial 2 with value: 0.998858.[0m
[700]	train-rmse:1.08902	valid-rmse:1.09458
[13:27:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09920	valid-rmse:1.10400
[800]	train-rmse:1.03254	valid-rmse:1.04560
[380]	train-rmse:1.08751	valid-rmse:1.09336
[20]	train-rmse:1.09919	valid-rmse:1.10400
[40]	train-rmse:1.09919	valid-rmse:1.10400
[680]	train-rmse:1.09857	valid-rmse:1.10341
[60]	train-rmse:1.09919	valid-rmse:1.10399
[740]	train-rmse:1.09912	valid-rmse:1.10393
[720]	train-rmse:1.08875	valid-rmse:1.09433
[400]	train-rmse:1.08693	valid-rmse:1.09283
[80]	train-rmse:1.09919	valid-rmse:1.10399
[820]	train-rmse:1.03139	valid-rmse:1.04466
[100]	train-rmse:1.09918	valid-rmse:1.10398
[700]	train-rmse:1.09855	valid-rmse:1.10340
[120]	train-rmse:1.09918	valid-rmse:1.10398
[740]	train-rmse:1.08847	valid-rmse:1.09407
[760]	train-rmse:1.09912	valid-rmse:1.10392
[420]	train-rmse:1.08635	valid-rmse:1.09230
[140]	train-rmse:1.09917	valid-rmse:1.10398
[160]	train-rmse:1.09917	valid-rmse:1.10397
[840]	train-rmse:1.03027	valid-rmse:1.04374
[180]	train-rmse:1.09917	valid-rmse:1.10397
[720]	train-rmse:1.09853	valid-rmse:1.10338
[440]	train-rmse:1.08577	valid-rmse:1.09178
[200]	train-rmse:1.09916	valid-rmse:1.10397
[760]	train-rmse:1.08819	valid-rmse:1.09381
[780]	train-rmse:1.09911	valid-rmse:1.10392
[220]	train-rmse:1.09916	valid-rmse:1.10396
[240]	train-rmse:1.09916	valid-rmse:1.10396
[860]	train-rmse:1.02915	valid-rmse:1.04284
[460]	train-rmse:1.08520	valid-rmse:1.09126
[260]	train-rmse:1.09915	valid-rmse:1.10395
[740]	train-rmse:1.09851	valid-rmse:1.10336
[780]	train-rmse:1.08791	valid-rmse:1.09356
[280]	train-rmse:1.09915	valid-rmse:1.10395
[800]	train-rmse:1.09911	valid-rmse:1.10392
[300]	train-rmse:1.09914	valid-rmse:1.10395
[320]	train-rmse:1.09914	valid-rmse:1.10394
[480]	train-rmse:1.08463	valid-rmse:1.09074
[880]	train-rmse:1.02808	valid-rmse:1.04195
[340]	train-rmse:1.09913	valid-rmse:1.10394
[800]	train-rmse:1.08764	valid-rmse:1.09331
[760]	train-rmse:1.09849	valid-rmse:1.10334
[820]	train-rmse:1.09911	valid-rmse:1.10392
[360]	train-rmse:1.09913	valid-rmse:1.10394
[380]	train-rmse:1.09913	valid-rmse:1.10393
[500]	train-rmse:1.08406	valid-rmse:1.09022
[400]	train-rmse:1.09912	valid-rmse:1.10393
[820]	train-rmse:1.08737	valid-rmse:1.09305
[420]	train-rmse:1.09912	valid-rmse:1.10392
[900]	train-rmse:1.02699	valid-rmse:1.04108
[780]	train-rmse:1.09848	valid-rmse:1.10333
[840]	train-rmse:1.09911	valid-rmse:1.10391
2022-04-16 18:53:38.337 | WARNING  | qlib.tests.data:qlib_data:150 - Data already exists: ~/igorlima/igor_tcc/qlib_data/br_data, the data download will be skipped
	If downloading is required: `exists_skip=False` or `change target_dir`
[234881:MainThread](2022-04-16 18:53:38,338) INFO - qlib.Initialization - [config.py:402] - default_conf: client.
[234881:MainThread](2022-04-16 18:53:38,653) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.
[234881:MainThread](2022-04-16 18:53:38,654) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/lisa/igorlima/igor_tcc/qlib_data/br_data')}
[234881:MainThread](2022-04-16 18:53:38,654) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:83] - Dataset intialization
[234881:MainThread](2022-04-16 18:53:46,857) INFO - qlib.timer - [log.py:113] - Time cost: 8.199s | Loading data Done
[234881:MainThread](2022-04-16 18:53:47,023) INFO - qlib.timer - [log.py:113] - Time cost: 0.058s | DropnaLabel Done
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/data/dataset/processor.py:347: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[cols] = t
[234881:MainThread](2022-04-16 18:53:47,182) INFO - qlib.timer - [log.py:113] - Time cost: 0.158s | CSRankNorm Done
[234881:MainThread](2022-04-16 18:53:47,182) INFO - qlib.timer - [log.py:113] - Time cost: 0.325s | fit & process data Done
[234881:MainThread](2022-04-16 18:53:47,183) INFO - qlib.timer - [log.py:113] - Time cost: 8.526s | Init data Done
[234881:MainThread](2022-04-16 18:53:47,183) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:86] - Start parameter tuning
[234881:MainThread](2022-04-16 18:53:47,212) ERROR - qlib.workflow - [utils.py:41] - An exception has been raised[KeyError: 'Record does not exist.'].
  File "hyperparameter_360_XGBoost_br.py", line 87, in <module>
    study = optuna.Study(study_name=" ", storage="sqlite:///db_3_0.sqlite3")
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/study.py", line 231, in __init__
    study_id = storage.get_study_id_from_name(study_name)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/storages/_cached_storage.py", line 124, in get_study_id_from_name
    return self._backend.get_study_id_from_name(study_name)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/storages/_rdb/storage.py", line 317, in get_study_id_from_name
    study = models.StudyModel.find_or_raise_by_name(study_name, session)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/storages/_rdb/models.py", line 71, in find_or_raise_by_name
    raise KeyError(NOT_FOUND_MSG)
KeyError: 'Record does not exist.'
2022-04-16 19:11:16.377 | WARNING  | qlib.tests.data:qlib_data:150 - Data already exists: ~/igorlima/igor_tcc/qlib_data/br_data, the data download will be skipped
	If downloading is required: `exists_skip=False` or `change target_dir`
[238300:MainThread](2022-04-16 19:11:16,378) INFO - qlib.Initialization - [config.py:402] - default_conf: client.
[238300:MainThread](2022-04-16 19:11:16,696) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.
[238300:MainThread](2022-04-16 19:11:16,696) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/lisa/igorlima/igor_tcc/qlib_data/br_data')}
[238300:MainThread](2022-04-16 19:11:16,697) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:83] - Dataset intialization
[238300:MainThread](2022-04-16 19:11:24,683) INFO - qlib.timer - [log.py:113] - Time cost: 7.983s | Loading data Done
[238300:MainThread](2022-04-16 19:11:24,854) INFO - qlib.timer - [log.py:113] - Time cost: 0.061s | DropnaLabel Done
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/data/dataset/processor.py:347: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[cols] = t
[238300:MainThread](2022-04-16 19:11:25,020) INFO - qlib.timer - [log.py:113] - Time cost: 0.166s | CSRankNorm Done
[238300:MainThread](2022-04-16 19:11:25,020) INFO - qlib.timer - [log.py:113] - Time cost: 0.337s | fit & process data Done
[238300:MainThread](2022-04-16 19:11:25,021) INFO - qlib.timer - [log.py:113] - Time cost: 8.321s | Init data Done
[238300:MainThread](2022-04-16 19:11:25,021) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:86] - Start parameter tuning
[19:11:29] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import MultiIndex, Int64Index
[33m[W 2022-04-16 19:11:29,797][0m Trial 0 failed because of the following error: FileExistsError(17, 'File exists')[0m
Traceback (most recent call last):
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/record_writer.py", line 47, in directory_check
    factory = REGISTERED_FACTORIES[prefix]
KeyError: './tensor_board/runs/xgboost'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/_optimize.py", line 213, in _run_trial
    value_or_values = func(trial)
  File "hyperparameter_360_XGBoost_br.py", line 73, in objective
    model.fit(dataset, evals_result=evals_result)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/contrib/model/xgboost.py", line 73, in fit
    callbacks=[TensorBoardCallback(experiment='xgboost_exp', data_name='test')],
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/contrib/model/xgboost.py", line 106, in __init__
    self.train_writer = SummaryWriter(log_dir=target_dir + '/runs/xgboost')
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/writer.py", line 301, in __init__
    self._get_file_writer()
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/writer.py", line 349, in _get_file_writer
    self.file_writer = FileWriter(logdir=self.logdir,
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/writer.py", line 105, in __init__
    self.event_writer = EventFileWriter(
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 104, in __init__
    directory_check(self._logdir)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/record_writer.py", line 51, in directory_check
    os.makedirs(path)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/os.py", line 223, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './tensor_board/runs/xgboost'
[19:11:30] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:11:30] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:11:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


target_dir:  ./tensor_board/runs/catboost
[19:11:30] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08351	valid-rmse:1.08683
[0]	train-rmse:1.09906	valid-rmse:1.10224
[0]	train-rmse:1.09906	valid-rmse:1.10224
[0]	train-rmse:1.04767	valid-rmse:1.05321
[0]	train-rmse:0.99373	valid-rmse:1.01259
[20]	train-rmse:0.99590	valid-rmse:1.00236
[20]	train-rmse:0.95897	valid-rmse:1.00698
[40]	train-rmse:0.98891	valid-rmse:0.99942
[20]	train-rmse:1.09906	valid-rmse:1.10224
[20]	train-rmse:1.09905	valid-rmse:1.10223
[60]	train-rmse:0.98443	valid-rmse:0.99981
[40]	train-rmse:0.92638	valid-rmse:1.01538
[80]	train-rmse:0.98079	valid-rmse:1.00010
[40]	train-rmse:1.09906	valid-rmse:1.10224
[94]	train-rmse:0.97833	valid-rmse:1.00069
[32m[I 2022-04-16 19:13:34,107][0m Trial 1 finished with value: 0.999336 and parameters: {'colsample_bytree': 0.36908636706118103, 'eta': 0.0835726229851427, 'max_depth': 5, 'n_estimators': 185, 'subsample': 0.255309133222227}. Best is trial 1 with value: 0.999336.[0m
[20]	train-rmse:0.85103	valid-rmse:1.09343
[49]	train-rmse:1.09906	valid-rmse:1.10224
[32m[I 2022-04-16 19:13:40,709][0m Trial 3 finished with value: 1.102238 and parameters: {'colsample_bytree': 0.5335044563168367, 'eta': 7.005944333207717e-08, 'max_depth': 5, 'n_estimators': 294, 'subsample': 0.6575452971816862}. Best is trial 1 with value: 0.999336.[0m
[40]	train-rmse:1.09904	valid-rmse:1.10221
[56]	train-rmse:0.90121	valid-rmse:1.02083
[32m[I 2022-04-16 19:13:46,147][0m Trial 2 finished with value: 1.002476 and parameters: {'colsample_bytree': 0.2970164958298247, 'eta': 0.2932252820553465, 'max_depth': 7, 'n_estimators': 133, 'subsample': 0.4951279653535092}. Best is trial 1 with value: 0.999336.[0m
[60]	train-rmse:1.09903	valid-rmse:1.10220
[40]	train-rmse:0.73352	valid-rmse:1.16815
[80]	train-rmse:1.09901	valid-rmse:1.10219
[51]	train-rmse:0.67733	valid-rmse:1.19982
[32m[I 2022-04-16 19:14:51,965][0m Trial 5 finished with value: 1.009177 and parameters: {'colsample_bytree': 0.5498864666763867, 'eta': 0.7701071617517461, 'max_depth': 9, 'n_estimators': 425, 'subsample': 0.6805447984989068}. Best is trial 1 with value: 0.999336.[0m
[100]	train-rmse:1.09900	valid-rmse:1.10218
[120]	train-rmse:1.09899	valid-rmse:1.10217
[140]	train-rmse:1.09897	valid-rmse:1.10215
[160]	train-rmse:1.09896	valid-rmse:1.10214
[180]	train-rmse:1.09895	valid-rmse:1.10213
[200]	train-rmse:1.09894	valid-rmse:1.10212
[220]	train-rmse:1.09892	valid-rmse:1.10211
[240]	train-rmse:1.09891	valid-rmse:1.10209
[260]	train-rmse:1.09890	valid-rmse:1.10208
[280]	train-rmse:1.09888	valid-rmse:1.10207
[300]	train-rmse:1.09887	valid-rmse:1.10206
[320]	train-rmse:1.09886	valid-rmse:1.10205
[340]	train-rmse:1.09885	valid-rmse:1.10204
[360]	train-rmse:1.09883	valid-rmse:1.10202
[380]	train-rmse:1.09882	valid-rmse:1.10201
[400]	train-rmse:1.09881	valid-rmse:1.10200
[420]	train-rmse:1.09879	valid-rmse:1.10199
[440]	train-rmse:1.09878	valid-rmse:1.10198
[460]	train-rmse:1.09877	valid-rmse:1.10196
[480]	train-rmse:1.09876	valid-rmse:1.10195
[500]	train-rmse:1.09874	valid-rmse:1.10194
[520]	train-rmse:1.09873	valid-rmse:1.10193
[540]	train-rmse:1.09872	valid-rmse:1.10192
[560]	train-rmse:1.09871	valid-rmse:1.10190
[580]	train-rmse:1.09869	valid-rmse:1.10189
[600]	train-rmse:1.09868	valid-rmse:1.10188
[620]	train-rmse:1.09867	valid-rmse:1.10187
[640]	train-rmse:1.09865	valid-rmse:1.10186
[660]	train-rmse:1.09864	valid-rmse:1.10185
[680]	train-rmse:1.09863	valid-rmse:1.10183
[700]	train-rmse:1.09862	valid-rmse:1.10182
[720]	train-rmse:1.09860	valid-rmse:1.10181
[740]	train-rmse:1.09859	valid-rmse:1.10180
[760]	train-rmse:1.09858	valid-rmse:1.10179
[780]	train-rmse:1.09856	valid-rmse:1.10177
[800]	train-rmse:1.09855	valid-rmse:1.10176
[820]	train-rmse:1.09854	valid-rmse:1.10175
[840]	train-rmse:1.09853	valid-rmse:1.10174
[860]	train-rmse:1.09851	valid-rmse:1.10173
[880]	train-rmse:1.09850	valid-rmse:1.10171
[900]	train-rmse:1.09849	valid-rmse:1.10170
[920]	train-rmse:1.09848	valid-rmse:1.10169
[940]	train-rmse:1.09846	valid-rmse:1.10168
[960]	train-rmse:1.09845	valid-rmse:1.10167
[980]	train-rmse:1.09844	valid-rmse:1.10166
[999]	train-rmse:1.09842	valid-rmse:1.10164
[32m[I 2022-04-16 19:22:27,598][0m Trial 4 finished with value: 1.101645 and parameters: {'colsample_bytree': 0.49487933293809183, 'eta': 3.102043933569569e-06, 'max_depth': 9, 'n_estimators': 340, 'subsample': 0.25413984189111505}. Best is trial 1 with value: 0.999336.[0m
[238300:MainThread](2022-04-16 19:22:27,599) ERROR - qlib.workflow - [utils.py:41] - An exception has been raised[FileExistsError: [Errno 17] File exists: './tensor_board/runs/xgboost'].
  File "hyperparameter_360_XGBoost_br.py", line 88, in <module>
    study.optimize(objective, n_jobs=6)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/study.py", line 400, in optimize
    _optimize(
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/_optimize.py", line 106, in _optimize
    f.result()
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    trial = _run_trial(study, func, catch)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/_optimize.py", line 264, in _run_trial
    raise func_err
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/_optimize.py", line 213, in _run_trial
    value_or_values = func(trial)
  File "hyperparameter_360_XGBoost_br.py", line 73, in objective
    model.fit(dataset, evals_result=evals_result)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/contrib/model/xgboost.py", line 73, in fit
    callbacks=[TensorBoardCallback(experiment='xgboost_exp', data_name='valid')],
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/contrib/model/xgboost.py", line 106, in __init__
    self.train_writer = SummaryWriter(log_dir=target_dir + '/runs/xgboost')
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/writer.py", line 301, in __init__
    self._get_file_writer()
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/writer.py", line 349, in _get_file_writer
    self.file_writer = FileWriter(logdir=self.logdir,
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/writer.py", line 105, in __init__
    self.event_writer = EventFileWriter(
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 104, in __init__
    directory_check(self._logdir)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/tensorboardX/record_writer.py", line 51, in directory_check
    os.makedirs(path)
  File "/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/os.py", line 223, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './tensor_board/runs/xgboost'
2022-04-16 19:28:57.473 | WARNING  | qlib.tests.data:qlib_data:150 - Data already exists: ~/igorlima/igor_tcc/qlib_data/br_data, the data download will be skipped
	If downloading is required: `exists_skip=False` or `change target_dir`
[242489:MainThread](2022-04-16 19:28:57,474) INFO - qlib.Initialization - [config.py:402] - default_conf: client.
[242489:MainThread](2022-04-16 19:28:57,797) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.
[242489:MainThread](2022-04-16 19:28:57,797) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/lisa/igorlima/igor_tcc/qlib_data/br_data')}
[242489:MainThread](2022-04-16 19:28:57,798) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:83] - Dataset intialization
[242489:MainThread](2022-04-16 19:29:05,683) INFO - qlib.timer - [log.py:113] - Time cost: 7.882s | Loading data Done
[242489:MainThread](2022-04-16 19:29:05,846) INFO - qlib.timer - [log.py:113] - Time cost: 0.057s | DropnaLabel Done
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/qlib/data/dataset/processor.py:347: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[cols] = t
[242489:MainThread](2022-04-16 19:29:06,002) INFO - qlib.timer - [log.py:113] - Time cost: 0.155s | CSRankNorm Done
[242489:MainThread](2022-04-16 19:29:06,002) INFO - qlib.timer - [log.py:113] - Time cost: 0.319s | fit & process data Done
[242489:MainThread](2022-04-16 19:29:06,003) INFO - qlib.timer - [log.py:113] - Time cost: 8.202s | Init data Done
[242489:MainThread](2022-04-16 19:29:06,003) INFO - qlib.Hyperparameter - [hyperparameter_360_XGBoost_br.py:86] - Start parameter tuning
[19:29:10] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


target_dir:  ./tensor_board/runs/catboost
[19:29:09] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[19:29:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:29:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:29:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[19:29:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[0]	train-rmse:0.99386	valid-rmse:1.00189
[0]	train-rmse:1.09906	valid-rmse:1.10223
[0]	train-rmse:1.08099	valid-rmse:1.08609
[20]	train-rmse:1.09906	valid-rmse:1.10224
[20]	train-rmse:1.09905	valid-rmse:1.10222
[20]	train-rmse:1.09906	valid-rmse:1.10224
[40]	train-rmse:1.09906	valid-rmse:1.10224
[20]	train-rmse:0.93009	valid-rmse:1.05010
[20]	train-rmse:1.09888	valid-rmse:1.10207
[40]	train-rmse:1.09903	valid-rmse:1.10221
[40]	train-rmse:1.09906	valid-rmse:1.10224
[49]	train-rmse:1.09906	valid-rmse:1.10224
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/optuna/study/study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(
/home/lisa/miniconda3/envs/igor_tcc/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import MultiIndex, Int64Index
[32m[I 2022-04-16 19:30:40,191][0m Trial 12 finished with value: 1.102238 and parameters: {'colsample_bytree': 0.5806599491467006, 'eta': 1.0865982862408315e-08, 'max_depth': 5, 'n_estimators': 999, 'subsample': 0.20099680631233063}. Best is trial 7 with value: 0.998686.[0m
[19:30:43] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[60]	train-rmse:1.09902	valid-rmse:1.10219
[60]	train-rmse:1.09906	valid-rmse:1.10224
[40]	train-rmse:1.09871	valid-rmse:1.10190
[40]	train-rmse:0.86306	valid-rmse:1.10548
[80]	train-rmse:1.09900	valid-rmse:1.10218
[80]	train-rmse:1.09906	valid-rmse:1.10223
[20]	train-rmse:1.09905	valid-rmse:1.10223
[50]	train-rmse:0.83522	valid-rmse:1.12676
[32m[I 2022-04-16 19:32:18,011][0m Trial 14 finished with value: 1.001894 and parameters: {'colsample_bytree': 0.30153247511231573, 'eta': 0.9910073114848794, 'max_depth': 7, 'n_estimators': 402, 'subsample': 0.7667967138629281}. Best is trial 7 with value: 0.998686.[0m
[19:32:22] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20]	train-rmse:0.96224	valid-rmse:1.00355
[0]	train-rmse:1.09594	valid-rmse:1.09914
[100]	train-rmse:1.09899	valid-rmse:1.10217
[60]	train-rmse:1.09854	valid-rmse:1.10174
[100]	train-rmse:1.09906	valid-rmse:1.10223
[20]	train-rmse:1.04955	valid-rmse:1.05295
[120]	train-rmse:1.09898	valid-rmse:1.10215
[120]	train-rmse:1.09906	valid-rmse:1.10223
[40]	train-rmse:1.09904	valid-rmse:1.10222
[40]	train-rmse:1.02448	valid-rmse:1.02790
[140]	train-rmse:1.09896	valid-rmse:1.10214
[80]	train-rmse:1.09837	valid-rmse:1.10158
[140]	train-rmse:1.09906	valid-rmse:1.10223
[60]	train-rmse:1.01106	valid-rmse:1.01443
[160]	train-rmse:1.09895	valid-rmse:1.10212
[160]	train-rmse:1.09906	valid-rmse:1.10223
[80]	train-rmse:1.00382	valid-rmse:1.00723
[60]	train-rmse:1.09903	valid-rmse:1.10221
[180]	train-rmse:1.09893	valid-rmse:1.10211
[100]	train-rmse:1.09820	valid-rmse:1.10142
[40]	train-rmse:0.93220	valid-rmse:1.00203
[200]	train-rmse:1.09892	valid-rmse:1.10209
[100]	train-rmse:0.99987	valid-rmse:1.00335
[180]	train-rmse:1.09905	valid-rmse:1.10223
[120]	train-rmse:1.09803	valid-rmse:1.10125
[220]	train-rmse:1.09890	valid-rmse:1.10208
[120]	train-rmse:0.99767	valid-rmse:1.00124
[80]	train-rmse:1.09902	valid-rmse:1.10220
[200]	train-rmse:1.09905	valid-rmse:1.10223
[240]	train-rmse:1.09889	valid-rmse:1.10206
[140]	train-rmse:0.99633	valid-rmse:1.00010
[220]	train-rmse:1.09905	valid-rmse:1.10223
[140]	train-rmse:1.09786	valid-rmse:1.10109
[260]	train-rmse:1.09887	valid-rmse:1.10205
[160]	train-rmse:0.99550	valid-rmse:0.99943
[100]	train-rmse:1.09901	valid-rmse:1.10219
[240]	train-rmse:1.09905	valid-rmse:1.10223
[280]	train-rmse:1.09886	valid-rmse:1.10204
[180]	train-rmse:0.99491	valid-rmse:0.99908
[60]	train-rmse:0.90660	valid-rmse:1.00280
[160]	train-rmse:1.09769	valid-rmse:1.10093
[260]	train-rmse:1.09905	valid-rmse:1.10223
[300]	train-rmse:1.09884	valid-rmse:1.10202
[200]	train-rmse:0.99443	valid-rmse:0.99887
[120]	train-rmse:1.09900	valid-rmse:1.10218
[280]	train-rmse:1.09905	valid-rmse:1.10222
[320]	train-rmse:1.09883	valid-rmse:1.10201
[220]	train-rmse:0.99405	valid-rmse:0.99876
[180]	train-rmse:1.09752	valid-rmse:1.10077
[300]	train-rmse:1.09905	valid-rmse:1.10222
[340]	train-rmse:1.09882	valid-rmse:1.10199
[240]	train-rmse:0.99372	valid-rmse:0.99867
[140]	train-rmse:1.09899	valid-rmse:1.10217
[360]	train-rmse:1.09880	valid-rmse:1.10198
[320]	train-rmse:1.09905	valid-rmse:1.10222
[200]	train-rmse:1.09735	valid-rmse:1.10061
[260]	train-rmse:0.99339	valid-rmse:0.99861
[380]	train-rmse:1.09879	valid-rmse:1.10196
[340]	train-rmse:1.09905	valid-rmse:1.10222
[280]	train-rmse:0.99306	valid-rmse:0.99858
[80]	train-rmse:0.87309	valid-rmse:1.00458
[160]	train-rmse:1.09898	valid-rmse:1.10215
[400]	train-rmse:1.09877	valid-rmse:1.10195
[220]	train-rmse:1.09718	valid-rmse:1.10045
[300]	train-rmse:0.99276	valid-rmse:0.99857
[360]	train-rmse:1.09905	valid-rmse:1.10222
[420]	train-rmse:1.09876	valid-rmse:1.10193
[320]	train-rmse:0.99246	valid-rmse:0.99856
[380]	train-rmse:1.09904	valid-rmse:1.10222
[240]	train-rmse:1.09702	valid-rmse:1.10028
[440]	train-rmse:1.09874	valid-rmse:1.10192
[180]	train-rmse:1.09897	valid-rmse:1.10214
[340]	train-rmse:0.99219	valid-rmse:0.99856
[400]	train-rmse:1.09904	valid-rmse:1.10222
[92]	train-rmse:0.85644	valid-rmse:1.00565
[32m[I 2022-04-16 19:43:51,857][0m Trial 15 finished with value: 1.001841 and parameters: {'colsample_bytree': 0.855512887741593, 'eta': 0.0888067777325371, 'max_depth': 9, 'n_estimators': 139, 'subsample': 0.6225214117984363}. Best is trial 7 with value: 0.998686.[0m
[19:43:56] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09905	valid-rmse:1.10223
[460]	train-rmse:1.09873	valid-rmse:1.10190
[360]	train-rmse:0.99190	valid-rmse:0.99855
[260]	train-rmse:1.09685	valid-rmse:1.10013
[420]	train-rmse:1.09904	valid-rmse:1.10222
[480]	train-rmse:1.09871	valid-rmse:1.10189
[200]	train-rmse:1.09896	valid-rmse:1.10213
[380]	train-rmse:0.99162	valid-rmse:0.99854
[440]	train-rmse:1.09904	valid-rmse:1.10221
[500]	train-rmse:1.09870	valid-rmse:1.10188
[20]	train-rmse:1.09888	valid-rmse:1.10207
[280]	train-rmse:1.09668	valid-rmse:1.09997
[400]	train-rmse:0.99132	valid-rmse:0.99855
[460]	train-rmse:1.09904	valid-rmse:1.10221
[520]	train-rmse:1.09868	valid-rmse:1.10186
[220]	train-rmse:1.09895	valid-rmse:1.10212
[420]	train-rmse:0.99106	valid-rmse:0.99854
[540]	train-rmse:1.09867	valid-rmse:1.10185
[480]	train-rmse:1.09904	valid-rmse:1.10221
[300]	train-rmse:1.09651	valid-rmse:1.09980
[40]	train-rmse:1.09871	valid-rmse:1.10191
[440]	train-rmse:0.99075	valid-rmse:0.99855
[560]	train-rmse:1.09866	valid-rmse:1.10183
[500]	train-rmse:1.09904	valid-rmse:1.10221
[240]	train-rmse:1.09894	valid-rmse:1.10211
[460]	train-rmse:0.99049	valid-rmse:0.99854
[462]	train-rmse:0.99045	valid-rmse:0.99854
[32m[I 2022-04-16 19:47:50,906][0m Trial 19 finished with value: 0.998533 and parameters: {'colsample_bytree': 0.5044610381796226, 'eta': 0.016264462924223542, 'max_depth': 3, 'n_estimators': 869, 'subsample': 0.8596397787018508}. Best is trial 19 with value: 0.998533.[0m
[19:47:54] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[580]	train-rmse:1.09864	valid-rmse:1.10182
[320]	train-rmse:1.09634	valid-rmse:1.09964
[0]	train-rmse:1.09879	valid-rmse:1.10197
[520]	train-rmse:1.09904	valid-rmse:1.10221
[60]	train-rmse:1.09854	valid-rmse:1.10174
[600]	train-rmse:1.09863	valid-rmse:1.10180
[540]	train-rmse:1.09904	valid-rmse:1.10221
[20]	train-rmse:1.09351	valid-rmse:1.09672
[260]	train-rmse:1.09892	valid-rmse:1.10210
[340]	train-rmse:1.09618	valid-rmse:1.09949
[620]	train-rmse:1.09861	valid-rmse:1.10179
[560]	train-rmse:1.09903	valid-rmse:1.10221
[640]	train-rmse:1.09860	valid-rmse:1.10177
[80]	train-rmse:1.09837	valid-rmse:1.10158
[40]	train-rmse:1.08849	valid-rmse:1.09173
[360]	train-rmse:1.09601	valid-rmse:1.09933
[580]	train-rmse:1.09903	valid-rmse:1.10221
[280]	train-rmse:1.09891	valid-rmse:1.10209
[660]	train-rmse:1.09858	valid-rmse:1.10176
[600]	train-rmse:1.09903	valid-rmse:1.10221
[60]	train-rmse:1.08372	valid-rmse:1.08699
[680]	train-rmse:1.09857	valid-rmse:1.10175
[100]	train-rmse:1.09819	valid-rmse:1.10142
[380]	train-rmse:1.09584	valid-rmse:1.09917
[700]	train-rmse:1.09855	valid-rmse:1.10173
[620]	train-rmse:1.09903	valid-rmse:1.10221
[300]	train-rmse:1.09890	valid-rmse:1.10208
[80]	train-rmse:1.07918	valid-rmse:1.08248
[720]	train-rmse:1.09854	valid-rmse:1.10172
[640]	train-rmse:1.09903	valid-rmse:1.10221
[400]	train-rmse:1.09568	valid-rmse:1.09901
[120]	train-rmse:1.09802	valid-rmse:1.10126
[740]	train-rmse:1.09853	valid-rmse:1.10170
[100]	train-rmse:1.07488	valid-rmse:1.07820
[660]	train-rmse:1.09903	valid-rmse:1.10220
[320]	train-rmse:1.09889	valid-rmse:1.10207
[760]	train-rmse:1.09851	valid-rmse:1.10169
[420]	train-rmse:1.09551	valid-rmse:1.09885
[680]	train-rmse:1.09903	valid-rmse:1.10220
[120]	train-rmse:1.07079	valid-rmse:1.07414
[140]	train-rmse:1.09785	valid-rmse:1.10110
[780]	train-rmse:1.09850	valid-rmse:1.10167
[340]	train-rmse:1.09888	valid-rmse:1.10206
[700]	train-rmse:1.09903	valid-rmse:1.10220
[440]	train-rmse:1.09535	valid-rmse:1.09869
[800]	train-rmse:1.09848	valid-rmse:1.10166
[140]	train-rmse:1.06691	valid-rmse:1.07027
[720]	train-rmse:1.09903	valid-rmse:1.10220
[820]	train-rmse:1.09847	valid-rmse:1.10165
[160]	train-rmse:1.09768	valid-rmse:1.10094
[360]	train-rmse:1.09887	valid-rmse:1.10205
[460]	train-rmse:1.09518	valid-rmse:1.09854
[740]	train-rmse:1.09902	valid-rmse:1.10220
[160]	train-rmse:1.06323	valid-rmse:1.06660
[840]	train-rmse:1.09845	valid-rmse:1.10163
[760]	train-rmse:1.09902	valid-rmse:1.10220
[860]	train-rmse:1.09844	valid-rmse:1.10162
[180]	train-rmse:1.05973	valid-rmse:1.06312
[180]	train-rmse:1.09751	valid-rmse:1.10078
[480]	train-rmse:1.09501	valid-rmse:1.09838
[380]	train-rmse:1.09886	valid-rmse:1.10204
[880]	train-rmse:1.09842	valid-rmse:1.10160
[780]	train-rmse:1.09902	valid-rmse:1.10220
[900]	train-rmse:1.09841	valid-rmse:1.10159
[200]	train-rmse:1.05641	valid-rmse:1.05981
[800]	train-rmse:1.09902	valid-rmse:1.10220
[500]	train-rmse:1.09485	valid-rmse:1.09822
[200]	train-rmse:1.09734	valid-rmse:1.10062
[920]	train-rmse:1.09840	valid-rmse:1.10157
[400]	train-rmse:1.09885	valid-rmse:1.10203
[820]	train-rmse:1.09902	valid-rmse:1.10220
[220]	train-rmse:1.05326	valid-rmse:1.05667
[940]	train-rmse:1.09838	valid-rmse:1.10156
[520]	train-rmse:1.09468	valid-rmse:1.09806
[840]	train-rmse:1.09902	valid-rmse:1.10219
[960]	train-rmse:1.09837	valid-rmse:1.10154
[220]	train-rmse:1.09717	valid-rmse:1.10046
[240]	train-rmse:1.05028	valid-rmse:1.05369
[420]	train-rmse:1.09884	valid-rmse:1.10202
[860]	train-rmse:1.09902	valid-rmse:1.10219
[980]	train-rmse:1.09835	valid-rmse:1.10153
[540]	train-rmse:1.09452	valid-rmse:1.09790
[880]	train-rmse:1.09902	valid-rmse:1.10219
[260]	train-rmse:1.04744	valid-rmse:1.05087
[999]	train-rmse:1.09834	valid-rmse:1.10152
[32m[I 2022-04-16 20:01:26,873][0m Trial 16 finished with value: 1.101517 and parameters: {'colsample_bytree': 0.4925832994051431, 'eta': 3.7537169016032784e-06, 'max_depth': 3, 'n_estimators': 468, 'subsample': 0.8545113701599671}. Best is trial 19 with value: 0.998533.[0m
[20:01:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09850	valid-rmse:1.10169
[240]	train-rmse:1.09700	valid-rmse:1.10030
[440]	train-rmse:1.09883	valid-rmse:1.10201
[560]	train-rmse:1.09435	valid-rmse:1.09775
[900]	train-rmse:1.09902	valid-rmse:1.10219
[280]	train-rmse:1.04475	valid-rmse:1.04819
[20]	train-rmse:1.08790	valid-rmse:1.09115
[920]	train-rmse:1.09901	valid-rmse:1.10219
[460]	train-rmse:1.09882	valid-rmse:1.10200
[260]	train-rmse:1.09683	valid-rmse:1.10014
[580]	train-rmse:1.09419	valid-rmse:1.09759
[300]	train-rmse:1.04220	valid-rmse:1.04564
[40]	train-rmse:1.07837	valid-rmse:1.08167
[940]	train-rmse:1.09901	valid-rmse:1.10219
[960]	train-rmse:1.09901	valid-rmse:1.10219
[600]	train-rmse:1.09403	valid-rmse:1.09743
[60]	train-rmse:1.06980	valid-rmse:1.07313
[320]	train-rmse:1.03978	valid-rmse:1.04322
[480]	train-rmse:1.09881	valid-rmse:1.10199
[280]	train-rmse:1.09666	valid-rmse:1.09998
[980]	train-rmse:1.09901	valid-rmse:1.10219
[80]	train-rmse:1.06209	valid-rmse:1.06546
[340]	train-rmse:1.03748	valid-rmse:1.04094
[620]	train-rmse:1.09386	valid-rmse:1.09728
[999]	train-rmse:1.09901	valid-rmse:1.10219
[32m[I 2022-04-16 20:05:45,886][0m Trial 13 finished with value: 1.102186 and parameters: {'colsample_bytree': 0.6084079051871516, 'eta': 2.7572167760667775e-07, 'max_depth': 5, 'n_estimators': 881, 'subsample': 0.28216056763835584}. Best is trial 19 with value: 0.998533.[0m
[20:05:50] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09860	valid-rmse:1.10178
[500]	train-rmse:1.09880	valid-rmse:1.10198
[300]	train-rmse:1.09649	valid-rmse:1.09982
[100]	train-rmse:1.05518	valid-rmse:1.05859
[360]	train-rmse:1.03531	valid-rmse:1.03877
[640]	train-rmse:1.09370	valid-rmse:1.09712
[20]	train-rmse:1.08973	valid-rmse:1.09296
[120]	train-rmse:1.04897	valid-rmse:1.05240
[520]	train-rmse:1.09879	valid-rmse:1.10197
[380]	train-rmse:1.03324	valid-rmse:1.03670
[320]	train-rmse:1.09632	valid-rmse:1.09966
[40]	train-rmse:1.08160	valid-rmse:1.08488
[660]	train-rmse:1.09353	valid-rmse:1.09697
[140]	train-rmse:1.04341	valid-rmse:1.04685
[400]	train-rmse:1.03128	valid-rmse:1.03475
[540]	train-rmse:1.09878	valid-rmse:1.10196
[60]	train-rmse:1.07416	valid-rmse:1.07748
[340]	train-rmse:1.09615	valid-rmse:1.09950
[680]	train-rmse:1.09337	valid-rmse:1.09681
[160]	train-rmse:1.03842	valid-rmse:1.04187
[420]	train-rmse:1.02942	valid-rmse:1.03289
[80]	train-rmse:1.06735	valid-rmse:1.07070
[560]	train-rmse:1.09876	valid-rmse:1.10195
[180]	train-rmse:1.03394	valid-rmse:1.03740
[700]	train-rmse:1.09321	valid-rmse:1.09666
[360]	train-rmse:1.09598	valid-rmse:1.09935
[440]	train-rmse:1.02766	valid-rmse:1.03112
[100]	train-rmse:1.06112	valid-rmse:1.06449
[200]	train-rmse:1.02994	valid-rmse:1.03340
[720]	train-rmse:1.09305	valid-rmse:1.09650
[580]	train-rmse:1.09875	valid-rmse:1.10194
[460]	train-rmse:1.02599	valid-rmse:1.02946
[120]	train-rmse:1.05543	valid-rmse:1.05882
[380]	train-rmse:1.09581	valid-rmse:1.09919
[220]	train-rmse:1.02634	valid-rmse:1.02981
[480]	train-rmse:1.02441	valid-rmse:1.02787
[740]	train-rmse:1.09288	valid-rmse:1.09635
[140]	train-rmse:1.05022	valid-rmse:1.05362
[600]	train-rmse:1.09874	valid-rmse:1.10193
[240]	train-rmse:1.02313	valid-rmse:1.02659
[400]	train-rmse:1.09564	valid-rmse:1.09903
[500]	train-rmse:1.02290	valid-rmse:1.02637
[160]	train-rmse:1.04546	valid-rmse:1.04887
[760]	train-rmse:1.09272	valid-rmse:1.09619
[260]	train-rmse:1.02025	valid-rmse:1.02370
[620]	train-rmse:1.09873	valid-rmse:1.10192
[520]	train-rmse:1.02148	valid-rmse:1.02495
[180]	train-rmse:1.04112	valid-rmse:1.04453
[420]	train-rmse:1.09548	valid-rmse:1.09887
[280]	train-rmse:1.01767	valid-rmse:1.02113
[780]	train-rmse:1.09256	valid-rmse:1.09604
[640]	train-rmse:1.09872	valid-rmse:1.10191
[540]	train-rmse:1.02013	valid-rmse:1.02360
[200]	train-rmse:1.03714	valid-rmse:1.04057
[300]	train-rmse:1.01535	valid-rmse:1.01881
[800]	train-rmse:1.09240	valid-rmse:1.09588
[440]	train-rmse:1.09531	valid-rmse:1.09872
[560]	train-rmse:1.01885	valid-rmse:1.02232
[220]	train-rmse:1.03352	valid-rmse:1.03694
[320]	train-rmse:1.01327	valid-rmse:1.01673
[660]	train-rmse:1.09871	valid-rmse:1.10190
[820]	train-rmse:1.09223	valid-rmse:1.09573
[580]	train-rmse:1.01764	valid-rmse:1.02110
[240]	train-rmse:1.03021	valid-rmse:1.03363
[340]	train-rmse:1.01143	valid-rmse:1.01488
[460]	train-rmse:1.09514	valid-rmse:1.09856
[680]	train-rmse:1.09870	valid-rmse:1.10189
[840]	train-rmse:1.09207	valid-rmse:1.09558
[360]	train-rmse:1.00976	valid-rmse:1.01322
[260]	train-rmse:1.02718	valid-rmse:1.03061
[600]	train-rmse:1.01648	valid-rmse:1.01995
[480]	train-rmse:1.09498	valid-rmse:1.09840
[380]	train-rmse:1.00828	valid-rmse:1.01172
[860]	train-rmse:1.09191	valid-rmse:1.09542
[280]	train-rmse:1.02442	valid-rmse:1.02785
[620]	train-rmse:1.01540	valid-rmse:1.01886
[700]	train-rmse:1.09869	valid-rmse:1.10187
[400]	train-rmse:1.00694	valid-rmse:1.01038
[300]	train-rmse:1.02189	valid-rmse:1.02533
[500]	train-rmse:1.09481	valid-rmse:1.09824
[640]	train-rmse:1.01436	valid-rmse:1.01783
[880]	train-rmse:1.09175	valid-rmse:1.09527
[720]	train-rmse:1.09868	valid-rmse:1.10187
[420]	train-rmse:1.00574	valid-rmse:1.00918
[320]	train-rmse:1.01959	valid-rmse:1.02303
[660]	train-rmse:1.01338	valid-rmse:1.01685
[900]	train-rmse:1.09159	valid-rmse:1.09512
[520]	train-rmse:1.09464	valid-rmse:1.09809
[440]	train-rmse:1.00466	valid-rmse:1.00810
[340]	train-rmse:1.01749	valid-rmse:1.02093
[740]	train-rmse:1.09867	valid-rmse:1.10186
[680]	train-rmse:1.01245	valid-rmse:1.01591
[920]	train-rmse:1.09143	valid-rmse:1.09497
[460]	train-rmse:1.00370	valid-rmse:1.00714
[360]	train-rmse:1.01557	valid-rmse:1.01900
[540]	train-rmse:1.09448	valid-rmse:1.09793
[700]	train-rmse:1.01157	valid-rmse:1.01503
[760]	train-rmse:1.09866	valid-rmse:1.10184
[940]	train-rmse:1.09127	valid-rmse:1.09482
[480]	train-rmse:1.00282	valid-rmse:1.00628
[380]	train-rmse:1.01382	valid-rmse:1.01725
[720]	train-rmse:1.01074	valid-rmse:1.01419
[560]	train-rmse:1.09431	valid-rmse:1.09778
[500]	train-rmse:1.00204	valid-rmse:1.00550
[780]	train-rmse:1.09865	valid-rmse:1.10183
[960]	train-rmse:1.09111	valid-rmse:1.09466
[400]	train-rmse:1.01222	valid-rmse:1.01565
[740]	train-rmse:1.00994	valid-rmse:1.01340
[520]	train-rmse:1.00134	valid-rmse:1.00481
[420]	train-rmse:1.01076	valid-rmse:1.01419
[580]	train-rmse:1.09414	valid-rmse:1.09762
[980]	train-rmse:1.09095	valid-rmse:1.09451
[800]	train-rmse:1.09864	valid-rmse:1.10182
[760]	train-rmse:1.00919	valid-rmse:1.01265
[540]	train-rmse:1.00071	valid-rmse:1.00419
[440]	train-rmse:1.00943	valid-rmse:1.01285
[999]	train-rmse:1.09080	valid-rmse:1.09437
[780]	train-rmse:1.00848	valid-rmse:1.01193
[32m[I 2022-04-16 20:28:08,620][0m Trial 17 finished with value: 1.094367 and parameters: {'colsample_bytree': 0.5936197358868985, 'eta': 4.256150803363845e-05, 'max_depth': 7, 'n_estimators': 31, 'subsample': 0.3215783124053698}. Best is trial 19 with value: 0.998533.[0m
[20:28:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09823	valid-rmse:1.10141
[600]	train-rmse:1.09398	valid-rmse:1.09746
[560]	train-rmse:1.00014	valid-rmse:1.00363
[820]	train-rmse:1.09863	valid-rmse:1.10181
[460]	train-rmse:1.00822	valid-rmse:1.01163
[800]	train-rmse:1.00780	valid-rmse:1.01125
[20]	train-rmse:1.08283	valid-rmse:1.08611
[580]	train-rmse:0.99962	valid-rmse:1.00313
[480]	train-rmse:1.00711	valid-rmse:1.01052
[840]	train-rmse:1.09862	valid-rmse:1.10180
[620]	train-rmse:1.09381	valid-rmse:1.09731
[820]	train-rmse:1.00716	valid-rmse:1.01061
[40]	train-rmse:1.06969	valid-rmse:1.07303
[600]	train-rmse:0.99915	valid-rmse:1.00268
[500]	train-rmse:1.00610	valid-rmse:1.00950
[860]	train-rmse:1.09861	valid-rmse:1.10179
[840]	train-rmse:1.00655	valid-rmse:1.01001
[620]	train-rmse:0.99873	valid-rmse:1.00228
[640]	train-rmse:1.09364	valid-rmse:1.09716
[60]	train-rmse:1.05849	valid-rmse:1.06187
[520]	train-rmse:1.00517	valid-rmse:1.00857
[640]	train-rmse:0.99835	valid-rmse:1.00191
[860]	train-rmse:1.00598	valid-rmse:1.00943
[80]	train-rmse:1.04897	valid-rmse:1.05238
[880]	train-rmse:1.09859	valid-rmse:1.10178
[540]	train-rmse:1.00432	valid-rmse:1.00773
[660]	train-rmse:1.09348	valid-rmse:1.09700
[660]	train-rmse:0.99800	valid-rmse:1.00158
[880]	train-rmse:1.00543	valid-rmse:1.00888
[100]	train-rmse:1.04088	valid-rmse:1.04431
[560]	train-rmse:1.00355	valid-rmse:1.00695
[900]	train-rmse:1.09858	valid-rmse:1.10177
[680]	train-rmse:0.99769	valid-rmse:1.00129
[680]	train-rmse:1.09332	valid-rmse:1.09685
[120]	train-rmse:1.03400	valid-rmse:1.03745
[900]	train-rmse:1.00491	valid-rmse:1.00836
[580]	train-rmse:1.00283	valid-rmse:1.00625
[700]	train-rmse:0.99740	valid-rmse:1.00103
[140]	train-rmse:1.02816	valid-rmse:1.03160
[920]	train-rmse:1.00441	valid-rmse:1.00787
[920]	train-rmse:1.09857	valid-rmse:1.10176
[600]	train-rmse:1.00219	valid-rmse:1.00560
[700]	train-rmse:1.09315	valid-rmse:1.09669
[720]	train-rmse:0.99714	valid-rmse:1.00079
[160]	train-rmse:1.02320	valid-rmse:1.02665
[940]	train-rmse:1.00395	valid-rmse:1.00740
[620]	train-rmse:1.00159	valid-rmse:1.00501
[940]	train-rmse:1.09856	valid-rmse:1.10175
[740]	train-rmse:0.99691	valid-rmse:1.00058
[720]	train-rmse:1.09299	valid-rmse:1.09654
[180]	train-rmse:1.01900	valid-rmse:1.02244
[960]	train-rmse:1.00350	valid-rmse:1.00696
[640]	train-rmse:1.00104	valid-rmse:1.00447
[760]	train-rmse:0.99669	valid-rmse:1.00039
[960]	train-rmse:1.09855	valid-rmse:1.10174
[200]	train-rmse:1.01544	valid-rmse:1.01887
[980]	train-rmse:1.00308	valid-rmse:1.00654
[660]	train-rmse:1.00054	valid-rmse:1.00398
[740]	train-rmse:1.09282	valid-rmse:1.09638
[780]	train-rmse:0.99649	valid-rmse:1.00021
[220]	train-rmse:1.01241	valid-rmse:1.01583
[999]	train-rmse:1.00269	valid-rmse:1.00616
[32m[I 2022-04-16 20:39:24,404][0m Trial 21 finished with value: 1.006157 and parameters: {'colsample_bytree': 0.8143025801469718, 'eta': 0.0013972713364916007, 'max_depth': 3, 'n_estimators': 782, 'subsample': 0.9513790208784552}. Best is trial 19 with value: 0.998533.[0m
[20:39:28] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[680]	train-rmse:1.00008	valid-rmse:1.00353
[0]	train-rmse:1.09820	valid-rmse:1.10138
[980]	train-rmse:1.09854	valid-rmse:1.10173
[800]	train-rmse:0.99630	valid-rmse:1.00005
[760]	train-rmse:1.09266	valid-rmse:1.09623
[240]	train-rmse:1.00985	valid-rmse:1.01325
[20]	train-rmse:1.08227	valid-rmse:1.08555
[700]	train-rmse:0.99966	valid-rmse:1.00312
[820]	train-rmse:0.99613	valid-rmse:0.99991
[999]	train-rmse:1.09853	valid-rmse:1.10172
[32m[I 2022-04-16 20:40:59,198][0m Trial 18 finished with value: 1.101721 and parameters: {'colsample_bytree': 0.7808808222684862, 'eta': 2.693632348124867e-06, 'max_depth': 5, 'n_estimators': 159, 'subsample': 0.6863904497705209}. Best is trial 19 with value: 0.998533.[0m
[20:41:03] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09794	valid-rmse:1.10113
[260]	train-rmse:1.00768	valid-rmse:1.01107
[40]	train-rmse:1.06876	valid-rmse:1.07210
[720]	train-rmse:0.99928	valid-rmse:1.00274
[780]	train-rmse:1.09250	valid-rmse:1.09608
[840]	train-rmse:0.99597	valid-rmse:0.99978
[20]	train-rmse:1.07785	valid-rmse:1.08115
[280]	train-rmse:1.00582	valid-rmse:1.00922
[60]	train-rmse:1.05731	valid-rmse:1.06070
[740]	train-rmse:0.99892	valid-rmse:1.00239
[860]	train-rmse:0.99582	valid-rmse:0.99966
[40]	train-rmse:1.06163	valid-rmse:1.06500
[800]	train-rmse:1.09233	valid-rmse:1.09593
[300]	train-rmse:1.00425	valid-rmse:1.00765
[80]	train-rmse:1.04763	valid-rmse:1.05106
[760]	train-rmse:0.99859	valid-rmse:1.00208
[880]	train-rmse:0.99568	valid-rmse:0.99956
[60]	train-rmse:1.04855	valid-rmse:1.05197
[320]	train-rmse:1.00290	valid-rmse:1.00631
[100]	train-rmse:1.03947	valid-rmse:1.04292
[780]	train-rmse:0.99829	valid-rmse:1.00179
[820]	train-rmse:1.09217	valid-rmse:1.09577
[900]	train-rmse:0.99555	valid-rmse:0.99947
[80]	train-rmse:1.03803	valid-rmse:1.04148
[120]	train-rmse:1.03257	valid-rmse:1.03603
[340]	train-rmse:1.00176	valid-rmse:1.00518
[800]	train-rmse:0.99801	valid-rmse:1.00152
[920]	train-rmse:0.99543	valid-rmse:0.99938
[100]	train-rmse:1.02961	valid-rmse:1.03308
[840]	train-rmse:1.09201	valid-rmse:1.09562
[140]	train-rmse:1.02674	valid-rmse:1.03022
[360]	train-rmse:1.00078	valid-rmse:1.00421
[820]	train-rmse:0.99775	valid-rmse:1.00128
[940]	train-rmse:0.99532	valid-rmse:0.99930
[120]	train-rmse:1.02283	valid-rmse:1.02632
[160]	train-rmse:1.02183	valid-rmse:1.02532
[380]	train-rmse:0.99995	valid-rmse:1.00338
[860]	train-rmse:1.09184	valid-rmse:1.09547
[840]	train-rmse:0.99751	valid-rmse:1.00106
[960]	train-rmse:0.99521	valid-rmse:0.99923
[140]	train-rmse:1.01741	valid-rmse:1.02088
[180]	train-rmse:1.01769	valid-rmse:1.02118
[400]	train-rmse:0.99924	valid-rmse:1.00268
[860]	train-rmse:0.99729	valid-rmse:1.00085
[980]	train-rmse:0.99511	valid-rmse:0.99917
[160]	train-rmse:1.01305	valid-rmse:1.01652
[200]	train-rmse:1.01420	valid-rmse:1.01769
[880]	train-rmse:1.09168	valid-rmse:1.09532
[420]	train-rmse:0.99861	valid-rmse:1.00208
[880]	train-rmse:0.99708	valid-rmse:1.00067
[999]	train-rmse:0.99501	valid-rmse:0.99912
[32m[I 2022-04-16 20:49:23,647][0m Trial 22 finished with value: 0.999118 and parameters: {'colsample_bytree': 0.7466559438472331, 'eta': 0.002885444710052222, 'max_depth': 3, 'n_estimators': 699, 'subsample': 0.9588062880689315}. Best is trial 19 with value: 0.998533.[0m
[180]	train-rmse:1.00955	valid-rmse:1.01303
[20:49:27] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09794	valid-rmse:1.10113
[220]	train-rmse:1.01126	valid-rmse:1.01475
[440]	train-rmse:0.99808	valid-rmse:1.00158
[900]	train-rmse:0.99689	valid-rmse:1.00050
[900]	train-rmse:1.09152	valid-rmse:1.09516
[200]	train-rmse:1.00675	valid-rmse:1.01023
[20]	train-rmse:1.07780	valid-rmse:1.08111
[240]	train-rmse:1.00880	valid-rmse:1.01226
[460]	train-rmse:0.99761	valid-rmse:1.00114
[40]	train-rmse:1.06155	valid-rmse:1.06494
[920]	train-rmse:0.99671	valid-rmse:1.00034
[220]	train-rmse:1.00450	valid-rmse:1.00798
[260]	train-rmse:1.00672	valid-rmse:1.01016
[920]	train-rmse:1.09136	valid-rmse:1.09501
[480]	train-rmse:0.99720	valid-rmse:1.00078
[60]	train-rmse:1.04846	valid-rmse:1.05190
[940]	train-rmse:0.99655	valid-rmse:1.00020
[240]	train-rmse:1.00271	valid-rmse:1.00617
[280]	train-rmse:1.00494	valid-rmse:1.00839
[80]	train-rmse:1.03794	valid-rmse:1.04141
[500]	train-rmse:0.99684	valid-rmse:1.00046
[940]	train-rmse:1.09119	valid-rmse:1.09486
[260]	train-rmse:1.00125	valid-rmse:1.00472
[960]	train-rmse:0.99639	valid-rmse:1.00006
[300]	train-rmse:1.00344	valid-rmse:1.00691
[100]	train-rmse:1.02950	valid-rmse:1.03300
[520]	train-rmse:0.99654	valid-rmse:1.00019
[280]	train-rmse:1.00007	valid-rmse:1.00355
[980]	train-rmse:0.99625	valid-rmse:0.99994
[320]	train-rmse:1.00218	valid-rmse:1.00564
[120]	train-rmse:1.02273	valid-rmse:1.02623
[960]	train-rmse:1.09103	valid-rmse:1.09471
[540]	train-rmse:0.99626	valid-rmse:0.99996
[300]	train-rmse:0.99909	valid-rmse:1.00261
[340]	train-rmse:1.00111	valid-rmse:1.00458
[999]	train-rmse:0.99611	valid-rmse:0.99984
[32m[I 2022-04-16 20:55:03,830][0m Trial 23 finished with value: 0.999838 and parameters: {'colsample_bytree': 0.7595975664731887, 'eta': 0.0023907067914161096, 'max_depth': 3, 'n_estimators': 690, 'subsample': 0.9877600388459709}. Best is trial 19 with value: 0.998533.[0m
[20:55:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09484	valid-rmse:1.09804
[140]	train-rmse:1.01732	valid-rmse:1.02082
[560]	train-rmse:0.99602	valid-rmse:0.99976
[360]	train-rmse:1.00020	valid-rmse:1.00368
[320]	train-rmse:0.99830	valid-rmse:1.00185
[160]	train-rmse:1.01297	valid-rmse:1.01645
[980]	train-rmse:1.09087	valid-rmse:1.09456
[20]	train-rmse:1.03818	valid-rmse:1.04168
[380]	train-rmse:0.99941	valid-rmse:1.00292
[580]	train-rmse:0.99580	valid-rmse:0.99959
[340]	train-rmse:0.99765	valid-rmse:1.00125
[180]	train-rmse:1.00947	valid-rmse:1.01296
[40]	train-rmse:1.01373	valid-rmse:1.01723
[999]	train-rmse:1.09072	valid-rmse:1.09441
[32m[I 2022-04-16 20:57:35,497][0m Trial 20 finished with value: 1.094415 and parameters: {'colsample_bytree': 0.4212212632262697, 'eta': 4.224431679602087e-05, 'max_depth': 7, 'n_estimators': 391, 'subsample': 0.8299781767468799}. Best is trial 19 with value: 0.998533.[0m
[200]	train-rmse:1.00668	valid-rmse:1.01016
[20:57:39] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[400]	train-rmse:0.99874	valid-rmse:1.00227
[0]	train-rmse:1.09670	valid-rmse:1.09989
[360]	train-rmse:0.99711	valid-rmse:1.00076
[600]	train-rmse:0.99560	valid-rmse:0.99944
[220]	train-rmse:1.00442	valid-rmse:1.00792
[60]	train-rmse:1.00323	valid-rmse:1.00676
[20]	train-rmse:1.05868	valid-rmse:1.06208
[420]	train-rmse:0.99816	valid-rmse:1.00172
[380]	train-rmse:0.99665	valid-rmse:1.00035
[620]	train-rmse:0.99541	valid-rmse:0.99932
[240]	train-rmse:1.00262	valid-rmse:1.00611
[40]	train-rmse:1.03493	valid-rmse:1.03840
[440]	train-rmse:0.99768	valid-rmse:1.00125
[80]	train-rmse:0.99856	valid-rmse:1.00225
[400]	train-rmse:0.99626	valid-rmse:1.00003
[640]	train-rmse:0.99526	valid-rmse:0.99921
[260]	train-rmse:1.00116	valid-rmse:1.00467
[60]	train-rmse:1.02005	valid-rmse:1.02351
[460]	train-rmse:0.99725	valid-rmse:1.00086
[420]	train-rmse:0.99592	valid-rmse:0.99976
[100]	train-rmse:0.99640	valid-rmse:1.00023
[660]	train-rmse:0.99510	valid-rmse:0.99911
[280]	train-rmse:0.99998	valid-rmse:1.00350
[80]	train-rmse:1.01074	valid-rmse:1.01426
[480]	train-rmse:0.99688	valid-rmse:1.00052
[440]	train-rmse:0.99564	valid-rmse:0.99955
[300]	train-rmse:0.99901	valid-rmse:1.00257
[680]	train-rmse:0.99497	valid-rmse:0.99903
[120]	train-rmse:0.99526	valid-rmse:0.99936
[100]	train-rmse:1.00495	valid-rmse:1.00852
[500]	train-rmse:0.99655	valid-rmse:1.00024
[460]	train-rmse:0.99539	valid-rmse:0.99937
[320]	train-rmse:0.99823	valid-rmse:1.00181
[120]	train-rmse:1.00127	valid-rmse:1.00490
[700]	train-rmse:0.99483	valid-rmse:0.99896
[140]	train-rmse:0.99448	valid-rmse:0.99895
[520]	train-rmse:0.99627	valid-rmse:0.99999
[480]	train-rmse:0.99517	valid-rmse:0.99923
[340]	train-rmse:0.99759	valid-rmse:1.00120
[140]	train-rmse:0.99891	valid-rmse:1.00263
[720]	train-rmse:0.99472	valid-rmse:0.99889
[540]	train-rmse:0.99601	valid-rmse:0.99980
[160]	train-rmse:0.99392	valid-rmse:0.99876
[360]	train-rmse:0.99704	valid-rmse:1.00072
[500]	train-rmse:0.99497	valid-rmse:0.99911
[160]	train-rmse:0.99736	valid-rmse:1.00119
[740]	train-rmse:0.99461	valid-rmse:0.99884
[560]	train-rmse:0.99579	valid-rmse:0.99962
[380]	train-rmse:0.99659	valid-rmse:1.00031
[180]	train-rmse:0.99633	valid-rmse:1.00029
[520]	train-rmse:0.99480	valid-rmse:0.99901
[180]	train-rmse:0.99339	valid-rmse:0.99867
[760]	train-rmse:0.99451	valid-rmse:0.99879
[400]	train-rmse:0.99621	valid-rmse:0.99999
[580]	train-rmse:0.99557	valid-rmse:0.99947
[200]	train-rmse:0.99563	valid-rmse:0.99972
[540]	train-rmse:0.99464	valid-rmse:0.99894
[200]	train-rmse:0.99294	valid-rmse:0.99862
[420]	train-rmse:0.99588	valid-rmse:0.99973
[780]	train-rmse:0.99441	valid-rmse:0.99875
[220]	train-rmse:0.99506	valid-rmse:0.99936
[600]	train-rmse:0.99539	valid-rmse:0.99935
[560]	train-rmse:0.99448	valid-rmse:0.99887
[220]	train-rmse:0.99249	valid-rmse:0.99862
[440]	train-rmse:0.99559	valid-rmse:0.99951
[240]	train-rmse:0.99464	valid-rmse:0.99911
[800]	train-rmse:0.99431	valid-rmse:0.99871
[620]	train-rmse:0.99521	valid-rmse:0.99924
[580]	train-rmse:0.99434	valid-rmse:0.99881
[460]	train-rmse:0.99533	valid-rmse:0.99934
[260]	train-rmse:0.99428	valid-rmse:0.99897
[240]	train-rmse:0.99208	valid-rmse:0.99863
[640]	train-rmse:0.99506	valid-rmse:0.99914
[820]	train-rmse:0.99421	valid-rmse:0.99867
[600]	train-rmse:0.99421	valid-rmse:0.99876
[480]	train-rmse:0.99511	valid-rmse:0.99920
[280]	train-rmse:0.99398	valid-rmse:0.99886
[660]	train-rmse:0.99491	valid-rmse:0.99906
[260]	train-rmse:0.99166	valid-rmse:0.99864
[840]	train-rmse:0.99412	valid-rmse:0.99865
[620]	train-rmse:0.99406	valid-rmse:0.99872
[500]	train-rmse:0.99491	valid-rmse:0.99908
[300]	train-rmse:0.99367	valid-rmse:0.99881
[680]	train-rmse:0.99477	valid-rmse:0.99899
[860]	train-rmse:0.99403	valid-rmse:0.99863
[520]	train-rmse:0.99473	valid-rmse:0.99898
[640]	train-rmse:0.99394	valid-rmse:0.99868
[280]	train-rmse:0.99127	valid-rmse:0.99861
[320]	train-rmse:0.99338	valid-rmse:0.99878
[700]	train-rmse:0.99465	valid-rmse:0.99892
[540]	train-rmse:0.99457	valid-rmse:0.99891
[340]	train-rmse:0.99314	valid-rmse:0.99876
[880]	train-rmse:0.99393	valid-rmse:0.99861
[660]	train-rmse:0.99382	valid-rmse:0.99866
[300]	train-rmse:0.99084	valid-rmse:0.99863
[720]	train-rmse:0.99454	valid-rmse:0.99887
[560]	train-rmse:0.99440	valid-rmse:0.99884
[360]	train-rmse:0.99286	valid-rmse:0.99874
[680]	train-rmse:0.99369	valid-rmse:0.99864
[900]	train-rmse:0.99386	valid-rmse:0.99859
[320]	train-rmse:0.99043	valid-rmse:0.99865
[740]	train-rmse:0.99443	valid-rmse:0.99883
[580]	train-rmse:0.99425	valid-rmse:0.99879
[380]	train-rmse:0.99261	valid-rmse:0.99873
[700]	train-rmse:0.99357	valid-rmse:0.99862
[920]	train-rmse:0.99377	valid-rmse:0.99857
[332]	train-rmse:0.99018	valid-rmse:0.99866
[32m[I 2022-04-16 21:13:40,548][0m Trial 28 finished with value: 0.9986 and parameters: {'colsample_bytree': 0.9995680480808171, 'eta': 0.02205369193185243, 'max_depth': 3, 'n_estimators': 571, 'subsample': 0.810998083890908}. Best is trial 19 with value: 0.998533.[0m
[21:13:44] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09652	valid-rmse:1.09972
[600]	train-rmse:0.99412	valid-rmse:0.99874
[760]	train-rmse:0.99433	valid-rmse:0.99878
[400]	train-rmse:0.99238	valid-rmse:0.99872
[720]	train-rmse:0.99345	valid-rmse:0.99860
[940]	train-rmse:0.99369	valid-rmse:0.99856
[20]	train-rmse:1.05661	valid-rmse:1.06005
[620]	train-rmse:0.99398	valid-rmse:0.99869
[420]	train-rmse:0.99214	valid-rmse:0.99873
[780]	train-rmse:0.99423	valid-rmse:0.99875
[740]	train-rmse:0.99333	valid-rmse:0.99858
[640]	train-rmse:0.99386	valid-rmse:0.99866
[40]	train-rmse:1.03237	valid-rmse:1.03586
[960]	train-rmse:0.99361	valid-rmse:0.99854
[440]	train-rmse:0.99189	valid-rmse:0.99872
[800]	train-rmse:0.99413	valid-rmse:0.99872
[443]	train-rmse:0.99186	valid-rmse:0.99872
[32m[I 2022-04-16 21:15:56,041][0m Trial 29 finished with value: 0.998718 and parameters: {'colsample_bytree': 0.9889924833947994, 'eta': 0.012387603055719534, 'max_depth': 3, 'n_estimators': 552, 'subsample': 0.4699665487787907}. Best is trial 19 with value: 0.998533.[0m
[21:16:00] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09902	valid-rmse:1.10220
[760]	train-rmse:0.99323	valid-rmse:0.99857
[660]	train-rmse:0.99373	valid-rmse:0.99865
[60]	train-rmse:1.01770	valid-rmse:1.02117
[980]	train-rmse:0.99352	valid-rmse:0.99854
[820]	train-rmse:0.99403	valid-rmse:0.99869
[20]	train-rmse:1.09824	valid-rmse:1.10142
[680]	train-rmse:0.99361	valid-rmse:0.99862
[80]	train-rmse:1.00886	valid-rmse:1.01234
[780]	train-rmse:0.99310	valid-rmse:0.99856
[999]	train-rmse:0.99344	valid-rmse:0.99853
[32m[I 2022-04-16 21:17:31,193][0m Trial 24 finished with value: 0.998526 and parameters: {'colsample_bytree': 0.7696199307872923, 'eta': 0.004307288977127075, 'max_depth': 3, 'n_estimators': 728, 'subsample': 0.979512047869921}. Best is trial 24 with value: 0.998526.[0m
[21:17:35] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[840]	train-rmse:0.99393	valid-rmse:0.99867
[0]	train-rmse:1.09567	valid-rmse:1.09888
[40]	train-rmse:1.09746	valid-rmse:1.10065
[700]	train-rmse:0.99349	valid-rmse:0.99860
[100]	train-rmse:1.00351	valid-rmse:1.00701
[800]	train-rmse:0.99299	valid-rmse:0.99855
[860]	train-rmse:0.99384	valid-rmse:0.99865
[60]	train-rmse:1.09668	valid-rmse:1.09987
[20]	train-rmse:1.04672	valid-rmse:1.05019
[720]	train-rmse:0.99337	valid-rmse:0.99859
[120]	train-rmse:1.00016	valid-rmse:1.00376
[820]	train-rmse:0.99289	valid-rmse:0.99854
[880]	train-rmse:0.99375	valid-rmse:0.99864
[80]	train-rmse:1.09592	valid-rmse:1.09911
[740]	train-rmse:0.99326	valid-rmse:0.99858
[140]	train-rmse:0.99811	valid-rmse:1.00179
[40]	train-rmse:1.02155	valid-rmse:1.02510
[840]	train-rmse:0.99278	valid-rmse:0.99854
[100]	train-rmse:1.09516	valid-rmse:1.09836
[900]	train-rmse:0.99367	valid-rmse:0.99862
[760]	train-rmse:0.99315	valid-rmse:0.99857
[160]	train-rmse:0.99680	valid-rmse:1.00058
[860]	train-rmse:0.99268	valid-rmse:0.99853
[60]	train-rmse:1.00873	valid-rmse:1.01224
[120]	train-rmse:1.09440	valid-rmse:1.09760
[780]	train-rmse:0.99303	valid-rmse:0.99856
[920]	train-rmse:0.99358	valid-rmse:0.99861
[180]	train-rmse:0.99591	valid-rmse:0.99982
[880]	train-rmse:0.99257	valid-rmse:0.99853
[140]	train-rmse:1.09364	valid-rmse:1.09686
[800]	train-rmse:0.99291	valid-rmse:0.99855
[80]	train-rmse:1.00216	valid-rmse:1.00566
[940]	train-rmse:0.99349	valid-rmse:0.99859
[200]	train-rmse:0.99528	valid-rmse:0.99937
[900]	train-rmse:0.99246	valid-rmse:0.99853
[160]	train-rmse:1.09290	valid-rmse:1.09611
[820]	train-rmse:0.99281	valid-rmse:0.99855
[960]	train-rmse:0.99341	valid-rmse:0.99857
[220]	train-rmse:0.99478	valid-rmse:0.99907
[100]	train-rmse:0.99873	valid-rmse:1.00231
[840]	train-rmse:0.99270	valid-rmse:0.99854
[180]	train-rmse:1.09215	valid-rmse:1.09538
[920]	train-rmse:0.99235	valid-rmse:0.99852
[980]	train-rmse:0.99332	valid-rmse:0.99857
[240]	train-rmse:0.99438	valid-rmse:0.99886
[120]	train-rmse:0.99685	valid-rmse:1.00058
[860]	train-rmse:0.99259	valid-rmse:0.99854
[200]	train-rmse:1.09142	valid-rmse:1.09465
[940]	train-rmse:0.99224	valid-rmse:0.99852
[999]	train-rmse:0.99323	valid-rmse:0.99856
[260]	train-rmse:0.99403	valid-rmse:0.99875
[32m[I 2022-04-16 21:24:57,827][0m Trial 25 finished with value: 0.99856 and parameters: {'colsample_bytree': 0.7245531632852765, 'eta': 0.004471220726514177, 'max_depth': 3, 'n_estimators': 738, 'subsample': 0.9522568467522557}. Best is trial 24 with value: 0.998526.[0m
[21:25:02] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09899	valid-rmse:1.10217
[880]	train-rmse:0.99248	valid-rmse:0.99854
[140]	train-rmse:0.99573	valid-rmse:0.99965
[220]	train-rmse:1.09069	valid-rmse:1.09392
[960]	train-rmse:0.99215	valid-rmse:0.99852
[280]	train-rmse:0.99374	valid-rmse:0.99866
[20]	train-rmse:1.09763	valid-rmse:1.10081
[900]	train-rmse:0.99237	valid-rmse:0.99854
[240]	train-rmse:1.08997	valid-rmse:1.09320
[160]	train-rmse:0.99500	valid-rmse:0.99916
[300]	train-rmse:0.99344	valid-rmse:0.99862
[980]	train-rmse:0.99206	valid-rmse:0.99852
[40]	train-rmse:1.09628	valid-rmse:1.09947
[920]	train-rmse:0.99227	valid-rmse:0.99853
[260]	train-rmse:1.08925	valid-rmse:1.09249
[320]	train-rmse:0.99314	valid-rmse:0.99860
[999]	train-rmse:0.99196	valid-rmse:0.99852
[32m[I 2022-04-16 21:27:35,887][0m Trial 26 finished with value: 0.998517 and parameters: {'colsample_bytree': 0.743203134611689, 'eta': 0.005784923430936532, 'max_depth': 3, 'n_estimators': 618, 'subsample': 0.9304737507055861}. Best is trial 26 with value: 0.998517.[0m
[60]	train-rmse:1.09495	valid-rmse:1.09815
[21:27:40] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[180]	train-rmse:0.99445	valid-rmse:0.99889
[0]	train-rmse:1.09901	valid-rmse:1.10219
[940]	train-rmse:0.99217	valid-rmse:0.99852
[280]	train-rmse:1.08853	valid-rmse:1.09177
[340]	train-rmse:0.99286	valid-rmse:0.99860
[80]	train-rmse:1.09364	valid-rmse:1.09685
[960]	train-rmse:0.99205	valid-rmse:0.99852
[200]	train-rmse:0.99403	valid-rmse:0.99876
[300]	train-rmse:1.08782	valid-rmse:1.09107
[20]	train-rmse:1.09796	valid-rmse:1.10116
[360]	train-rmse:0.99259	valid-rmse:0.99859
[100]	train-rmse:1.09234	valid-rmse:1.09556
[980]	train-rmse:0.99195	valid-rmse:0.99852
[320]	train-rmse:1.08712	valid-rmse:1.09037
[220]	train-rmse:0.99362	valid-rmse:0.99868
[380]	train-rmse:0.99234	valid-rmse:0.99858
[120]	train-rmse:1.09106	valid-rmse:1.09429
[999]	train-rmse:0.99186	valid-rmse:0.99852
[32m[I 2022-04-16 21:30:24,097][0m Trial 27 finished with value: 0.998512 and parameters: {'colsample_bytree': 0.6804769768982715, 'eta': 0.005802874383382983, 'max_depth': 3, 'n_estimators': 659, 'subsample': 0.8473039095658501}. Best is trial 27 with value: 0.998512.[0m
[21:30:28] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[40]	train-rmse:1.09692	valid-rmse:1.10015
[0]	train-rmse:1.09903	valid-rmse:1.10221
[340]	train-rmse:1.08642	valid-rmse:1.08968
[400]	train-rmse:0.99209	valid-rmse:0.99857
[240]	train-rmse:0.99328	valid-rmse:0.99863
[140]	train-rmse:1.08980	valid-rmse:1.09303
[360]	train-rmse:1.08573	valid-rmse:1.08899
[420]	train-rmse:0.99184	valid-rmse:0.99857
[60]	train-rmse:1.09588	valid-rmse:1.09915
[160]	train-rmse:1.08855	valid-rmse:1.09179
[20]	train-rmse:1.09835	valid-rmse:1.10154
[260]	train-rmse:0.99295	valid-rmse:0.99860
[380]	train-rmse:1.08504	valid-rmse:1.08831
[440]	train-rmse:0.99160	valid-rmse:0.99857
[180]	train-rmse:1.08732	valid-rmse:1.09057
[400]	train-rmse:1.08435	valid-rmse:1.08763
[280]	train-rmse:0.99262	valid-rmse:0.99858
[80]	train-rmse:1.09486	valid-rmse:1.09815
[40]	train-rmse:1.09767	valid-rmse:1.10088
[460]	train-rmse:0.99135	valid-rmse:0.99857
[200]	train-rmse:1.08610	valid-rmse:1.08936
[420]	train-rmse:1.08367	valid-rmse:1.08695
[300]	train-rmse:0.99230	valid-rmse:0.99857
[220]	train-rmse:1.08490	valid-rmse:1.08816
[480]	train-rmse:0.99107	valid-rmse:0.99857
[32m[I 2022-04-16 21:34:35,819][0m Trial 30 finished with value: 0.998558 and parameters: {'colsample_bytree': 0.988867119798681, 'eta': 0.013231868624369397, 'max_depth': 3, 'n_estimators': 575, 'subsample': 0.5172017320814568}. Best is trial 27 with value: 0.998512.[0m
[21:34:40] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.09699	valid-rmse:1.10022
[100]	train-rmse:1.09385	valid-rmse:1.09717
[0]	train-rmse:1.09899	valid-rmse:1.10217
[440]	train-rmse:1.08300	valid-rmse:1.08628
[240]	train-rmse:1.08372	valid-rmse:1.08699
[320]	train-rmse:0.99196	valid-rmse:0.99858
[460]	train-rmse:1.08233	valid-rmse:1.08562
[80]	train-rmse:1.09632	valid-rmse:1.09957
[120]	train-rmse:1.09285	valid-rmse:1.09620
[20]	train-rmse:1.09756	valid-rmse:1.10078
[260]	train-rmse:1.08255	valid-rmse:1.08583
[340]	train-rmse:0.99162	valid-rmse:0.99858
[480]	train-rmse:1.08167	valid-rmse:1.08496
[280]	train-rmse:1.08139	valid-rmse:1.08468
[355]	train-rmse:0.99140	valid-rmse:0.99859
[32m[I 2022-04-16 21:37:30,736][0m Trial 32 finished with value: 0.998563 and parameters: {'colsample_bytree': 0.9403857489994436, 'eta': 0.01757979207352174, 'max_depth': 3, 'n_estimators': 546, 'subsample': 0.9076496227549934}. Best is trial 27 with value: 0.998512.[0m
[500]	train-rmse:1.08101	valid-rmse:1.08431
[100]	train-rmse:1.09565	valid-rmse:1.09892
[140]	train-rmse:1.09185	valid-rmse:1.09523
[40]	train-rmse:1.09615	valid-rmse:1.09941
[21:37:35] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09900	valid-rmse:1.10218
[300]	train-rmse:1.08025	valid-rmse:1.08354
[520]	train-rmse:1.08036	valid-rmse:1.08366
[320]	train-rmse:1.07913	valid-rmse:1.08243
[60]	train-rmse:1.09476	valid-rmse:1.09806
[120]	train-rmse:1.09499	valid-rmse:1.09828
[20]	train-rmse:1.09777	valid-rmse:1.10098
[160]	train-rmse:1.09087	valid-rmse:1.09427
[540]	train-rmse:1.07971	valid-rmse:1.08301
[340]	train-rmse:1.07802	valid-rmse:1.08132
[560]	train-rmse:1.07906	valid-rmse:1.08237
[40]	train-rmse:1.09655	valid-rmse:1.09980
[80]	train-rmse:1.09339	valid-rmse:1.09672
[140]	train-rmse:1.09433	valid-rmse:1.09764
[180]	train-rmse:1.08989	valid-rmse:1.09333
[360]	train-rmse:1.07692	valid-rmse:1.08023
[580]	train-rmse:1.07843	valid-rmse:1.08173
[380]	train-rmse:1.07584	valid-rmse:1.07916
[60]	train-rmse:1.09535	valid-rmse:1.09862
[100]	train-rmse:1.09203	valid-rmse:1.09541
[160]	train-rmse:1.09367	valid-rmse:1.09700
[200]	train-rmse:1.08893	valid-rmse:1.09239
[600]	train-rmse:1.07779	valid-rmse:1.08110
[400]	train-rmse:1.07478	valid-rmse:1.07810
[620]	train-rmse:1.07716	valid-rmse:1.08048
[80]	train-rmse:1.09416	valid-rmse:1.09746
[420]	train-rmse:1.07372	valid-rmse:1.07705
[120]	train-rmse:1.09069	valid-rmse:1.09411
[180]	train-rmse:1.09302	valid-rmse:1.09637
[220]	train-rmse:1.08797	valid-rmse:1.09146
[640]	train-rmse:1.07654	valid-rmse:1.07986
[440]	train-rmse:1.07268	valid-rmse:1.07601
[100]	train-rmse:1.09298	valid-rmse:1.09632
[660]	train-rmse:1.07592	valid-rmse:1.07924
[140]	train-rmse:1.08937	valid-rmse:1.09282
[200]	train-rmse:1.09238	valid-rmse:1.09574
[240]	train-rmse:1.08702	valid-rmse:1.09054
[460]	train-rmse:1.07166	valid-rmse:1.07499
[120]	train-rmse:1.09181	valid-rmse:1.09518
[680]	train-rmse:1.07530	valid-rmse:1.07863
[480]	train-rmse:1.07064	valid-rmse:1.07398
[160]	train-rmse:1.08807	valid-rmse:1.09156
[220]	train-rmse:1.09173	valid-rmse:1.09512
[260]	train-rmse:1.08608	valid-rmse:1.08963
[700]	train-rmse:1.07469	valid-rmse:1.07802
[500]	train-rmse:1.06964	valid-rmse:1.07299
[140]	train-rmse:1.09066	valid-rmse:1.09406
[720]	train-rmse:1.07408	valid-rmse:1.07741
[180]	train-rmse:1.08678	valid-rmse:1.09031
[520]	train-rmse:1.06865	valid-rmse:1.07201
[240]	train-rmse:1.09110	valid-rmse:1.09449
[280]	train-rmse:1.08515	valid-rmse:1.08873
[160]	train-rmse:1.08952	valid-rmse:1.09295
[740]	train-rmse:1.07348	valid-rmse:1.07681
[540]	train-rmse:1.06768	valid-rmse:1.07103
[200]	train-rmse:1.08551	valid-rmse:1.08907
[760]	train-rmse:1.07288	valid-rmse:1.07622
[260]	train-rmse:1.09046	valid-rmse:1.09388
[300]	train-rmse:1.08423	valid-rmse:1.08783
[180]	train-rmse:1.08839	valid-rmse:1.09186
[560]	train-rmse:1.06672	valid-rmse:1.07008
[780]	train-rmse:1.07229	valid-rmse:1.07563
[580]	train-rmse:1.06577	valid-rmse:1.06913
[280]	train-rmse:1.08983	valid-rmse:1.09327
[220]	train-rmse:1.08425	valid-rmse:1.08786
[320]	train-rmse:1.08332	valid-rmse:1.08695
[200]	train-rmse:1.08727	valid-rmse:1.09077
[800]	train-rmse:1.07170	valid-rmse:1.07505
[600]	train-rmse:1.06484	valid-rmse:1.06820
[820]	train-rmse:1.07112	valid-rmse:1.07447
[220]	train-rmse:1.08617	valid-rmse:1.08970
[300]	train-rmse:1.08920	valid-rmse:1.09266
[240]	train-rmse:1.08302	valid-rmse:1.08666
[340]	train-rmse:1.08242	valid-rmse:1.08607
[620]	train-rmse:1.06391	valid-rmse:1.06728
[840]	train-rmse:1.07054	valid-rmse:1.07389
[640]	train-rmse:1.06300	valid-rmse:1.06638
[240]	train-rmse:1.08508	valid-rmse:1.08864
[320]	train-rmse:1.08858	valid-rmse:1.09205
[260]	train-rmse:1.08180	valid-rmse:1.08547
[360]	train-rmse:1.08153	valid-rmse:1.08521
[860]	train-rmse:1.06996	valid-rmse:1.07332
[660]	train-rmse:1.06210	valid-rmse:1.06548
[880]	train-rmse:1.06939	valid-rmse:1.07275
[260]	train-rmse:1.08401	valid-rmse:1.08759
[680]	train-rmse:1.06121	valid-rmse:1.06459
[340]	train-rmse:1.08796	valid-rmse:1.09145
[280]	train-rmse:1.08059	valid-rmse:1.08430
[380]	train-rmse:1.08064	valid-rmse:1.08435
[900]	train-rmse:1.06882	valid-rmse:1.07219
[700]	train-rmse:1.06034	valid-rmse:1.06372
[280]	train-rmse:1.08294	valid-rmse:1.08655
[920]	train-rmse:1.06826	valid-rmse:1.07163
[360]	train-rmse:1.08734	valid-rmse:1.09085
[300]	train-rmse:1.07940	valid-rmse:1.08315
[400]	train-rmse:1.07976	valid-rmse:1.08350
[720]	train-rmse:1.05947	valid-rmse:1.06286
[300]	train-rmse:1.08189	valid-rmse:1.08553
[940]	train-rmse:1.06770	valid-rmse:1.07107
[740]	train-rmse:1.05862	valid-rmse:1.06201
[380]	train-rmse:1.08673	valid-rmse:1.09026
[320]	train-rmse:1.07822	valid-rmse:1.08201
[420]	train-rmse:1.07889	valid-rmse:1.08265
[960]	train-rmse:1.06715	valid-rmse:1.07052
[760]	train-rmse:1.05778	valid-rmse:1.06117
[320]	train-rmse:1.08084	valid-rmse:1.08452
[980]	train-rmse:1.06660	valid-rmse:1.06998
[400]	train-rmse:1.08612	valid-rmse:1.08967
[340]	train-rmse:1.07706	valid-rmse:1.08088
[440]	train-rmse:1.07803	valid-rmse:1.08182
[780]	train-rmse:1.05695	valid-rmse:1.06034
[999]	train-rmse:1.06608	valid-rmse:1.06946
[340]	train-rmse:1.07981	valid-rmse:1.08352
[32m[I 2022-04-16 21:58:59,901][0m Trial 31 finished with value: 1.069461 and parameters: {'colsample_bytree': 0.9693084667895933, 'eta': 0.00020333018363057702, 'max_depth': 3, 'n_estimators': 571, 'subsample': 0.5307551146210268}. Best is trial 27 with value: 0.998512.[0m
[21:59:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09898	valid-rmse:1.10216
[800]	train-rmse:1.05612	valid-rmse:1.05953
[420]	train-rmse:1.08552	valid-rmse:1.08908
[360]	train-rmse:1.07592	valid-rmse:1.07977
[460]	train-rmse:1.07718	valid-rmse:1.08099
[820]	train-rmse:1.05532	valid-rmse:1.05872
[360]	train-rmse:1.07879	valid-rmse:1.08253
[20]	train-rmse:1.09738	valid-rmse:1.10060
[840]	train-rmse:1.05452	valid-rmse:1.05792
[440]	train-rmse:1.08492	valid-rmse:1.08850
[380]	train-rmse:1.07479	valid-rmse:1.07868
[480]	train-rmse:1.07633	valid-rmse:1.08017
[380]	train-rmse:1.07779	valid-rmse:1.08156
[40]	train-rmse:1.09580	valid-rmse:1.09907
[860]	train-rmse:1.05373	valid-rmse:1.05714
[460]	train-rmse:1.08432	valid-rmse:1.08792
[400]	train-rmse:1.07367	valid-rmse:1.07760
[500]	train-rmse:1.07550	valid-rmse:1.07936
[880]	train-rmse:1.05295	valid-rmse:1.05636
[400]	train-rmse:1.07679	valid-rmse:1.08059
[60]	train-rmse:1.09425	valid-rmse:1.09755
[900]	train-rmse:1.05218	valid-rmse:1.05560
[480]	train-rmse:1.08373	valid-rmse:1.08734
[420]	train-rmse:1.07258	valid-rmse:1.07653
[520]	train-rmse:1.07467	valid-rmse:1.07856
[420]	train-rmse:1.07580	valid-rmse:1.07963
[80]	train-rmse:1.09272	valid-rmse:1.09606
[920]	train-rmse:1.05143	valid-rmse:1.05484
[940]	train-rmse:1.05068	valid-rmse:1.05410
[440]	train-rmse:1.07483	valid-rmse:1.07868
[500]	train-rmse:1.08314	valid-rmse:1.08677
[440]	train-rmse:1.07149	valid-rmse:1.07548
[540]	train-rmse:1.07385	valid-rmse:1.07776
[100]	train-rmse:1.09121	valid-rmse:1.09459
[960]	train-rmse:1.04994	valid-rmse:1.05336
[460]	train-rmse:1.07387	valid-rmse:1.07775
[520]	train-rmse:1.08255	valid-rmse:1.08620
[460]	train-rmse:1.07042	valid-rmse:1.07444
[560]	train-rmse:1.07304	valid-rmse:1.07697
[120]	train-rmse:1.08971	valid-rmse:1.09315
[980]	train-rmse:1.04921	valid-rmse:1.05264
[999]	train-rmse:1.04853	valid-rmse:1.05196
[32m[I 2022-04-16 22:07:49,096][0m Trial 33 finished with value: 1.051958 and parameters: {'colsample_bytree': 0.6898516745927956, 'eta': 0.00035396562181145186, 'max_depth': 3, 'n_estimators': 840, 'subsample': 0.9008547346486395}. Best is trial 27 with value: 0.998512.[0m
[480]	train-rmse:1.07292	valid-rmse:1.07683
[22:07:53] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09894	valid-rmse:1.10212
[540]	train-rmse:1.08197	valid-rmse:1.08564
[480]	train-rmse:1.06936	valid-rmse:1.07342
[140]	train-rmse:1.08825	valid-rmse:1.09172
[580]	train-rmse:1.07223	valid-rmse:1.07620
[500]	train-rmse:1.07197	valid-rmse:1.07592
[20]	train-rmse:1.09653	valid-rmse:1.09977
[560]	train-rmse:1.08139	valid-rmse:1.08508
[160]	train-rmse:1.08680	valid-rmse:1.09031
[500]	train-rmse:1.06831	valid-rmse:1.07241
[600]	train-rmse:1.07143	valid-rmse:1.07542
[520]	train-rmse:1.07104	valid-rmse:1.07501
[40]	train-rmse:1.09417	valid-rmse:1.09748
[180]	train-rmse:1.08537	valid-rmse:1.08893
[580]	train-rmse:1.08082	valid-rmse:1.08452
[520]	train-rmse:1.06728	valid-rmse:1.07141
[620]	train-rmse:1.07065	valid-rmse:1.07466
[540]	train-rmse:1.07012	valid-rmse:1.07412
[60]	train-rmse:1.09186	valid-rmse:1.09524
[200]	train-rmse:1.08397	valid-rmse:1.08756
[600]	train-rmse:1.08025	valid-rmse:1.08396
[540]	train-rmse:1.06627	valid-rmse:1.07042
[640]	train-rmse:1.06986	valid-rmse:1.07390
[560]	train-rmse:1.06921	valid-rmse:1.07323
[80]	train-rmse:1.08961	valid-rmse:1.09305
[220]	train-rmse:1.08258	valid-rmse:1.08621
[620]	train-rmse:1.07968	valid-rmse:1.08341
[560]	train-rmse:1.06526	valid-rmse:1.06945
[660]	train-rmse:1.06909	valid-rmse:1.07315
[580]	train-rmse:1.06831	valid-rmse:1.07236
[100]	train-rmse:1.08740	valid-rmse:1.09090
[240]	train-rmse:1.08122	valid-rmse:1.08489
[640]	train-rmse:1.07912	valid-rmse:1.08287
[580]	train-rmse:1.06427	valid-rmse:1.06849
[680]	train-rmse:1.06832	valid-rmse:1.07241
[600]	train-rmse:1.06742	valid-rmse:1.07150
[120]	train-rmse:1.08524	valid-rmse:1.08880
[260]	train-rmse:1.07987	valid-rmse:1.08358
[660]	train-rmse:1.07855	valid-rmse:1.08232
[600]	train-rmse:1.06329	valid-rmse:1.06754
[700]	train-rmse:1.06756	valid-rmse:1.07168
[620]	train-rmse:1.06654	valid-rmse:1.07065
[140]	train-rmse:1.08312	valid-rmse:1.08675
[280]	train-rmse:1.07854	valid-rmse:1.08229
[680]	train-rmse:1.07800	valid-rmse:1.08178
[640]	train-rmse:1.06567	valid-rmse:1.06981
[620]	train-rmse:1.06233	valid-rmse:1.06661
[720]	train-rmse:1.06681	valid-rmse:1.07095
[300]	train-rmse:1.07724	valid-rmse:1.08102
[160]	train-rmse:1.08105	valid-rmse:1.08474
[660]	train-rmse:1.06481	valid-rmse:1.06897
[700]	train-rmse:1.07744	valid-rmse:1.08125
[640]	train-rmse:1.06138	valid-rmse:1.06569
[740]	train-rmse:1.06607	valid-rmse:1.07023
[320]	train-rmse:1.07595	valid-rmse:1.07977
[180]	train-rmse:1.07903	valid-rmse:1.08278
[680]	train-rmse:1.06396	valid-rmse:1.06815
[720]	train-rmse:1.07689	valid-rmse:1.08071
[660]	train-rmse:1.06044	valid-rmse:1.06478
[760]	train-rmse:1.06533	valid-rmse:1.06951
[340]	train-rmse:1.07468	valid-rmse:1.07855
[200]	train-rmse:1.07705	valid-rmse:1.08086
[700]	train-rmse:1.06312	valid-rmse:1.06734
[740]	train-rmse:1.07635	valid-rmse:1.08018
[680]	train-rmse:1.05951	valid-rmse:1.06389
[780]	train-rmse:1.06460	valid-rmse:1.06881
[360]	train-rmse:1.07343	valid-rmse:1.07733
[220]	train-rmse:1.07512	valid-rmse:1.07898
[720]	train-rmse:1.06229	valid-rmse:1.06653
[760]	train-rmse:1.07580	valid-rmse:1.07966
[700]	train-rmse:1.05859	valid-rmse:1.06300
[800]	train-rmse:1.06387	valid-rmse:1.06811
[380]	train-rmse:1.07220	valid-rmse:1.07614
[240]	train-rmse:1.07323	valid-rmse:1.07715
[740]	train-rmse:1.06147	valid-rmse:1.06574
[780]	train-rmse:1.07526	valid-rmse:1.07913
[720]	train-rmse:1.05769	valid-rmse:1.06213
[820]	train-rmse:1.06316	valid-rmse:1.06742
[400]	train-rmse:1.07098	valid-rmse:1.07496
[260]	train-rmse:1.07138	valid-rmse:1.07536
[760]	train-rmse:1.06066	valid-rmse:1.06495
[800]	train-rmse:1.07472	valid-rmse:1.07861
[740]	train-rmse:1.05680	valid-rmse:1.06127
[840]	train-rmse:1.06245	valid-rmse:1.06673
[420]	train-rmse:1.06979	valid-rmse:1.07380
[280]	train-rmse:1.06957	valid-rmse:1.07360
[780]	train-rmse:1.05986	valid-rmse:1.06418
[820]	train-rmse:1.07419	valid-rmse:1.07810
[760]	train-rmse:1.05592	valid-rmse:1.06042
[440]	train-rmse:1.06861	valid-rmse:1.07266
[860]	train-rmse:1.06175	valid-rmse:1.06605
[300]	train-rmse:1.06780	valid-rmse:1.07189
[800]	train-rmse:1.05906	valid-rmse:1.06341
[840]	train-rmse:1.07366	valid-rmse:1.07758
[780]	train-rmse:1.05505	valid-rmse:1.05959
[460]	train-rmse:1.06745	valid-rmse:1.07154
[880]	train-rmse:1.06105	valid-rmse:1.06538
[320]	train-rmse:1.06607	valid-rmse:1.07021
[820]	train-rmse:1.05828	valid-rmse:1.06265
[860]	train-rmse:1.07313	valid-rmse:1.07707
[480]	train-rmse:1.06631	valid-rmse:1.07043
[800]	train-rmse:1.05419	valid-rmse:1.05876
[840]	train-rmse:1.05750	valid-rmse:1.06190
[340]	train-rmse:1.06438	valid-rmse:1.06858
[900]	train-rmse:1.06036	valid-rmse:1.06471
[500]	train-rmse:1.06518	valid-rmse:1.06934
[880]	train-rmse:1.07261	valid-rmse:1.07656
[820]	train-rmse:1.05335	valid-rmse:1.05794
[860]	train-rmse:1.05673	valid-rmse:1.06116
[360]	train-rmse:1.06273	valid-rmse:1.06698
[920]	train-rmse:1.05968	valid-rmse:1.06405
[520]	train-rmse:1.06407	valid-rmse:1.06826
[880]	train-rmse:1.05598	valid-rmse:1.06043
[900]	train-rmse:1.07209	valid-rmse:1.07606
[840]	train-rmse:1.05252	valid-rmse:1.05714
[380]	train-rmse:1.06111	valid-rmse:1.06542
[940]	train-rmse:1.05900	valid-rmse:1.06340
[540]	train-rmse:1.06297	valid-rmse:1.06720
[900]	train-rmse:1.05523	valid-rmse:1.05970
[860]	train-rmse:1.05169	valid-rmse:1.05635
[920]	train-rmse:1.07157	valid-rmse:1.07556
[400]	train-rmse:1.05953	valid-rmse:1.06388
[960]	train-rmse:1.05833	valid-rmse:1.06276
[560]	train-rmse:1.06189	valid-rmse:1.06616
[920]	train-rmse:1.05449	valid-rmse:1.05899
[880]	train-rmse:1.05088	valid-rmse:1.05556
[420]	train-rmse:1.05798	valid-rmse:1.06239
[940]	train-rmse:1.07106	valid-rmse:1.07506
[980]	train-rmse:1.05767	valid-rmse:1.06212
[580]	train-rmse:1.06083	valid-rmse:1.06513
[940]	train-rmse:1.05375	valid-rmse:1.05828
[440]	train-rmse:1.05647	valid-rmse:1.06093
[960]	train-rmse:1.07055	valid-rmse:1.07457
[900]	train-rmse:1.05008	valid-rmse:1.05479
[999]	train-rmse:1.05705	valid-rmse:1.06151
[32m[I 2022-04-16 22:37:40,471][0m Trial 34 finished with value: 1.061514 and parameters: {'colsample_bytree': 0.665449426698277, 'eta': 0.00026724412504011095, 'max_depth': 5, 'n_estimators': 873, 'subsample': 0.9003075874101443}. Best is trial 27 with value: 0.998512.[0m
[22:37:44] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09885	valid-rmse:1.10204
[600]	train-rmse:1.05978	valid-rmse:1.06412
[960]	train-rmse:1.05303	valid-rmse:1.05758
[460]	train-rmse:1.05499	valid-rmse:1.05951
[980]	train-rmse:1.07004	valid-rmse:1.07407
[920]	train-rmse:1.04929	valid-rmse:1.05403
[620]	train-rmse:1.05875	valid-rmse:1.06312
[980]	train-rmse:1.05231	valid-rmse:1.05689
[20]	train-rmse:1.09474	valid-rmse:1.09804
[480]	train-rmse:1.05354	valid-rmse:1.05811
[999]	train-rmse:1.06956	valid-rmse:1.07361
[32m[I 2022-04-16 22:40:00,219][0m Trial 35 finished with value: 1.073612 and parameters: {'colsample_bytree': 0.6650008028392935, 'eta': 0.00017334436246057916, 'max_depth': 5, 'n_estimators': 590, 'subsample': 0.8964978849851393}. Best is trial 27 with value: 0.998512.[0m
[940]	train-rmse:1.04851	valid-rmse:1.05328
[22:40:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09890	valid-rmse:1.10208
[999]	train-rmse:1.05164	valid-rmse:1.05624
[32m[I 2022-04-16 22:40:39,856][0m Trial 37 finished with value: 1.056242 and parameters: {'colsample_bytree': 0.6666263673539587, 'eta': 0.0003137423870757157, 'max_depth': 5, 'n_estimators': 674, 'subsample': 0.7469455893455501}. Best is trial 27 with value: 0.998512.[0m
[640]	train-rmse:1.05774	valid-rmse:1.06214
[22:40:44] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08834	valid-rmse:1.09156
[40]	train-rmse:1.09078	valid-rmse:1.09419
[500]	train-rmse:1.05213	valid-rmse:1.05675
[20]	train-rmse:1.00559	valid-rmse:1.00894
[960]	train-rmse:1.04773	valid-rmse:1.05254
[20]	train-rmse:1.09573	valid-rmse:1.09900
[40]	train-rmse:0.99616	valid-rmse:0.99988
[660]	train-rmse:1.05673	valid-rmse:1.06117
[60]	train-rmse:0.99424	valid-rmse:0.99875
[520]	train-rmse:1.05074	valid-rmse:1.05541
[60]	train-rmse:1.08697	valid-rmse:1.09048
[980]	train-rmse:1.04697	valid-rmse:1.05181
[80]	train-rmse:0.99310	valid-rmse:0.99872
[100]	train-rmse:0.99212	valid-rmse:0.99867
[680]	train-rmse:1.05575	valid-rmse:1.06022
[40]	train-rmse:1.09264	valid-rmse:1.09600
[540]	train-rmse:1.04939	valid-rmse:1.05411
[120]	train-rmse:0.99117	valid-rmse:0.99869
[999]	train-rmse:1.04626	valid-rmse:1.05112
[80]	train-rmse:1.08330	valid-rmse:1.08692
[32m[I 2022-04-16 22:44:08,761][0m Trial 36 finished with value: 1.05112 and parameters: {'colsample_bytree': 0.6608979649945679, 'eta': 0.00036335222243820593, 'max_depth': 5, 'n_estimators': 655, 'subsample': 0.9033326607318988}. Best is trial 27 with value: 0.998512.[0m
[22:44:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08895	valid-rmse:1.09218
[140]	train-rmse:0.99017	valid-rmse:0.99881
[145]	train-rmse:0.98994	valid-rmse:0.99886
[32m[I 2022-04-16 22:44:30,472][0m Trial 42 finished with value: 0.998657 and parameters: {'colsample_bytree': 0.39968414478764347, 'eta': 0.05701272587693836, 'max_depth': 3, 'n_estimators': 997, 'subsample': 0.7675216972194221}. Best is trial 27 with value: 0.998512.[0m
[22:44:34] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[700]	train-rmse:1.05478	valid-rmse:1.05928
[0]	train-rmse:1.09887	valid-rmse:1.10205
[60]	train-rmse:1.08964	valid-rmse:1.09308
[560]	train-rmse:1.04806	valid-rmse:1.05283
[20]	train-rmse:1.00719	valid-rmse:1.01057
[100]	train-rmse:1.07977	valid-rmse:1.08349
[20]	train-rmse:1.09512	valid-rmse:1.09832
[720]	train-rmse:1.05382	valid-rmse:1.05835
[580]	train-rmse:1.04677	valid-rmse:1.05159
[40]	train-rmse:0.99663	valid-rmse:1.00025
[80]	train-rmse:1.08673	valid-rmse:1.09025
[40]	train-rmse:1.09150	valid-rmse:1.09472
[740]	train-rmse:1.05288	valid-rmse:1.05744
[120]	train-rmse:1.07637	valid-rmse:1.08019
[60]	train-rmse:0.99462	valid-rmse:0.99883
[600]	train-rmse:1.04551	valid-rmse:1.05037
[60]	train-rmse:1.08801	valid-rmse:1.09125
[100]	train-rmse:1.08391	valid-rmse:1.08751
[760]	train-rmse:1.05195	valid-rmse:1.05655
[80]	train-rmse:0.99348	valid-rmse:0.99858
[140]	train-rmse:1.07309	valid-rmse:1.07702
[620]	train-rmse:1.04428	valid-rmse:1.04918
[80]	train-rmse:1.08464	valid-rmse:1.08790
[780]	train-rmse:1.05104	valid-rmse:1.05567
[100]	train-rmse:0.99259	valid-rmse:0.99857
[120]	train-rmse:1.08116	valid-rmse:1.08485
[640]	train-rmse:1.04306	valid-rmse:1.04802
[100]	train-rmse:1.08139	valid-rmse:1.08467
[160]	train-rmse:1.06994	valid-rmse:1.07397
[120]	train-rmse:0.99167	valid-rmse:0.99855
[800]	train-rmse:1.05014	valid-rmse:1.05480
[120]	train-rmse:1.07825	valid-rmse:1.08155
[140]	train-rmse:1.07849	valid-rmse:1.08226
[660]	train-rmse:1.04188	valid-rmse:1.04689
[180]	train-rmse:1.06690	valid-rmse:1.07102
[140]	train-rmse:0.99078	valid-rmse:0.99855
[820]	train-rmse:1.04925	valid-rmse:1.05394
[140]	train-rmse:1.07523	valid-rmse:1.07854
[680]	train-rmse:1.04073	valid-rmse:1.04578
[160]	train-rmse:1.07590	valid-rmse:1.07974
[160]	train-rmse:0.98987	valid-rmse:0.99853
[200]	train-rmse:1.06398	valid-rmse:1.06820
[840]	train-rmse:1.04837	valid-rmse:1.05310
[160]	train-rmse:1.07232	valid-rmse:1.07564
[700]	train-rmse:1.03960	valid-rmse:1.04469
[180]	train-rmse:0.98909	valid-rmse:0.99852
[180]	train-rmse:1.07339	valid-rmse:1.07730
[180]	train-rmse:1.06951	valid-rmse:1.07285
[860]	train-rmse:1.04751	valid-rmse:1.05227
[220]	train-rmse:1.06118	valid-rmse:1.06549
[720]	train-rmse:1.03850	valid-rmse:1.04363
[200]	train-rmse:0.98835	valid-rmse:0.99857
[200]	train-rmse:1.06681	valid-rmse:1.07015
[880]	train-rmse:1.04666	valid-rmse:1.05145
[200]	train-rmse:1.07094	valid-rmse:1.07494
[220]	train-rmse:0.98746	valid-rmse:0.99859
[32m[I 2022-04-16 22:56:40,459][0m Trial 43 finished with value: 0.998511 and parameters: {'colsample_bytree': 0.8809408925650273, 'eta': 0.05321100281739171, 'max_depth': 3, 'n_estimators': 979, 'subsample': 0.9970667695259599}. Best is trial 43 with value: 0.998511.[0m
[240]	train-rmse:1.05848	valid-rmse:1.06287
[22:56:44] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[740]	train-rmse:1.03742	valid-rmse:1.04260
[0]	train-rmse:1.09889	valid-rmse:1.10206
[220]	train-rmse:1.06420	valid-rmse:1.06755
[900]	train-rmse:1.04582	valid-rmse:1.05064
[20]	train-rmse:1.09540	valid-rmse:1.09860
[220]	train-rmse:1.06857	valid-rmse:1.07264
[760]	train-rmse:1.03636	valid-rmse:1.04159
[260]	train-rmse:1.05588	valid-rmse:1.06036
[240]	train-rmse:1.06168	valid-rmse:1.06504
[920]	train-rmse:1.04500	valid-rmse:1.04985
[40]	train-rmse:1.09203	valid-rmse:1.09525
[780]	train-rmse:1.03533	valid-rmse:1.04061
[260]	train-rmse:1.05926	valid-rmse:1.06263
[240]	train-rmse:1.06628	valid-rmse:1.07041
[280]	train-rmse:1.05337	valid-rmse:1.05794
[60]	train-rmse:1.08876	valid-rmse:1.09200
[940]	train-rmse:1.04418	valid-rmse:1.04907
[280]	train-rmse:1.05692	valid-rmse:1.06029
[800]	train-rmse:1.03433	valid-rmse:1.03964
[260]	train-rmse:1.06404	valid-rmse:1.06825
[80]	train-rmse:1.08561	valid-rmse:1.08887
[300]	train-rmse:1.05097	valid-rmse:1.05562
[960]	train-rmse:1.04338	valid-rmse:1.04830
[300]	train-rmse:1.05466	valid-rmse:1.05805
[820]	train-rmse:1.03334	valid-rmse:1.03870
[100]	train-rmse:1.08256	valid-rmse:1.08583
[980]	train-rmse:1.04260	valid-rmse:1.04754
[280]	train-rmse:1.06187	valid-rmse:1.06615
[320]	train-rmse:1.05249	valid-rmse:1.05588
[320]	train-rmse:1.04865	valid-rmse:1.05339
[840]	train-rmse:1.03237	valid-rmse:1.03778
[120]	train-rmse:1.07961	valid-rmse:1.08290
[999]	train-rmse:1.04186	valid-rmse:1.04683
[340]	train-rmse:1.05040	valid-rmse:1.05380
[32m[I 2022-04-16 23:04:03,289][0m Trial 38 finished with value: 1.046834 and parameters: {'colsample_bytree': 0.6845192632880855, 'eta': 0.00040855585611244597, 'max_depth': 5, 'n_estimators': 670, 'subsample': 0.7490749132250081}. Best is trial 43 with value: 0.998511.[0m
[23:04:07] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08127	valid-rmse:1.08454
[300]	train-rmse:1.05977	valid-rmse:1.06412
[340]	train-rmse:1.04643	valid-rmse:1.05125
[860]	train-rmse:1.03143	valid-rmse:1.03688
[140]	train-rmse:1.07676	valid-rmse:1.08006
[360]	train-rmse:1.04838	valid-rmse:1.05179
[20]	train-rmse:0.99717	valid-rmse:1.00070
[160]	train-rmse:1.07400	valid-rmse:1.07732
[880]	train-rmse:1.03050	valid-rmse:1.03601
[320]	train-rmse:1.05772	valid-rmse:1.06214
[360]	train-rmse:1.04429	valid-rmse:1.04919
[380]	train-rmse:1.04644	valid-rmse:1.04985
[40]	train-rmse:0.99374	valid-rmse:0.99856
[180]	train-rmse:1.07134	valid-rmse:1.07467
[900]	train-rmse:1.02961	valid-rmse:1.03515
[400]	train-rmse:1.04457	valid-rmse:1.04798
[60]	train-rmse:0.99203	valid-rmse:0.99848
[340]	train-rmse:1.05573	valid-rmse:1.06022
[380]	train-rmse:1.04223	valid-rmse:1.04721
[200]	train-rmse:1.06876	valid-rmse:1.07210
[920]	train-rmse:1.02873	valid-rmse:1.03431
[420]	train-rmse:1.04276	valid-rmse:1.04618
[80]	train-rmse:0.99049	valid-rmse:0.99858
[220]	train-rmse:1.06627	valid-rmse:1.06962
[400]	train-rmse:1.04024	valid-rmse:1.04530
[360]	train-rmse:1.05380	valid-rmse:1.05837
[940]	train-rmse:1.02786	valid-rmse:1.03349
[440]	train-rmse:1.04103	valid-rmse:1.04445
[99]	train-rmse:0.98894	valid-rmse:0.99865
[32m[I 2022-04-16 23:09:52,613][0m Trial 46 finished with value: 0.998462 and parameters: {'colsample_bytree': 0.8794929473455162, 'eta': 0.09531313141434856, 'max_depth': 3, 'n_estimators': 947, 'subsample': 0.9961726159296795}. Best is trial 46 with value: 0.998462.[0m
[23:09:56] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.06765	valid-rmse:1.07097
[240]	train-rmse:1.06386	valid-rmse:1.06722
[420]	train-rmse:1.03833	valid-rmse:1.04347
[380]	train-rmse:1.05194	valid-rmse:1.05657
[460]	train-rmse:1.03935	valid-rmse:1.04278
[960]	train-rmse:1.02702	valid-rmse:1.03269
[20]	train-rmse:0.99412	valid-rmse:0.99870
[260]	train-rmse:1.06154	valid-rmse:1.06491
[480]	train-rmse:1.03774	valid-rmse:1.04117
[40]	train-rmse:0.99119	valid-rmse:0.99863
[980]	train-rmse:1.02620	valid-rmse:1.03191
[440]	train-rmse:1.03649	valid-rmse:1.04171
[400]	train-rmse:1.05011	valid-rmse:1.05481
[280]	train-rmse:1.05929	valid-rmse:1.06267
[500]	train-rmse:1.03618	valid-rmse:1.03961
[60]	train-rmse:0.98840	valid-rmse:0.99885
[300]	train-rmse:1.05712	valid-rmse:1.06050
[999]	train-rmse:1.02544	valid-rmse:1.03119
[32m[I 2022-04-16 23:13:36,010][0m Trial 39 finished with value: 1.031187 and parameters: {'colsample_bytree': 0.6794677256590659, 'eta': 0.0006171577890169127, 'max_depth': 5, 'n_estimators': 667, 'subsample': 0.7831939952944096}. Best is trial 46 with value: 0.998462.[0m
[23:13:40] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.05567	valid-rmse:1.05900
[460]	train-rmse:1.03473	valid-rmse:1.04002
[420]	train-rmse:1.04835	valid-rmse:1.05312
[520]	train-rmse:1.03469	valid-rmse:1.03812
[77]	train-rmse:0.98611	valid-rmse:0.99910
[32m[I 2022-04-16 23:14:22,865][0m Trial 47 finished with value: 0.998568 and parameters: {'colsample_bytree': 0.8829706666364441, 'eta': 0.17450735030003925, 'max_depth': 3, 'n_estimators': 934, 'subsample': 0.9818938872907593}. Best is trial 46 with value: 0.998462.[0m
[23:14:27] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09021	valid-rmse:1.09344
[320]	train-rmse:1.05502	valid-rmse:1.05841
[20]	train-rmse:0.99274	valid-rmse:0.99840
[540]	train-rmse:1.03324	valid-rmse:1.03668
[480]	train-rmse:1.03303	valid-rmse:1.03840
[440]	train-rmse:1.04664	valid-rmse:1.05147
[20]	train-rmse:1.01103	valid-rmse:1.01440
[340]	train-rmse:1.05299	valid-rmse:1.05639
[40]	train-rmse:0.98862	valid-rmse:0.99890
[560]	train-rmse:1.03185	valid-rmse:1.03529
[40]	train-rmse:0.99782	valid-rmse:1.00136
[360]	train-rmse:1.05103	valid-rmse:1.05443
[500]	train-rmse:1.03140	valid-rmse:1.03684
[460]	train-rmse:1.04498	valid-rmse:1.04987
[60]	train-rmse:0.98504	valid-rmse:0.99930
[580]	train-rmse:1.03051	valid-rmse:1.03395
[70]	train-rmse:0.98312	valid-rmse:0.99932
[32m[I 2022-04-16 23:17:46,157][0m Trial 48 finished with value: 0.998395 and parameters: {'colsample_bytree': 0.8867850872013032, 'eta': 0.2500144601124373, 'max_depth': 3, 'n_estimators': 950, 'subsample': 0.9950878624420878}. Best is trial 48 with value: 0.998395.[0m
[23:17:50] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[380]	train-rmse:1.04913	valid-rmse:1.05254
[60]	train-rmse:0.99514	valid-rmse:0.99908
[0]	train-rmse:1.03674	valid-rmse:1.04002
[520]	train-rmse:1.02982	valid-rmse:1.03534
[480]	train-rmse:1.04337	valid-rmse:1.04832
[600]	train-rmse:1.02922	valid-rmse:1.03266
[400]	train-rmse:1.04730	valid-rmse:1.05072
[80]	train-rmse:0.99399	valid-rmse:0.99860
[20]	train-rmse:0.99067	valid-rmse:0.99886
[620]	train-rmse:1.02798	valid-rmse:1.03142
[420]	train-rmse:1.04553	valid-rmse:1.04895
[540]	train-rmse:1.02831	valid-rmse:1.03389
[100]	train-rmse:0.99315	valid-rmse:0.99855
[40]	train-rmse:0.98467	valid-rmse:0.99944
[500]	train-rmse:1.04181	valid-rmse:1.04681
[640]	train-rmse:1.02678	valid-rmse:1.03023
[440]	train-rmse:1.04382	valid-rmse:1.04725
[120]	train-rmse:0.99231	valid-rmse:0.99846
[60]	train-rmse:0.97894	valid-rmse:1.00034
[560]	train-rmse:1.02685	valid-rmse:1.03251
[65]	train-rmse:0.97761	valid-rmse:1.00046
[32m[I 2022-04-16 23:21:50,131][0m Trial 50 finished with value: 0.998687 and parameters: {'colsample_bytree': 0.9210544104968224, 'eta': 0.3859817196541734, 'max_depth': 3, 'n_estimators': 946, 'subsample': 0.9984160906100953}. Best is trial 48 with value: 0.998395.[0m
[520]	train-rmse:1.04028	valid-rmse:1.04535
[23:21:54] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08504	valid-rmse:1.08909
[660]	train-rmse:1.02563	valid-rmse:1.02907
[460]	train-rmse:1.04217	valid-rmse:1.04560
[140]	train-rmse:0.99151	valid-rmse:0.99843
[580]	train-rmse:1.02545	valid-rmse:1.03118
[680]	train-rmse:1.02452	valid-rmse:1.02796
[480]	train-rmse:1.04058	valid-rmse:1.04401
[540]	train-rmse:1.03880	valid-rmse:1.04394
[160]	train-rmse:0.99075	valid-rmse:0.99843
[20]	train-rmse:0.98695	valid-rmse:1.00500
[500]	train-rmse:1.03904	valid-rmse:1.04247
[700]	train-rmse:1.02345	valid-rmse:1.02689
[180]	train-rmse:0.99009	valid-rmse:0.99842
[600]	train-rmse:1.02410	valid-rmse:1.02991
[560]	train-rmse:1.03737	valid-rmse:1.04256
[520]	train-rmse:1.03755	valid-rmse:1.04099
[720]	train-rmse:1.02242	valid-rmse:1.02586
[200]	train-rmse:0.98933	valid-rmse:0.99848
[620]	train-rmse:1.02280	valid-rmse:1.02868
[40]	train-rmse:0.97047	valid-rmse:0.99999
[540]	train-rmse:1.03611	valid-rmse:1.03955
[580]	train-rmse:1.03598	valid-rmse:1.04123
[740]	train-rmse:1.02143	valid-rmse:1.02487
[220]	train-rmse:0.98859	valid-rmse:0.99850
[224]	train-rmse:0.98844	valid-rmse:0.99852
[32m[I 2022-04-16 23:27:27,515][0m Trial 49 finished with value: 0.998417 and parameters: {'colsample_bytree': 0.8892584954252539, 'eta': 0.04645436126967898, 'max_depth': 3, 'n_estimators': 944, 'subsample': 0.9963794345553297}. Best is trial 48 with value: 0.998395.[0m
[23:27:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08882	valid-rmse:1.09209
[560]	train-rmse:1.03472	valid-rmse:1.03817
[760]	train-rmse:1.02047	valid-rmse:1.02391
[640]	train-rmse:1.02155	valid-rmse:1.02750
[600]	train-rmse:1.03463	valid-rmse:1.03995
[20]	train-rmse:1.00674	valid-rmse:1.01027
[60]	train-rmse:0.96029	valid-rmse:1.00000
[580]	train-rmse:1.03338	valid-rmse:1.03683
[780]	train-rmse:1.01955	valid-rmse:1.02299
[40]	train-rmse:0.99636	valid-rmse:1.00027
[660]	train-rmse:1.02035	valid-rmse:1.02637
[620]	train-rmse:1.03332	valid-rmse:1.03870
[600]	train-rmse:1.03208	valid-rmse:1.03553
[800]	train-rmse:1.01867	valid-rmse:1.02210
[60]	train-rmse:0.99433	valid-rmse:0.99888
[620]	train-rmse:1.03083	valid-rmse:1.03428
[80]	train-rmse:0.94897	valid-rmse:1.00048
[680]	train-rmse:1.01920	valid-rmse:1.02529
[820]	train-rmse:1.01781	valid-rmse:1.02125
[640]	train-rmse:1.03205	valid-rmse:1.03749
[80]	train-rmse:0.99317	valid-rmse:0.99870
[640]	train-rmse:1.02962	valid-rmse:1.03307
[840]	train-rmse:1.01699	valid-rmse:1.02042
[100]	train-rmse:0.99213	valid-rmse:0.99865
[700]	train-rmse:1.01809	valid-rmse:1.02424
[660]	train-rmse:1.03081	valid-rmse:1.03631
[660]	train-rmse:1.02845	valid-rmse:1.03191
[100]	train-rmse:0.93926	valid-rmse:1.00105
[32m[I 2022-04-16 23:33:23,600][0m Trial 51 finished with value: 0.999715 and parameters: {'colsample_bytree': 0.8453404129189962, 'eta': 0.07092634300744693, 'max_depth': 7, 'n_estimators': 810, 'subsample': 0.6991899025339869}. Best is trial 48 with value: 0.998395.[0m
[23:33:27] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[120]	train-rmse:0.99114	valid-rmse:0.99867
[860]	train-rmse:1.01620	valid-rmse:1.01963
[0]	train-rmse:1.02399	valid-rmse:1.02722
[680]	train-rmse:1.02732	valid-rmse:1.03078
[720]	train-rmse:1.01703	valid-rmse:1.02324
[140]	train-rmse:0.99012	valid-rmse:0.99866
[680]	train-rmse:1.02962	valid-rmse:1.03517
[20]	train-rmse:0.98948	valid-rmse:1.00004
[880]	train-rmse:1.01544	valid-rmse:1.01886
[700]	train-rmse:1.02623	valid-rmse:1.02969
[160]	train-rmse:0.98925	valid-rmse:0.99875
[40]	train-rmse:0.98252	valid-rmse:1.00179
[900]	train-rmse:1.01470	valid-rmse:1.01813
[740]	train-rmse:1.01599	valid-rmse:1.02228
[700]	train-rmse:1.02846	valid-rmse:1.03407
[178]	train-rmse:0.98850	valid-rmse:0.99878
[32m[I 2022-04-16 23:36:28,534][0m Trial 52 finished with value: 0.998631 and parameters: {'colsample_bytree': 0.8213800844377193, 'eta': 0.054121145946474214, 'max_depth': 3, 'n_estimators': 798, 'subsample': 0.8657874989057002}. Best is trial 48 with value: 0.998395.[0m
[720]	train-rmse:1.02518	valid-rmse:1.02864
[55]	train-rmse:0.97784	valid-rmse:1.00264
[32m[I 2022-04-16 23:36:30,858][0m Trial 53 finished with value: 0.998856 and parameters: {'colsample_bytree': 0.8960564644157953, 'eta': 0.49728583577984997, 'max_depth': 3, 'n_estimators': 1020, 'subsample': 0.8616239122510136}. Best is trial 48 with value: 0.998395.[0m
[23:36:32] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[23:36:34] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.03012	valid-rmse:1.03353
[0]	train-rmse:1.06790	valid-rmse:1.07129
[920]	train-rmse:1.01399	valid-rmse:1.01742
[760]	train-rmse:1.01500	valid-rmse:1.02136
[740]	train-rmse:1.02416	valid-rmse:1.02762
[720]	train-rmse:1.02733	valid-rmse:1.03300
[20]	train-rmse:0.99396	valid-rmse:0.99863
[20]	train-rmse:0.98986	valid-rmse:0.99962
[940]	train-rmse:1.01331	valid-rmse:1.01674
[760]	train-rmse:1.02318	valid-rmse:1.02664
[40]	train-rmse:0.99088	valid-rmse:0.99855
[40]	train-rmse:0.98347	valid-rmse:1.00081
[780]	train-rmse:1.01405	valid-rmse:1.02047
[960]	train-rmse:1.01266	valid-rmse:1.01608
[740]	train-rmse:1.02623	valid-rmse:1.03196
[780]	train-rmse:1.02223	valid-rmse:1.02569
[57]	train-rmse:0.97876	valid-rmse:1.00148
[32m[I 2022-04-16 23:39:51,673][0m Trial 54 finished with value: 0.998886 and parameters: {'colsample_bytree': 0.8979154403345504, 'eta': 0.44102667078208013, 'max_depth': 3, 'n_estimators': 939, 'subsample': 0.9393184173454714}. Best is trial 48 with value: 0.998395.[0m
[23:39:55] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:0.98794	valid-rmse:0.99881
[0]	train-rmse:1.06612	valid-rmse:1.07350
[980]	train-rmse:1.01202	valid-rmse:1.01544
[800]	train-rmse:1.01313	valid-rmse:1.01962
[800]	train-rmse:1.02132	valid-rmse:1.02477
[760]	train-rmse:1.02517	valid-rmse:1.03095
[78]	train-rmse:0.98546	valid-rmse:0.99894
[32m[I 2022-04-16 23:40:56,565][0m Trial 55 finished with value: 0.998494 and parameters: {'colsample_bytree': 0.8765172699897716, 'eta': 0.1731435496300982, 'max_depth': 3, 'n_estimators': 946, 'subsample': 0.9381108824116203}. Best is trial 48 with value: 0.998395.[0m
[23:41:00] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.06509	valid-rmse:1.07138
[999]	train-rmse:1.01144	valid-rmse:1.01486
[32m[I 2022-04-16 23:41:20,454][0m Trial 44 finished with value: 1.014863 and parameters: {'colsample_bytree': 0.9106815978166233, 'eta': 0.0009842880844962516, 'max_depth': 3, 'n_estimators': 807, 'subsample': 0.9894904556092804}. Best is trial 48 with value: 0.998395.[0m
[23:41:24] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.07867	valid-rmse:1.08234
[820]	train-rmse:1.02044	valid-rmse:1.02389
[20]	train-rmse:0.99040	valid-rmse:0.99999
[820]	train-rmse:1.01225	valid-rmse:1.01880
[780]	train-rmse:1.02414	valid-rmse:1.02998
[20]	train-rmse:0.93733	valid-rmse:1.00202
[40]	train-rmse:0.98397	valid-rmse:0.99895
[840]	train-rmse:1.01958	valid-rmse:1.02304
[60]	train-rmse:0.97869	valid-rmse:0.99898
[840]	train-rmse:1.01139	valid-rmse:1.01802
[40]	train-rmse:0.89565	valid-rmse:1.00373
[800]	train-rmse:1.02314	valid-rmse:1.02903
[860]	train-rmse:1.01876	valid-rmse:1.02221
[20]	train-rmse:0.93406	valid-rmse:1.00101
[80]	train-rmse:0.97343	valid-rmse:0.99932
[95]	train-rmse:0.96944	valid-rmse:0.99955
[32m[I 2022-04-16 23:44:46,477][0m Trial 58 finished with value: 0.998836 and parameters: {'colsample_bytree': 0.23750433327098835, 'eta': 0.1081309748352032, 'max_depth': 5, 'n_estimators': 917, 'subsample': 0.9328017668459737}. Best is trial 48 with value: 0.998395.[0m
[23:44:50] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.05689	valid-rmse:1.06586
[60]	train-rmse:0.84917	valid-rmse:1.00714
[880]	train-rmse:1.01796	valid-rmse:1.02141
[860]	train-rmse:1.01058	valid-rmse:1.01726
[63]	train-rmse:0.84296	valid-rmse:1.00753
[32m[I 2022-04-16 23:45:31,689][0m Trial 57 finished with value: 1.001632 and parameters: {'colsample_bytree': 0.20148193459301933, 'eta': 0.17388914063470945, 'max_depth': 9, 'n_estimators': 912, 'subsample': 0.990357347782971}. Best is trial 48 with value: 0.998395.[0m
[820]	train-rmse:1.02216	valid-rmse:1.02811
[23:45:35] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:0.99880	valid-rmse:1.00309
[900]	train-rmse:1.01719	valid-rmse:1.02064
[880]	train-rmse:1.00978	valid-rmse:1.01654
[840]	train-rmse:1.02122	valid-rmse:1.02722
[20]	train-rmse:0.96403	valid-rmse:1.01281
[920]	train-rmse:1.01645	valid-rmse:1.01990
[40]	train-rmse:0.89491	valid-rmse:1.00345
[900]	train-rmse:1.00903	valid-rmse:1.01585
[940]	train-rmse:1.01573	valid-rmse:1.01918
[20]	train-rmse:0.92167	valid-rmse:1.00365
[860]	train-rmse:1.02030	valid-rmse:1.02636
[40]	train-rmse:0.93684	valid-rmse:1.02734
[960]	train-rmse:1.01503	valid-rmse:1.01849
[51]	train-rmse:0.92253	valid-rmse:1.03283
[32m[I 2022-04-16 23:50:02,061][0m Trial 60 finished with value: 1.000128 and parameters: {'colsample_bytree': 0.8570305244732782, 'eta': 0.8340207875035642, 'max_depth': 5, 'n_estimators': 983, 'subsample': 0.8025100024394023}. Best is trial 48 with value: 0.998395.[0m
[920]	train-rmse:1.00830	valid-rmse:1.01517
[23:50:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09387	valid-rmse:1.09710
[880]	train-rmse:1.01941	valid-rmse:1.02552
[980]	train-rmse:1.01437	valid-rmse:1.01781
[20]	train-rmse:1.03025	valid-rmse:1.03370
[940]	train-rmse:1.00759	valid-rmse:1.01453
[999]	train-rmse:1.01375	valid-rmse:1.01720
[32m[I 2022-04-16 23:51:50,801][0m Trial 45 finished with value: 1.017198 and parameters: {'colsample_bytree': 0.8856001334849892, 'eta': 0.0009132257372849462, 'max_depth': 3, 'n_estimators': 798, 'subsample': 0.9806160312533553}. Best is trial 48 with value: 0.998395.[0m
[23:51:55] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[900]	train-rmse:1.01855	valid-rmse:1.02472
[0]	train-rmse:1.09156	valid-rmse:1.09480
[40]	train-rmse:1.00771	valid-rmse:1.01117
[60]	train-rmse:0.83867	valid-rmse:1.00672
[40]	train-rmse:0.85314	valid-rmse:1.00984
[960]	train-rmse:1.00691	valid-rmse:1.01391
[60]	train-rmse:0.99972	valid-rmse:1.00317
[20]	train-rmse:1.01648	valid-rmse:1.02000
[920]	train-rmse:1.01771	valid-rmse:1.02393
[80]	train-rmse:0.99664	valid-rmse:1.00034
[40]	train-rmse:0.99994	valid-rmse:1.00349
[68]	train-rmse:0.81766	valid-rmse:1.00815
[32m[I 2022-04-16 23:54:25,507][0m Trial 56 finished with value: 1.000989 and parameters: {'colsample_bytree': 0.9407983810995589, 'eta': 0.16029855614444227, 'max_depth': 9, 'n_estimators': 970, 'subsample': 0.9917951203235962}. Best is trial 48 with value: 0.998395.[0m
[23:54:29] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09180	valid-rmse:1.09505
[980]	train-rmse:1.00626	valid-rmse:1.01333
[100]	train-rmse:0.99523	valid-rmse:0.99930
[940]	train-rmse:1.01689	valid-rmse:1.02317
[60]	train-rmse:0.99592	valid-rmse:0.99978
[20]	train-rmse:1.01765	valid-rmse:1.02106
[120]	train-rmse:0.99443	valid-rmse:0.99889
[999]	train-rmse:1.00565	valid-rmse:1.01279
[32m[I 2022-04-16 23:56:12,887][0m Trial 40 finished with value: 1.012785 and parameters: {'colsample_bytree': 0.8653862130040202, 'eta': 0.0010612800132725323, 'max_depth': 5, 'n_estimators': 679, 'subsample': 0.7604859897474605}. Best is trial 48 with value: 0.998395.[0m
[23:56:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09237	valid-rmse:1.09561
[60]	train-rmse:0.78699	valid-rmse:1.01507
[40]	train-rmse:1.00050	valid-rmse:1.00394
[80]	train-rmse:0.99446	valid-rmse:0.99890
[960]	train-rmse:1.01610	valid-rmse:1.02243
[62]	train-rmse:0.78220	valid-rmse:1.01542
[32m[I 2022-04-16 23:57:00,310][0m Trial 59 finished with value: 1.002138 and parameters: {'colsample_bytree': 0.8554345912210837, 'eta': 0.20923799846105093, 'max_depth': 9, 'n_estimators': 974, 'subsample': 0.9693938985334517}. Best is trial 48 with value: 0.998395.[0m
[23:57:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[140]	train-rmse:0.99380	valid-rmse:0.99869
[0]	train-rmse:1.09224	valid-rmse:1.09548
[20]	train-rmse:1.02057	valid-rmse:1.02399
[60]	train-rmse:0.99626	valid-rmse:0.99991
[100]	train-rmse:0.99353	valid-rmse:0.99867
[20]	train-rmse:1.01986	valid-rmse:1.02331
[160]	train-rmse:0.99323	valid-rmse:0.99861
[40]	train-rmse:1.00192	valid-rmse:1.00534
[980]	train-rmse:1.01533	valid-rmse:1.02171
[80]	train-rmse:0.99472	valid-rmse:0.99897
[120]	train-rmse:0.99273	valid-rmse:0.99861
[40]	train-rmse:1.00155	valid-rmse:1.00503
[180]	train-rmse:0.99278	valid-rmse:0.99861
[60]	train-rmse:0.99682	valid-rmse:1.00044
[100]	train-rmse:0.99379	valid-rmse:0.99868
[999]	train-rmse:1.01462	valid-rmse:1.02105
[32m[I 2022-04-16 23:59:56,142][0m Trial 41 finished with value: 1.021051 and parameters: {'colsample_bytree': 0.8878344344349395, 'eta': 0.0008157028030581259, 'max_depth': 5, 'n_estimators': 638, 'subsample': 0.7537800872104197}. Best is trial 48 with value: 0.998395.[0m
[00:00:00] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[140]	train-rmse:0.99204	valid-rmse:0.99857
[0]	train-rmse:1.09325	valid-rmse:1.09648
[60]	train-rmse:0.99664	valid-rmse:1.00038
[200]	train-rmse:0.99229	valid-rmse:0.99858
[80]	train-rmse:0.99501	valid-rmse:0.99914
[120]	train-rmse:0.99301	valid-rmse:0.99862
[20]	train-rmse:1.02584	valid-rmse:1.02934
[80]	train-rmse:0.99496	valid-rmse:0.99918
[220]	train-rmse:0.99186	valid-rmse:0.99857
[160]	train-rmse:0.99130	valid-rmse:0.99857
[100]	train-rmse:0.99405	valid-rmse:0.99871
[140]	train-rmse:0.99231	valid-rmse:0.99859
[40]	train-rmse:1.00488	valid-rmse:1.00833
[100]	train-rmse:0.99402	valid-rmse:0.99881
[240]	train-rmse:0.99140	valid-rmse:0.99859
[120]	train-rmse:0.99332	valid-rmse:0.99861
[180]	train-rmse:0.99056	valid-rmse:0.99855
[160]	train-rmse:0.99163	valid-rmse:0.99860
[60]	train-rmse:0.99821	valid-rmse:1.00175
[120]	train-rmse:0.99328	valid-rmse:0.99869
[260]	train-rmse:0.99096	valid-rmse:0.99859
[140]	train-rmse:0.99269	valid-rmse:0.99858
[199]	train-rmse:0.98995	valid-rmse:0.99856
[32m[I 2022-04-17 00:03:39,087][0m Trial 62 finished with value: 0.998549 and parameters: {'colsample_bytree': 0.9518672752666459, 'eta': 0.039267669160930566, 'max_depth': 3, 'n_estimators': 975, 'subsample': 0.9487118172128916}. Best is trial 48 with value: 0.998395.[0m
[00:03:43] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09336	valid-rmse:1.09657
[180]	train-rmse:0.99094	valid-rmse:0.99859
[80]	train-rmse:0.99585	valid-rmse:0.99964
[140]	train-rmse:0.99262	valid-rmse:0.99867
[280]	train-rmse:0.99055	valid-rmse:0.99858
[160]	train-rmse:0.99207	valid-rmse:0.99855
[20]	train-rmse:1.02626	valid-rmse:1.02961
[200]	train-rmse:0.99031	valid-rmse:0.99860
[40]	train-rmse:1.00518	valid-rmse:1.00857
[100]	train-rmse:0.99469	valid-rmse:0.99895
[160]	train-rmse:0.99194	valid-rmse:0.99867
[300]	train-rmse:0.99000	valid-rmse:0.99857
[180]	train-rmse:0.99143	valid-rmse:0.99853
[60]	train-rmse:0.99833	valid-rmse:1.00196
[215]	train-rmse:0.98992	valid-rmse:0.99860
[32m[I 2022-04-17 00:05:42,963][0m Trial 63 finished with value: 0.998574 and parameters: {'colsample_bytree': 0.8271773885353202, 'eta': 0.0379716112908236, 'max_depth': 3, 'n_estimators': 226, 'subsample': 0.9451287347359835}. Best is trial 48 with value: 0.998395.[0m
[00:05:47] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09301	valid-rmse:1.09623
[120]	train-rmse:0.99394	valid-rmse:0.99870
[180]	train-rmse:0.99131	valid-rmse:0.99864
[80]	train-rmse:0.99585	valid-rmse:0.99985
[320]	train-rmse:0.98956	valid-rmse:0.99858
[200]	train-rmse:0.99081	valid-rmse:0.99853
[20]	train-rmse:1.02397	valid-rmse:1.02743
[100]	train-rmse:0.99467	valid-rmse:0.99917
[140]	train-rmse:0.99337	valid-rmse:0.99861
[40]	train-rmse:1.00382	valid-rmse:1.00726
[200]	train-rmse:0.99073	valid-rmse:0.99864
[340]	train-rmse:0.98910	valid-rmse:0.99858
[120]	train-rmse:0.99394	valid-rmse:0.99892
[220]	train-rmse:0.99027	valid-rmse:0.99856
[32m[I 2022-04-17 00:07:25,036][0m Trial 61 finished with value: 0.998551 and parameters: {'colsample_bytree': 0.8022589527239297, 'eta': 0.027083031449867994, 'max_depth': 3, 'n_estimators': 963, 'subsample': 0.9545639070037685}. Best is trial 48 with value: 0.998395.[0m
[00:07:29] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09741	valid-rmse:1.10059
[60]	train-rmse:0.99776	valid-rmse:1.00132
[140]	train-rmse:0.99331	valid-rmse:0.99879
[160]	train-rmse:0.99278	valid-rmse:0.99857
[220]	train-rmse:0.99020	valid-rmse:0.99869
[20]	train-rmse:1.06898	valid-rmse:1.07230
[237]	train-rmse:0.98980	valid-rmse:0.99860
[32m[I 2022-04-17 00:08:14,689][0m Trial 64 finished with value: 0.998514 and parameters: {'colsample_bytree': 0.8017262703747159, 'eta': 0.0349865789840024, 'max_depth': 3, 'n_estimators': 294, 'subsample': 0.9439898472049784}. Best is trial 48 with value: 0.998395.[0m
[00:08:18] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:0.99557	valid-rmse:0.99956
[223]	train-rmse:0.99013	valid-rmse:0.99869
[32m[I 2022-04-17 00:08:23,090][0m Trial 65 finished with value: 0.998634 and parameters: {'colsample_bytree': 0.8004827460558204, 'eta': 0.03567260246835848, 'max_depth': 3, 'n_estimators': 286, 'subsample': 0.9416699879053905}. Best is trial 48 with value: 0.998395.[0m
[0]	train-rmse:1.09723	valid-rmse:1.10042
[00:08:27] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09728	valid-rmse:1.10048
[160]	train-rmse:0.99273	valid-rmse:0.99874
[40]	train-rmse:1.04838	valid-rmse:1.05181
[100]	train-rmse:0.99447	valid-rmse:0.99894
[180]	train-rmse:0.99224	valid-rmse:0.99856
[20]	train-rmse:1.06714	valid-rmse:1.07052
[180]	train-rmse:0.99220	valid-rmse:0.99879
[20]	train-rmse:1.06653	valid-rmse:1.06990
[60]	train-rmse:1.03354	valid-rmse:1.03698
[120]	train-rmse:0.99375	valid-rmse:0.99877
[40]	train-rmse:1.04584	valid-rmse:1.04929
[200]	train-rmse:0.99163	valid-rmse:0.99879
[200]	train-rmse:0.99169	valid-rmse:0.99854
[207]	train-rmse:0.99145	valid-rmse:0.99880
[80]	train-rmse:1.02284	valid-rmse:1.02628
[32m[I 2022-04-17 00:10:04,284][0m Trial 67 finished with value: 0.998731 and parameters: {'colsample_bytree': 0.8089280189785826, 'eta': 0.030114874704037797, 'max_depth': 3, 'n_estimators': 243, 'subsample': 0.3672328241961734}. Best is trial 48 with value: 0.998395.[0m
[40]	train-rmse:1.04498	valid-rmse:1.04843
[00:10:08] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.03083	valid-rmse:1.03432
[140]	train-rmse:0.99311	valid-rmse:0.99867
[0]	train-rmse:1.09763	valid-rmse:1.10082
[100]	train-rmse:1.01515	valid-rmse:1.01859
[80]	train-rmse:1.02030	valid-rmse:1.02377
[160]	train-rmse:0.99252	valid-rmse:0.99864
[60]	train-rmse:1.02992	valid-rmse:1.03339
[220]	train-rmse:0.99120	valid-rmse:0.99859
[20]	train-rmse:1.07262	valid-rmse:1.07595
[100]	train-rmse:1.01293	valid-rmse:1.01637
[120]	train-rmse:1.00960	valid-rmse:1.01306
[180]	train-rmse:0.99192	valid-rmse:0.99861
[120]	train-rmse:1.00772	valid-rmse:1.01118
[80]	train-rmse:1.01944	valid-rmse:1.02291
[140]	train-rmse:1.00560	valid-rmse:1.00907
[238]	train-rmse:0.99072	valid-rmse:0.99858
[32m[I 2022-04-17 00:12:00,150][0m Trial 66 finished with value: 0.998542 and parameters: {'colsample_bytree': 0.809502153799607, 'eta': 0.030356957139133604, 'max_depth': 3, 'n_estimators': 888, 'subsample': 0.929263778862042}. Best is trial 48 with value: 0.998395.[0m
[40]	train-rmse:1.05363	valid-rmse:1.05705
[00:12:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[200]	train-rmse:0.99130	valid-rmse:0.99856
[0]	train-rmse:1.09738	valid-rmse:1.10057
[140]	train-rmse:1.00406	valid-rmse:1.00752
[160]	train-rmse:1.00271	valid-rmse:1.00619
[100]	train-rmse:1.01217	valid-rmse:1.01562
[220]	train-rmse:0.99067	valid-rmse:0.99860
[60]	train-rmse:1.03926	valid-rmse:1.04272
[160]	train-rmse:1.00145	valid-rmse:1.00494
[20]	train-rmse:1.06880	valid-rmse:1.07215
[180]	train-rmse:1.00062	valid-rmse:1.00414
[240]	train-rmse:0.99011	valid-rmse:0.99864
[180]	train-rmse:0.99959	valid-rmse:1.00313
[120]	train-rmse:1.00709	valid-rmse:1.01054
[80]	train-rmse:1.02843	valid-rmse:1.03191
[200]	train-rmse:0.99908	valid-rmse:1.00266
[200]	train-rmse:0.99826	valid-rmse:1.00187
[260]	train-rmse:0.98953	valid-rmse:0.99867
[32m[I 2022-04-17 00:14:06,645][0m Trial 68 finished with value: 0.998544 and parameters: {'colsample_bytree': 0.7902667526895636, 'eta': 0.03199756204324764, 'max_depth': 3, 'n_estimators': 879, 'subsample': 0.40260570735112733}. Best is trial 48 with value: 0.998395.[0m
[00:14:10] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09744	valid-rmse:1.10063
[40]	train-rmse:1.04812	valid-rmse:1.05158
[220]	train-rmse:0.99791	valid-rmse:1.00159
[140]	train-rmse:1.00353	valid-rmse:1.00700
[220]	train-rmse:0.99727	valid-rmse:1.00098
[100]	train-rmse:1.02029	valid-rmse:1.02376
[240]	train-rmse:0.99705	valid-rmse:1.00081
[240]	train-rmse:0.99653	valid-rmse:1.00033
[20]	train-rmse:1.06966	valid-rmse:1.07302
[60]	train-rmse:1.03323	valid-rmse:1.03673
[160]	train-rmse:1.00101	valid-rmse:1.00451
[120]	train-rmse:1.01415	valid-rmse:1.01762
[260]	train-rmse:0.99638	valid-rmse:1.00025
[260]	train-rmse:0.99598	valid-rmse:0.99989
[180]	train-rmse:0.99922	valid-rmse:1.00279
[280]	train-rmse:0.99552	valid-rmse:0.99954
[280]	train-rmse:0.99586	valid-rmse:0.99983
[80]	train-rmse:1.02253	valid-rmse:1.02603
[40]	train-rmse:1.04933	valid-rmse:1.05278
[140]	train-rmse:1.00953	valid-rmse:1.01300
[300]	train-rmse:0.99515	valid-rmse:0.99932
[300]	train-rmse:0.99544	valid-rmse:0.99954
[200]	train-rmse:0.99794	valid-rmse:1.00158
[160]	train-rmse:1.00603	valid-rmse:1.00951
[320]	train-rmse:0.99482	valid-rmse:0.99915
[100]	train-rmse:1.01487	valid-rmse:1.01838
[60]	train-rmse:1.03453	valid-rmse:1.03802
[320]	train-rmse:0.99507	valid-rmse:0.99932
[340]	train-rmse:0.99454	valid-rmse:0.99903
[220]	train-rmse:0.99700	valid-rmse:1.00072
[340]	train-rmse:0.99478	valid-rmse:0.99916
[180]	train-rmse:1.00338	valid-rmse:1.00687
[360]	train-rmse:0.99430	valid-rmse:0.99895
[120]	train-rmse:1.00937	valid-rmse:1.01287
[80]	train-rmse:1.02378	valid-rmse:1.02728
[360]	train-rmse:0.99452	valid-rmse:0.99903
[240]	train-rmse:0.99632	valid-rmse:1.00013
[380]	train-rmse:0.99409	valid-rmse:0.99887
[200]	train-rmse:1.00138	valid-rmse:1.00488
[380]	train-rmse:0.99429	valid-rmse:0.99894
[400]	train-rmse:0.99388	valid-rmse:0.99881
[140]	train-rmse:1.00540	valid-rmse:1.00893
[100]	train-rmse:1.01600	valid-rmse:1.01950
[260]	train-rmse:0.99579	valid-rmse:0.99970
[220]	train-rmse:0.99984	valid-rmse:1.00340
[420]	train-rmse:0.99371	valid-rmse:0.99877
[400]	train-rmse:0.99406	valid-rmse:0.99887
[280]	train-rmse:0.99536	valid-rmse:0.99939
[440]	train-rmse:0.99352	valid-rmse:0.99873
[160]	train-rmse:1.00252	valid-rmse:1.00609
[120]	train-rmse:1.01034	valid-rmse:1.01384
[420]	train-rmse:0.99387	valid-rmse:0.99880
[240]	train-rmse:0.99869	valid-rmse:1.00227
[460]	train-rmse:0.99334	valid-rmse:0.99871
[440]	train-rmse:0.99368	valid-rmse:0.99874
[300]	train-rmse:0.99501	valid-rmse:0.99917
[480]	train-rmse:0.99315	valid-rmse:0.99870
[180]	train-rmse:1.00043	valid-rmse:1.00405
[260]	train-rmse:0.99780	valid-rmse:1.00141
[140]	train-rmse:1.00622	valid-rmse:1.00975
[460]	train-rmse:0.99350	valid-rmse:0.99871
[500]	train-rmse:0.99296	valid-rmse:0.99871
[320]	train-rmse:0.99471	valid-rmse:0.99900
[480]	train-rmse:0.99332	valid-rmse:0.99871
[280]	train-rmse:0.99708	valid-rmse:1.00075
[200]	train-rmse:0.99891	valid-rmse:1.00258
[520]	train-rmse:0.99277	valid-rmse:0.99870
[160]	train-rmse:1.00323	valid-rmse:1.00676
[32m[I 2022-04-17 00:22:55,391][0m Trial 71 finished with value: 0.998697 and parameters: {'colsample_bytree': 0.716483580203003, 'eta': 0.009286120764357073, 'max_depth': 3, 'n_estimators': 896, 'subsample': 0.3725183669665076}. Best is trial 48 with value: 0.998395.[0m
[00:22:59] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08097	valid-rmse:1.08431
[340]	train-rmse:0.99444	valid-rmse:0.99889
[500]	train-rmse:0.99314	valid-rmse:0.99870
[300]	train-rmse:0.99650	valid-rmse:1.00026
[20]	train-rmse:0.99703	valid-rmse:1.00058
[220]	train-rmse:0.99777	valid-rmse:1.00152
[520]	train-rmse:0.99299	valid-rmse:0.99867
[180]	train-rmse:1.00100	valid-rmse:1.00459
[360]	train-rmse:0.99422	valid-rmse:0.99880
[320]	train-rmse:0.99605	valid-rmse:0.99988
[40]	train-rmse:0.99376	valid-rmse:0.99869
[540]	train-rmse:0.99281	valid-rmse:0.99866
[240]	train-rmse:0.99694	valid-rmse:1.00075
[380]	train-rmse:0.99398	valid-rmse:0.99874
[200]	train-rmse:0.99938	valid-rmse:1.00300
[560]	train-rmse:0.99264	valid-rmse:0.99866
[60]	train-rmse:0.99216	valid-rmse:0.99859
[340]	train-rmse:0.99567	valid-rmse:0.99959
[580]	train-rmse:0.99246	valid-rmse:0.99865
[400]	train-rmse:0.99377	valid-rmse:0.99869
[80]	train-rmse:0.99049	valid-rmse:0.99852
[260]	train-rmse:0.99630	valid-rmse:1.00019
[220]	train-rmse:0.99816	valid-rmse:1.00186
[360]	train-rmse:0.99535	valid-rmse:0.99938
[600]	train-rmse:0.99231	valid-rmse:0.99865
[100]	train-rmse:0.98901	valid-rmse:0.99856
[420]	train-rmse:0.99357	valid-rmse:0.99866
[280]	train-rmse:0.99578	valid-rmse:0.99978
[380]	train-rmse:0.99507	valid-rmse:0.99920
[620]	train-rmse:0.99213	valid-rmse:0.99865
[240]	train-rmse:0.99727	valid-rmse:1.00102
[120]	train-rmse:0.98741	valid-rmse:0.99870
[125]	train-rmse:0.98698	valid-rmse:0.99875
[32m[I 2022-04-17 00:27:40,674][0m Trial 75 finished with value: 0.998499 and parameters: {'colsample_bytree': 0.5594956921157953, 'eta': 0.09723711740492809, 'max_depth': 3, 'n_estimators': 38, 'subsample': 0.8861627371344465}. Best is trial 48 with value: 0.998395.[0m
[440]	train-rmse:0.99340	valid-rmse:0.99862
[00:27:45] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[640]	train-rmse:0.99197	valid-rmse:0.99864
[0]	train-rmse:1.08011	valid-rmse:1.08343
[400]	train-rmse:0.99483	valid-rmse:0.99906
[300]	train-rmse:0.99537	valid-rmse:0.99948
[260]	train-rmse:0.99658	valid-rmse:1.00039
[660]	train-rmse:0.99180	valid-rmse:0.99864
[20]	train-rmse:0.99657	valid-rmse:1.00013
[460]	train-rmse:0.99322	valid-rmse:0.99861
[420]	train-rmse:0.99462	valid-rmse:0.99895
[680]	train-rmse:0.99165	valid-rmse:0.99864
[40]	train-rmse:0.99349	valid-rmse:0.99862
[320]	train-rmse:0.99503	valid-rmse:0.99926
[280]	train-rmse:0.99602	valid-rmse:0.99993
[480]	train-rmse:0.99304	valid-rmse:0.99858
[700]	train-rmse:0.99150	valid-rmse:0.99865
[440]	train-rmse:0.99443	valid-rmse:0.99887
[60]	train-rmse:0.99187	valid-rmse:0.99856
[340]	train-rmse:0.99474	valid-rmse:0.99910
[500]	train-rmse:0.99286	valid-rmse:0.99859
[720]	train-rmse:0.99134	valid-rmse:0.99865
[300]	train-rmse:0.99558	valid-rmse:0.99958
[80]	train-rmse:0.99009	valid-rmse:0.99859
[730]	train-rmse:0.99126	valid-rmse:0.99865
[460]	train-rmse:0.99425	valid-rmse:0.99880
[32m[I 2022-04-17 00:30:43,282][0m Trial 69 finished with value: 0.998635 and parameters: {'colsample_bytree': 0.7936670887315806, 'eta': 0.00866283059902183, 'max_depth': 3, 'n_estimators': 897, 'subsample': 0.41680283567368775}. Best is trial 48 with value: 0.998395.[0m
[00:30:47] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08081	valid-rmse:1.08415
[520]	train-rmse:0.99267	valid-rmse:0.99859
[100]	train-rmse:0.98841	valid-rmse:0.99874
[360]	train-rmse:0.99449	valid-rmse:0.99898
[320]	train-rmse:0.99520	valid-rmse:0.99933
[20]	train-rmse:0.99692	valid-rmse:1.00057
[480]	train-rmse:0.99409	valid-rmse:0.99876
[529]	train-rmse:0.99259	valid-rmse:0.99858
[32m[I 2022-04-17 00:31:39,670][0m Trial 70 finished with value: 0.998581 and parameters: {'colsample_bytree': 0.7194543627853809, 'eta': 0.009483432862674104, 'max_depth': 3, 'n_estimators': 894, 'subsample': 0.8842539608539739}. Best is trial 48 with value: 0.998395.[0m
[00:31:43] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[113]	train-rmse:0.98733	valid-rmse:0.99893
[32m[I 2022-04-17 00:31:44,551][0m Trial 76 finished with value: 0.998539 and parameters: {'colsample_bytree': 0.5469265082704443, 'eta': 0.10246144761082306, 'max_depth': 3, 'n_estimators': 1024, 'subsample': 0.843548839920784}. Best is trial 48 with value: 0.998395.[0m
[0]	train-rmse:1.08082	valid-rmse:1.08413
[00:31:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.04901	valid-rmse:1.05256
[40]	train-rmse:0.99360	valid-rmse:0.99866
[380]	train-rmse:0.99425	valid-rmse:0.99888
[500]	train-rmse:0.99391	valid-rmse:0.99871
[20]	train-rmse:0.99687	valid-rmse:1.00047
[20]	train-rmse:0.99230	valid-rmse:0.99930
[340]	train-rmse:0.99490	valid-rmse:0.99915
[60]	train-rmse:0.99195	valid-rmse:0.99864
[40]	train-rmse:0.98810	valid-rmse:0.99981
[40]	train-rmse:0.99338	valid-rmse:0.99862
[520]	train-rmse:0.99376	valid-rmse:0.99868
[400]	train-rmse:0.99403	valid-rmse:0.99880
[360]	train-rmse:0.99463	valid-rmse:0.99901
[80]	train-rmse:0.99027	valid-rmse:0.99874
[60]	train-rmse:0.98394	valid-rmse:1.00076
[32m[I 2022-04-17 00:33:53,021][0m Trial 79 finished with value: 0.998979 and parameters: {'colsample_bytree': 0.6248139394680641, 'eta': 0.29798133380524816, 'max_depth': 3, 'n_estimators': 501, 'subsample': 0.6240845678303087}. Best is trial 48 with value: 0.998395.[0m
[00:33:57] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:0.99173	valid-rmse:0.99856
[0]	train-rmse:1.09905	valid-rmse:1.10223
[540]	train-rmse:0.99361	valid-rmse:0.99866
[97]	train-rmse:0.98891	valid-rmse:0.99882
[32m[I 2022-04-17 00:34:16,836][0m Trial 77 finished with value: 0.998605 and parameters: {'colsample_bytree': 0.5606936875289915, 'eta': 0.09820771054884987, 'max_depth': 3, 'n_estimators': 476, 'subsample': 0.8720471295127199}. Best is trial 48 with value: 0.998395.[0m
[00:34:21] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09865	valid-rmse:1.10183
[420]	train-rmse:0.99383	valid-rmse:0.99875
[20]	train-rmse:1.09887	valid-rmse:1.10204
[80]	train-rmse:0.99008	valid-rmse:0.99864
[380]	train-rmse:0.99440	valid-rmse:0.99889
[20]	train-rmse:1.09066	valid-rmse:1.09389
[560]	train-rmse:0.99346	valid-rmse:0.99864
[40]	train-rmse:1.09868	valid-rmse:1.10186
[100]	train-rmse:0.98835	valid-rmse:0.99878
[32m[I 2022-04-17 00:35:25,836][0m Trial 78 finished with value: 0.998546 and parameters: {'colsample_bytree': 0.5824684837751145, 'eta': 0.09843119483169958, 'max_depth': 3, 'n_estimators': 25, 'subsample': 0.8402887017944886}. Best is trial 48 with value: 0.998395.[0m
[00:35:30] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.01239	valid-rmse:1.01564
[440]	train-rmse:0.99365	valid-rmse:0.99871
[40]	train-rmse:1.08327	valid-rmse:1.08654
[400]	train-rmse:0.99419	valid-rmse:0.99880
[60]	train-rmse:1.09850	valid-rmse:1.10168
[580]	train-rmse:0.99330	valid-rmse:0.99862
[20]	train-rmse:0.98829	valid-rmse:1.00102
[60]	train-rmse:1.07644	valid-rmse:1.07974
[80]	train-rmse:1.09831	valid-rmse:1.10149
[460]	train-rmse:0.99346	valid-rmse:0.99868
[40]	train-rmse:0.98094	valid-rmse:1.00270
[420]	train-rmse:0.99398	valid-rmse:0.99874
[600]	train-rmse:0.99317	valid-rmse:0.99861
[80]	train-rmse:1.07013	valid-rmse:1.07346
[55]	train-rmse:0.97566	valid-rmse:1.00383
[32m[I 2022-04-17 00:37:19,426][0m Trial 82 finished with value: 0.999101 and parameters: {'colsample_bytree': 0.46815477344460515, 'eta': 0.6227880096822302, 'max_depth': 3, 'n_estimators': 69, 'subsample': 0.924035914093863}. Best is trial 48 with value: 0.998395.[0m
[100]	train-rmse:1.09813	valid-rmse:1.10131
[00:37:23] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[100]	train-rmse:1.06431	valid-rmse:1.06767
[480]	train-rmse:0.99329	valid-rmse:0.99865
[620]	train-rmse:0.99302	valid-rmse:0.99860
[440]	train-rmse:0.99379	valid-rmse:0.99868
[120]	train-rmse:1.09794	valid-rmse:1.10112
[20]	train-rmse:1.09904	valid-rmse:1.10221
[120]	train-rmse:1.05893	valid-rmse:1.06232
[140]	train-rmse:1.09776	valid-rmse:1.10094
[640]	train-rmse:0.99287	valid-rmse:0.99859
[500]	train-rmse:0.99311	valid-rmse:0.99863
[460]	train-rmse:0.99360	valid-rmse:0.99865
[40]	train-rmse:1.09901	valid-rmse:1.10218
[140]	train-rmse:1.05397	valid-rmse:1.05737
[160]	train-rmse:1.09757	valid-rmse:1.10076
[660]	train-rmse:0.99273	valid-rmse:0.99858
[60]	train-rmse:1.09898	valid-rmse:1.10215
[160]	train-rmse:1.04939	valid-rmse:1.05281
[180]	train-rmse:1.09739	valid-rmse:1.10058
[520]	train-rmse:0.99294	valid-rmse:0.99862
[480]	train-rmse:0.99343	valid-rmse:0.99862
[180]	train-rmse:1.04517	valid-rmse:1.04859
[680]	train-rmse:0.99260	valid-rmse:0.99857
[80]	train-rmse:1.09895	valid-rmse:1.10213
[200]	train-rmse:1.09721	valid-rmse:1.10040
[540]	train-rmse:0.99279	valid-rmse:0.99861
[200]	train-rmse:1.04127	valid-rmse:1.04471
[500]	train-rmse:0.99325	valid-rmse:0.99861
[220]	train-rmse:1.09703	valid-rmse:1.10021
[100]	train-rmse:1.09892	valid-rmse:1.10210
[700]	train-rmse:0.99246	valid-rmse:0.99857
[220]	train-rmse:1.03768	valid-rmse:1.04112
[240]	train-rmse:1.09684	valid-rmse:1.10003
[120]	train-rmse:1.09889	valid-rmse:1.10207
[560]	train-rmse:0.99262	valid-rmse:0.99860
[520]	train-rmse:0.99308	valid-rmse:0.99859
[720]	train-rmse:0.99232	valid-rmse:0.99856
[240]	train-rmse:1.03438	valid-rmse:1.03782
[260]	train-rmse:1.09666	valid-rmse:1.09985
[140]	train-rmse:1.09887	valid-rmse:1.10204
[260]	train-rmse:1.03133	valid-rmse:1.03477
[280]	train-rmse:1.09648	valid-rmse:1.09967
[580]	train-rmse:0.99245	valid-rmse:0.99861
[740]	train-rmse:0.99217	valid-rmse:0.99856
[540]	train-rmse:0.99293	valid-rmse:0.99857
[160]	train-rmse:1.09884	valid-rmse:1.10201
[280]	train-rmse:1.02851	valid-rmse:1.03196
[300]	train-rmse:1.09630	valid-rmse:1.09949
[760]	train-rmse:0.99204	valid-rmse:0.99855
[600]	train-rmse:0.99231	valid-rmse:0.99860
[560]	train-rmse:0.99277	valid-rmse:0.99856
[300]	train-rmse:1.02592	valid-rmse:1.02938
[180]	train-rmse:1.09881	valid-rmse:1.10199
[320]	train-rmse:1.09612	valid-rmse:1.09931
[780]	train-rmse:0.99190	valid-rmse:0.99855
[320]	train-rmse:1.02353	valid-rmse:1.02698
[340]	train-rmse:1.09594	valid-rmse:1.09913
[200]	train-rmse:1.09878	valid-rmse:1.10196
[620]	train-rmse:0.99214	valid-rmse:0.99859
[580]	train-rmse:0.99261	valid-rmse:0.99855
[340]	train-rmse:1.02133	valid-rmse:1.02479
[360]	train-rmse:1.09575	valid-rmse:1.09895
[800]	train-rmse:0.99177	valid-rmse:0.99855
[220]	train-rmse:1.09875	valid-rmse:1.10193
[360]	train-rmse:1.01931	valid-rmse:1.02276
[640]	train-rmse:0.99199	valid-rmse:0.99859
[380]	train-rmse:1.09557	valid-rmse:1.09877
[600]	train-rmse:0.99247	valid-rmse:0.99853
[240]	train-rmse:1.09873	valid-rmse:1.10190
[820]	train-rmse:0.99164	valid-rmse:0.99854
[400]	train-rmse:1.09539	valid-rmse:1.09859
[380]	train-rmse:1.01744	valid-rmse:1.02089
[660]	train-rmse:0.99183	valid-rmse:0.99860
[260]	train-rmse:1.09870	valid-rmse:1.10188
[620]	train-rmse:0.99230	valid-rmse:0.99852
[840]	train-rmse:0.99150	valid-rmse:0.99854
[420]	train-rmse:1.09521	valid-rmse:1.09841
[400]	train-rmse:1.01571	valid-rmse:1.01917
[280]	train-rmse:1.09867	valid-rmse:1.10185
[440]	train-rmse:1.09503	valid-rmse:1.09824
[420]	train-rmse:1.01412	valid-rmse:1.01758
[860]	train-rmse:0.99138	valid-rmse:0.99854
[680]	train-rmse:0.99169	valid-rmse:0.99859
[640]	train-rmse:0.99214	valid-rmse:0.99851
[460]	train-rmse:1.09485	valid-rmse:1.09806
[440]	train-rmse:1.01265	valid-rmse:1.01611
[300]	train-rmse:1.09864	valid-rmse:1.10182
[880]	train-rmse:0.99126	valid-rmse:0.99854
[700]	train-rmse:0.99153	valid-rmse:0.99859
[480]	train-rmse:1.09468	valid-rmse:1.09788
[660]	train-rmse:0.99198	valid-rmse:0.99850
[460]	train-rmse:1.01130	valid-rmse:1.01476
[320]	train-rmse:1.09862	valid-rmse:1.10179
[500]	train-rmse:1.09450	valid-rmse:1.09770
[900]	train-rmse:0.99112	valid-rmse:0.99854
[480]	train-rmse:1.01006	valid-rmse:1.01351
[340]	train-rmse:1.09859	valid-rmse:1.10177
[720]	train-rmse:0.99137	valid-rmse:0.99860
[680]	train-rmse:0.99184	valid-rmse:0.99851
[520]	train-rmse:1.09432	valid-rmse:1.09753
[500]	train-rmse:1.00892	valid-rmse:1.01237
[920]	train-rmse:0.99100	valid-rmse:0.99854
[360]	train-rmse:1.09856	valid-rmse:1.10174
[540]	train-rmse:1.09414	valid-rmse:1.09735
[520]	train-rmse:1.00786	valid-rmse:1.01131
[700]	train-rmse:0.99169	valid-rmse:0.99851
[740]	train-rmse:0.99122	valid-rmse:0.99860
[743]	train-rmse:0.99120	valid-rmse:0.99860
[32m[I 2022-04-17 00:52:26,821][0m Trial 73 finished with value: 0.998589 and parameters: {'colsample_bytree': 0.9247309077578829, 'eta': 0.008697136004124995, 'max_depth': 3, 'n_estimators': 70, 'subsample': 0.8844717658485381}. Best is trial 48 with value: 0.998395.[0m
[00:52:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[940]	train-rmse:0.99087	valid-rmse:0.99854
[380]	train-rmse:1.09853	valid-rmse:1.10171
[942]	train-rmse:0.99085	valid-rmse:0.99854
[0]	train-rmse:1.09905	valid-rmse:1.10223
[32m[I 2022-04-17 00:52:38,053][0m Trial 72 finished with value: 0.998536 and parameters: {'colsample_bytree': 0.7167428727245188, 'eta': 0.007430944704946715, 'max_depth': 3, 'n_estimators': 94, 'subsample': 0.9186094331936754}. Best is trial 48 with value: 0.998395.[0m
[560]	train-rmse:1.09397	valid-rmse:1.09717
[00:52:42] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[540]	train-rmse:1.00689	valid-rmse:1.01034
[711]	train-rmse:0.99160	valid-rmse:0.99852
[0]	train-rmse:1.09906	valid-rmse:1.10224
[32m[I 2022-04-17 00:52:51,812][0m Trial 74 finished with value: 0.998501 and parameters: {'colsample_bytree': 0.9309290225090897, 'eta': 0.008406925491495463, 'max_depth': 3, 'n_estimators': 446, 'subsample': 0.8685369729673496}. Best is trial 48 with value: 0.998395.[0m
[00:52:55] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09865	valid-rmse:1.10183
[580]	train-rmse:1.09379	valid-rmse:1.09699
[400]	train-rmse:1.09850	valid-rmse:1.10168
[560]	train-rmse:1.00599	valid-rmse:1.00944
[20]	train-rmse:1.09883	valid-rmse:1.10201
[600]	train-rmse:1.09361	valid-rmse:1.09682
[420]	train-rmse:1.09848	valid-rmse:1.10166
[580]	train-rmse:1.00517	valid-rmse:1.00862
[20]	train-rmse:1.09075	valid-rmse:1.09397
[620]	train-rmse:1.09343	valid-rmse:1.09664
[600]	train-rmse:1.00440	valid-rmse:1.00785
[440]	train-rmse:1.09845	valid-rmse:1.10163
[20]	train-rmse:1.09903	valid-rmse:1.10221
[40]	train-rmse:1.09862	valid-rmse:1.10180
[640]	train-rmse:1.09326	valid-rmse:1.09647
[40]	train-rmse:1.08343	valid-rmse:1.08670
[620]	train-rmse:1.00370	valid-rmse:1.00715
[460]	train-rmse:1.09842	valid-rmse:1.10160
[660]	train-rmse:1.09308	valid-rmse:1.09629
[60]	train-rmse:1.09840	valid-rmse:1.10158
[640]	train-rmse:1.00304	valid-rmse:1.00650
[480]	train-rmse:1.09839	valid-rmse:1.10157
[60]	train-rmse:1.07666	valid-rmse:1.07996
[680]	train-rmse:1.09291	valid-rmse:1.09612
[660]	train-rmse:1.00245	valid-rmse:1.00591
[40]	train-rmse:1.09900	valid-rmse:1.10218
[700]	train-rmse:1.09273	valid-rmse:1.09594
[500]	train-rmse:1.09837	valid-rmse:1.10154
[80]	train-rmse:1.09818	valid-rmse:1.10136
[680]	train-rmse:1.00189	valid-rmse:1.00535
[80]	train-rmse:1.07039	valid-rmse:1.07374
[720]	train-rmse:1.09255	valid-rmse:1.09577
[520]	train-rmse:1.09834	valid-rmse:1.10152
[700]	train-rmse:1.00137	valid-rmse:1.00484
[100]	train-rmse:1.09797	valid-rmse:1.10115
[740]	train-rmse:1.09238	valid-rmse:1.09560
[720]	train-rmse:1.00090	valid-rmse:1.00437
[540]	train-rmse:1.09831	valid-rmse:1.10149
[100]	train-rmse:1.06461	valid-rmse:1.06798
[60]	train-rmse:1.09897	valid-rmse:1.10215
[760]	train-rmse:1.09221	valid-rmse:1.09542
[740]	train-rmse:1.00045	valid-rmse:1.00394
[120]	train-rmse:1.09775	valid-rmse:1.10094
[560]	train-rmse:1.09828	valid-rmse:1.10146
[780]	train-rmse:1.09203	valid-rmse:1.09525
[120]	train-rmse:1.05927	valid-rmse:1.06266
[760]	train-rmse:1.00005	valid-rmse:1.00354
[580]	train-rmse:1.09825	valid-rmse:1.10143
[800]	train-rmse:1.09186	valid-rmse:1.09508
[780]	train-rmse:0.99967	valid-rmse:1.00317
[140]	train-rmse:1.09754	valid-rmse:1.10072
[820]	train-rmse:1.09168	valid-rmse:1.09491
[600]	train-rmse:1.09823	valid-rmse:1.10141
[140]	train-rmse:1.05433	valid-rmse:1.05774
[80]	train-rmse:1.09893	valid-rmse:1.10212
[800]	train-rmse:0.99931	valid-rmse:1.00283
[840]	train-rmse:1.09151	valid-rmse:1.09473
[160]	train-rmse:1.09733	valid-rmse:1.10051
[620]	train-rmse:1.09820	valid-rmse:1.10138
[820]	train-rmse:0.99899	valid-rmse:1.00252
[160]	train-rmse:1.04977	valid-rmse:1.05319
[860]	train-rmse:1.09134	valid-rmse:1.09456
[640]	train-rmse:1.09817	valid-rmse:1.10135
[840]	train-rmse:0.99869	valid-rmse:1.00223
[880]	train-rmse:1.09117	valid-rmse:1.09439
[180]	train-rmse:1.09711	valid-rmse:1.10030
[100]	train-rmse:1.09890	valid-rmse:1.10209
[860]	train-rmse:0.99840	valid-rmse:1.00197
[660]	train-rmse:1.09814	valid-rmse:1.10132
[180]	train-rmse:1.04556	valid-rmse:1.04900
[900]	train-rmse:1.09099	valid-rmse:1.09422
[880]	train-rmse:0.99814	valid-rmse:1.00172
[200]	train-rmse:1.09690	valid-rmse:1.10008
[680]	train-rmse:1.09812	valid-rmse:1.10130
[920]	train-rmse:1.09082	valid-rmse:1.09405
[200]	train-rmse:1.04167	valid-rmse:1.04512
[900]	train-rmse:0.99790	valid-rmse:1.00149
[940]	train-rmse:1.09065	valid-rmse:1.09388
[700]	train-rmse:1.09809	valid-rmse:1.10127
[120]	train-rmse:1.09887	valid-rmse:1.10206
[920]	train-rmse:0.99767	valid-rmse:1.00127
[220]	train-rmse:1.09668	valid-rmse:1.09987
[960]	train-rmse:1.09048	valid-rmse:1.09371
[720]	train-rmse:1.09806	valid-rmse:1.10124
[220]	train-rmse:1.03809	valid-rmse:1.04154
[940]	train-rmse:0.99745	valid-rmse:1.00108
[980]	train-rmse:1.09031	valid-rmse:1.09354
[240]	train-rmse:1.09647	valid-rmse:1.09966
[740]	train-rmse:1.09803	valid-rmse:1.10121
[960]	train-rmse:0.99726	valid-rmse:1.00090
[999]	train-rmse:1.09014	valid-rmse:1.09337
[32m[I 2022-04-17 01:07:18,170][0m Trial 80 finished with value: 1.093374 and parameters: {'colsample_bytree': 0.5200876018743992, 'eta': 4.796025323436431e-05, 'max_depth': 3, 'n_estimators': 452, 'subsample': 0.8761170814930864}. Best is trial 48 with value: 0.998395.[0m
[240]	train-rmse:1.03478	valid-rmse:1.03824
[01:07:22] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[980]	train-rmse:0.99707	valid-rmse:1.00073
[760]	train-rmse:1.09800	valid-rmse:1.10119
[140]	train-rmse:1.09884	valid-rmse:1.10203
[260]	train-rmse:1.09626	valid-rmse:1.09945
[999]	train-rmse:0.99690	valid-rmse:1.00059
[32m[I 2022-04-17 01:08:23,891][0m Trial 81 finished with value: 1.000585 and parameters: {'colsample_bytree': 0.5237377364651331, 'eta': 0.0021448082458366473, 'max_depth': 3, 'n_estimators': 60, 'subsample': 0.9174035370863552}. Best is trial 48 with value: 0.998395.[0m
[01:08:28] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20]	train-rmse:1.09901	valid-rmse:1.10218
[260]	train-rmse:1.03173	valid-rmse:1.03519
[780]	train-rmse:1.09798	valid-rmse:1.10116
[0]	train-rmse:1.09906	valid-rmse:1.10224
[280]	train-rmse:1.09605	valid-rmse:1.09924
[800]	train-rmse:1.09795	valid-rmse:1.10113
[40]	train-rmse:1.09896	valid-rmse:1.10213
[280]	train-rmse:1.02891	valid-rmse:1.03238
[160]	train-rmse:1.09881	valid-rmse:1.10200
[820]	train-rmse:1.09792	valid-rmse:1.10110
[300]	train-rmse:1.09583	valid-rmse:1.09903
[60]	train-rmse:1.09891	valid-rmse:1.10208
[300]	train-rmse:1.02631	valid-rmse:1.02979
[840]	train-rmse:1.09789	valid-rmse:1.10108
[20]	train-rmse:1.09906	valid-rmse:1.10224
[320]	train-rmse:1.09562	valid-rmse:1.09882
[80]	train-rmse:1.09885	valid-rmse:1.10203
[860]	train-rmse:1.09787	valid-rmse:1.10105
[320]	train-rmse:1.02391	valid-rmse:1.02739
[180]	train-rmse:1.09877	valid-rmse:1.10197
[880]	train-rmse:1.09784	valid-rmse:1.10102
[100]	train-rmse:1.09880	valid-rmse:1.10198
[340]	train-rmse:1.09542	valid-rmse:1.09861
[340]	train-rmse:1.02171	valid-rmse:1.02518
[900]	train-rmse:1.09781	valid-rmse:1.10099
[120]	train-rmse:1.09875	valid-rmse:1.10193
[40]	train-rmse:1.09906	valid-rmse:1.10224
[360]	train-rmse:1.09520	valid-rmse:1.09840
[920]	train-rmse:1.09778	valid-rmse:1.10097
[200]	train-rmse:1.09874	valid-rmse:1.10194
[360]	train-rmse:1.01967	valid-rmse:1.02313
[140]	train-rmse:1.09870	valid-rmse:1.10188
[940]	train-rmse:1.09776	valid-rmse:1.10094
[380]	train-rmse:1.09499	valid-rmse:1.09820
[380]	train-rmse:1.01778	valid-rmse:1.02125
[960]	train-rmse:1.09773	valid-rmse:1.10091
[160]	train-rmse:1.09865	valid-rmse:1.10183
[220]	train-rmse:1.09871	valid-rmse:1.10191
[400]	train-rmse:1.09478	valid-rmse:1.09799
[980]	train-rmse:1.09770	valid-rmse:1.10088
[60]	train-rmse:1.09906	valid-rmse:1.10223
[400]	train-rmse:1.01605	valid-rmse:1.01952
[180]	train-rmse:1.09860	valid-rmse:1.10177
[999]	train-rmse:1.09767	valid-rmse:1.10086
[32m[I 2022-04-17 01:17:21,450][0m Trial 83 finished with value: 1.100858 and parameters: {'colsample_bytree': 0.6288666127892972, 'eta': 7.201142736501534e-06, 'max_depth': 3, 'n_estimators': 341, 'subsample': 0.9141246160590379}. Best is trial 48 with value: 0.998395.[0m
[01:17:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[420]	train-rmse:1.09458	valid-rmse:1.09778
[0]	train-rmse:1.09817	valid-rmse:1.10140
[200]	train-rmse:1.09855	valid-rmse:1.10172
[420]	train-rmse:1.01445	valid-rmse:1.01792
[240]	train-rmse:1.09868	valid-rmse:1.10188
[440]	train-rmse:1.09437	valid-rmse:1.09757
[220]	train-rmse:1.09849	valid-rmse:1.10167
[440]	train-rmse:1.01297	valid-rmse:1.01644
[80]	train-rmse:1.09906	valid-rmse:1.10223
[460]	train-rmse:1.09416	valid-rmse:1.09736
[240]	train-rmse:1.09844	valid-rmse:1.10162
[20]	train-rmse:1.08143	valid-rmse:1.08588
[460]	train-rmse:1.01161	valid-rmse:1.01508
[260]	train-rmse:1.09865	valid-rmse:1.10185
[480]	train-rmse:1.09395	valid-rmse:1.09716
[260]	train-rmse:1.09839	valid-rmse:1.10157
[480]	train-rmse:1.01035	valid-rmse:1.01382
[100]	train-rmse:1.09906	valid-rmse:1.10223
[280]	train-rmse:1.09834	valid-rmse:1.10152
[500]	train-rmse:1.09374	valid-rmse:1.09695
[280]	train-rmse:1.09861	valid-rmse:1.10182
[500]	train-rmse:1.00920	valid-rmse:1.01266
[40]	train-rmse:1.06711	valid-rmse:1.07266
[300]	train-rmse:1.09829	valid-rmse:1.10147
[520]	train-rmse:1.09354	valid-rmse:1.09675
[520]	train-rmse:1.00813	valid-rmse:1.01158
[320]	train-rmse:1.09824	valid-rmse:1.10142
[540]	train-rmse:1.09333	valid-rmse:1.09654
[120]	train-rmse:1.09905	valid-rmse:1.10223
[300]	train-rmse:1.09858	valid-rmse:1.10179
[540]	train-rmse:1.00714	valid-rmse:1.01060
[340]	train-rmse:1.09818	valid-rmse:1.10136
[60]	train-rmse:1.05479	valid-rmse:1.06140
[560]	train-rmse:1.09312	valid-rmse:1.09634
[560]	train-rmse:1.00623	valid-rmse:1.00969
[360]	train-rmse:1.09813	valid-rmse:1.10131
[320]	train-rmse:1.09855	valid-rmse:1.10176
[580]	train-rmse:1.09292	valid-rmse:1.09613
[140]	train-rmse:1.09905	valid-rmse:1.10223
[380]	train-rmse:1.09808	valid-rmse:1.10126
[580]	train-rmse:1.00539	valid-rmse:1.00885
[600]	train-rmse:1.09272	valid-rmse:1.09593
[80]	train-rmse:1.04418	valid-rmse:1.05183
[400]	train-rmse:1.09803	valid-rmse:1.10121
[600]	train-rmse:1.00461	valid-rmse:1.00808
[340]	train-rmse:1.09852	valid-rmse:1.10173
[620]	train-rmse:1.09251	valid-rmse:1.09573
[420]	train-rmse:1.09798	valid-rmse:1.10116
[620]	train-rmse:1.00389	valid-rmse:1.00736
[160]	train-rmse:1.09905	valid-rmse:1.10223
[640]	train-rmse:1.09231	valid-rmse:1.09552
[440]	train-rmse:1.09793	valid-rmse:1.10111
[100]	train-rmse:1.03508	valid-rmse:1.04374
[360]	train-rmse:1.09849	valid-rmse:1.10170
[640]	train-rmse:1.00323	valid-rmse:1.00670
[660]	train-rmse:1.09210	valid-rmse:1.09532
[460]	train-rmse:1.09788	valid-rmse:1.10106
[660]	train-rmse:1.00261	valid-rmse:1.00609
[180]	train-rmse:1.09905	valid-rmse:1.10222
[480]	train-rmse:1.09783	valid-rmse:1.10101
[680]	train-rmse:1.09190	valid-rmse:1.09512
[380]	train-rmse:1.09845	valid-rmse:1.10167
[680]	train-rmse:1.00204	valid-rmse:1.00553
[120]	train-rmse:1.02720	valid-rmse:1.03687
[500]	train-rmse:1.09777	valid-rmse:1.10096
[700]	train-rmse:1.09170	valid-rmse:1.09492
[700]	train-rmse:1.00151	valid-rmse:1.00501
[520]	train-rmse:1.09772	valid-rmse:1.10091
[720]	train-rmse:1.09149	valid-rmse:1.09472
[400]	train-rmse:1.09842	valid-rmse:1.10164
[200]	train-rmse:1.09905	valid-rmse:1.10222
[720]	train-rmse:1.00103	valid-rmse:1.00453
[540]	train-rmse:1.09767	valid-rmse:1.10086
[740]	train-rmse:1.09129	valid-rmse:1.09451
[140]	train-rmse:1.02043	valid-rmse:1.03106
[560]	train-rmse:1.09762	valid-rmse:1.10081
[740]	train-rmse:1.00059	valid-rmse:1.00408
[420]	train-rmse:1.09839	valid-rmse:1.10161
[760]	train-rmse:1.09109	valid-rmse:1.09431
[220]	train-rmse:1.09905	valid-rmse:1.10222
[580]	train-rmse:1.09757	valid-rmse:1.10075
[760]	train-rmse:1.00018	valid-rmse:1.00367
[780]	train-rmse:1.09089	valid-rmse:1.09411
[160]	train-rmse:1.01460	valid-rmse:1.02614
[600]	train-rmse:1.09752	valid-rmse:1.10070
[780]	train-rmse:0.99979	valid-rmse:1.00330
[440]	train-rmse:1.09836	valid-rmse:1.10158
[800]	train-rmse:1.09069	valid-rmse:1.09391
[620]	train-rmse:1.09747	valid-rmse:1.10065
[800]	train-rmse:0.99943	valid-rmse:1.00295
[240]	train-rmse:1.09905	valid-rmse:1.10222
[820]	train-rmse:1.09049	valid-rmse:1.09371
[640]	train-rmse:1.09742	valid-rmse:1.10060
[460]	train-rmse:1.09833	valid-rmse:1.10155
[180]	train-rmse:1.00958	valid-rmse:1.02194
[820]	train-rmse:0.99909	valid-rmse:1.00263
[840]	train-rmse:1.09029	valid-rmse:1.09352
[660]	train-rmse:1.09736	valid-rmse:1.10055
[840]	train-rmse:0.99878	valid-rmse:1.00233
[260]	train-rmse:1.09904	valid-rmse:1.10222
[680]	train-rmse:1.09731	valid-rmse:1.10050
[860]	train-rmse:1.09009	valid-rmse:1.09332
[480]	train-rmse:1.09830	valid-rmse:1.10152
[860]	train-rmse:0.99850	valid-rmse:1.00205
[200]	train-rmse:1.00518	valid-rmse:1.01840
[700]	train-rmse:1.09726	valid-rmse:1.10045
[880]	train-rmse:1.08989	valid-rmse:1.09312
[880]	train-rmse:0.99823	valid-rmse:1.00180
[720]	train-rmse:1.09721	valid-rmse:1.10040
[900]	train-rmse:1.08969	valid-rmse:1.09292
[500]	train-rmse:1.09827	valid-rmse:1.10149
[280]	train-rmse:1.09904	valid-rmse:1.10222
[900]	train-rmse:0.99797	valid-rmse:1.00157
[740]	train-rmse:1.09716	valid-rmse:1.10035
[920]	train-rmse:1.08949	valid-rmse:1.09272
[220]	train-rmse:1.00130	valid-rmse:1.01545
[760]	train-rmse:1.09711	valid-rmse:1.10030
[920]	train-rmse:0.99774	valid-rmse:1.00135
[520]	train-rmse:1.09823	valid-rmse:1.10146
[940]	train-rmse:1.08929	valid-rmse:1.09253
[780]	train-rmse:1.09706	valid-rmse:1.10025
[300]	train-rmse:1.09904	valid-rmse:1.10222
[940]	train-rmse:0.99753	valid-rmse:1.00115
[960]	train-rmse:1.08909	valid-rmse:1.09233
[240]	train-rmse:0.99798	valid-rmse:1.01294
[800]	train-rmse:1.09701	valid-rmse:1.10020
[540]	train-rmse:1.09820	valid-rmse:1.10143
[960]	train-rmse:0.99732	valid-rmse:1.00096
[980]	train-rmse:1.08890	valid-rmse:1.09214
[820]	train-rmse:1.09696	valid-rmse:1.10015
[980]	train-rmse:0.99713	valid-rmse:1.00080
[320]	train-rmse:1.09904	valid-rmse:1.10221
[999]	train-rmse:1.08871	valid-rmse:1.09195
[32m[I 2022-04-17 01:51:36,846][0m Trial 84 finished with value: 1.091949 and parameters: {'colsample_bytree': 0.9639811172339959, 'eta': 5.60439936051377e-05, 'max_depth': 3, 'n_estimators': 353, 'subsample': 0.9670422872539465}. Best is trial 48 with value: 0.998395.[0m
[01:51:41] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[840]	train-rmse:1.09691	valid-rmse:1.10010
[0]	train-rmse:1.09906	valid-rmse:1.10224
[560]	train-rmse:1.09817	valid-rmse:1.10140
[260]	train-rmse:0.99518	valid-rmse:1.01080
[999]	train-rmse:0.99695	valid-rmse:1.00064
[32m[I 2022-04-17 01:52:22,491][0m Trial 86 finished with value: 1.000643 and parameters: {'colsample_bytree': 0.9721271021584348, 'eta': 0.0021206371041989952, 'max_depth': 3, 'n_estimators': 845, 'subsample': 0.9664597556547273}. Best is trial 48 with value: 0.998395.[0m
[01:52:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.04834	valid-rmse:1.05449
[860]	train-rmse:1.09686	valid-rmse:1.10005
[880]	train-rmse:1.09681	valid-rmse:1.10000
[340]	train-rmse:1.09904	valid-rmse:1.10221
[20]	train-rmse:0.95523	valid-rmse:1.00364
[580]	train-rmse:1.09814	valid-rmse:1.10137
[20]	train-rmse:1.09906	valid-rmse:1.10224
[280]	train-rmse:0.99262	valid-rmse:1.00897
[900]	train-rmse:1.09676	valid-rmse:1.09995
[40]	train-rmse:0.92149	valid-rmse:1.00738
[920]	train-rmse:1.09670	valid-rmse:1.09990
[600]	train-rmse:1.09811	valid-rmse:1.10134
[360]	train-rmse:1.09903	valid-rmse:1.10221
[40]	train-rmse:1.09906	valid-rmse:1.10224
[940]	train-rmse:1.09665	valid-rmse:1.09984
[58]	train-rmse:0.88548	valid-rmse:1.01224
[32m[I 2022-04-17 01:57:11,961][0m Trial 91 finished with value: 1.001145 and parameters: {'colsample_bytree': 0.46658748097089064, 'eta': 0.2851123946624207, 'max_depth': 7, 'n_estimators': 718, 'subsample': 0.8244659019383962}. Best is trial 48 with value: 0.998395.[0m
[01:57:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08736	valid-rmse:1.09065
[300]	train-rmse:0.99042	valid-rmse:1.00744
[50]	train-rmse:1.09906	valid-rmse:1.10224
[32m[I 2022-04-17 01:57:59,867][0m Trial 90 finished with value: 1.102238 and parameters: {'colsample_bytree': 0.87692492733881, 'eta': 2.148150656701655e-08, 'max_depth': 7, 'n_estimators': 842, 'subsample': 0.8220454800919837}. Best is trial 48 with value: 0.998395.[0m
[01:58:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[960]	train-rmse:1.09660	valid-rmse:1.09980
[0]	train-rmse:1.09579	valid-rmse:1.09899
[20]	train-rmse:1.00357	valid-rmse:1.00706
[620]	train-rmse:1.09807	valid-rmse:1.10131
[980]	train-rmse:1.09655	valid-rmse:1.09974
[20]	train-rmse:1.04800	valid-rmse:1.05140
[380]	train-rmse:1.09903	valid-rmse:1.10221
[40]	train-rmse:0.99561	valid-rmse:0.99946
[999]	train-rmse:1.09650	valid-rmse:1.09970
[320]	train-rmse:0.98844	valid-rmse:1.00614
[32m[I 2022-04-17 02:00:10,038][0m Trial 87 finished with value: 1.099697 and parameters: {'colsample_bytree': 0.9478207403270501, 'eta': 1.3332997768512401e-05, 'max_depth': 3, 'n_estimators': 836, 'subsample': 0.8256828921377339}. Best is trial 48 with value: 0.998395.[0m
[02:00:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[40]	train-rmse:1.02286	valid-rmse:1.02626
[0]	train-rmse:1.09533	valid-rmse:1.09854
[60]	train-rmse:0.99401	valid-rmse:0.99864
[640]	train-rmse:1.09804	valid-rmse:1.10129
[60]	train-rmse:1.00978	valid-rmse:1.01313
[20]	train-rmse:1.04316	valid-rmse:1.04656
[80]	train-rmse:0.99288	valid-rmse:0.99854
[400]	train-rmse:1.09903	valid-rmse:1.10221
[80]	train-rmse:1.00293	valid-rmse:1.00631
[40]	train-rmse:1.01815	valid-rmse:1.02154
[100]	train-rmse:0.99179	valid-rmse:0.99852
[660]	train-rmse:1.09801	valid-rmse:1.10126
[340]	train-rmse:0.98664	valid-rmse:1.00503
[100]	train-rmse:0.99927	valid-rmse:1.00271
[60]	train-rmse:1.00626	valid-rmse:1.00962
[120]	train-rmse:0.99076	valid-rmse:0.99854
[120]	train-rmse:0.99729	valid-rmse:1.00082
[80]	train-rmse:1.00055	valid-rmse:1.00396
[420]	train-rmse:1.09903	valid-rmse:1.10221
[140]	train-rmse:0.98975	valid-rmse:0.99857
[680]	train-rmse:1.09798	valid-rmse:1.10123
[360]	train-rmse:0.98503	valid-rmse:1.00411
[152]	train-rmse:0.98909	valid-rmse:0.99859
[32m[I 2022-04-17 02:05:28,876][0m Trial 92 finished with value: 0.998488 and parameters: {'colsample_bytree': 0.8386901183962032, 'eta': 0.06192225703104037, 'max_depth': 3, 'n_estimators': 412, 'subsample': 0.964033771953307}. Best is trial 48 with value: 0.998395.[0m
[140]	train-rmse:0.99613	valid-rmse:0.99980
[02:05:32] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[100]	train-rmse:0.99772	valid-rmse:1.00124
[0]	train-rmse:1.09570	valid-rmse:1.09890
[160]	train-rmse:0.99538	valid-rmse:0.99923
[120]	train-rmse:0.99623	valid-rmse:0.99992
[20]	train-rmse:1.04701	valid-rmse:1.05041
[700]	train-rmse:1.09795	valid-rmse:1.10120
[440]	train-rmse:1.09903	valid-rmse:1.10221
[180]	train-rmse:0.99484	valid-rmse:0.99892
[140]	train-rmse:0.99534	valid-rmse:0.99926
[40]	train-rmse:1.02187	valid-rmse:1.02528
[380]	train-rmse:0.98352	valid-rmse:1.00330
[200]	train-rmse:0.99440	valid-rmse:0.99874
[160]	train-rmse:0.99475	valid-rmse:0.99890
[60]	train-rmse:1.00901	valid-rmse:1.01236
[720]	train-rmse:1.09791	valid-rmse:1.10117
[220]	train-rmse:0.99404	valid-rmse:0.99863
[180]	train-rmse:0.99428	valid-rmse:0.99870
[80]	train-rmse:1.00239	valid-rmse:1.00574
[460]	train-rmse:1.09903	valid-rmse:1.10220
[400]	train-rmse:0.98223	valid-rmse:1.00265
[240]	train-rmse:0.99374	valid-rmse:0.99857
[200]	train-rmse:0.99388	valid-rmse:0.99862
[100]	train-rmse:0.99890	valid-rmse:1.00234
[740]	train-rmse:1.09788	valid-rmse:1.10114
[260]	train-rmse:0.99342	valid-rmse:0.99852
[120]	train-rmse:0.99703	valid-rmse:1.00055
[220]	train-rmse:0.99350	valid-rmse:0.99855
[480]	train-rmse:1.09903	valid-rmse:1.10220
[280]	train-rmse:0.99312	valid-rmse:0.99847
[140]	train-rmse:0.99594	valid-rmse:0.99962
[240]	train-rmse:0.99316	valid-rmse:0.99851
[760]	train-rmse:1.09785	valid-rmse:1.10111
[420]	train-rmse:0.98096	valid-rmse:1.00207
[300]	train-rmse:0.99283	valid-rmse:0.99846
[160]	train-rmse:0.99525	valid-rmse:0.99913
[260]	train-rmse:0.99284	valid-rmse:0.99850
[320]	train-rmse:0.99253	valid-rmse:0.99845
[180]	train-rmse:0.99474	valid-rmse:0.99884
[280]	train-rmse:0.99247	valid-rmse:0.99847
[780]	train-rmse:1.09782	valid-rmse:1.10108
[500]	train-rmse:1.09902	valid-rmse:1.10220
[440]	train-rmse:0.97980	valid-rmse:1.00159
[340]	train-rmse:0.99227	valid-rmse:0.99844
[200]	train-rmse:0.99429	valid-rmse:0.99866
[300]	train-rmse:0.99218	valid-rmse:0.99846
[360]	train-rmse:0.99198	valid-rmse:0.99844
[220]	train-rmse:0.99393	valid-rmse:0.99858
[320]	train-rmse:0.99184	valid-rmse:0.99847
[800]	train-rmse:1.09779	valid-rmse:1.10105
[380]	train-rmse:0.99170	valid-rmse:0.99843
[520]	train-rmse:1.09902	valid-rmse:1.10220
[240]	train-rmse:0.99359	valid-rmse:0.99853
[340]	train-rmse:0.99152	valid-rmse:0.99847
[460]	train-rmse:0.97870	valid-rmse:1.00118
[400]	train-rmse:0.99145	valid-rmse:0.99844
[355]	train-rmse:0.99128	valid-rmse:0.99847
[32m[I 2022-04-17 02:19:21,485][0m Trial 94 finished with value: 0.998452 and parameters: {'colsample_bytree': 0.8353037893754558, 'eta': 0.019350323580271136, 'max_depth': 3, 'n_estimators': 186, 'subsample': 0.9965648220828099}. Best is trial 48 with value: 0.998395.[0m
[02:19:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[260]	train-rmse:0.99329	valid-rmse:0.99849
[0]	train-rmse:1.09581	valid-rmse:1.09901
[820]	train-rmse:1.09776	valid-rmse:1.10102
[420]	train-rmse:0.99114	valid-rmse:0.99845
[280]	train-rmse:0.99297	valid-rmse:0.99847
[20]	train-rmse:1.04826	valid-rmse:1.05165
[540]	train-rmse:1.09902	valid-rmse:1.10220
[433]	train-rmse:0.99100	valid-rmse:0.99846
[32m[I 2022-04-17 02:21:07,468][0m Trial 93 finished with value: 0.998431 and parameters: {'colsample_bytree': 0.8380718536064131, 'eta': 0.016965483076501243, 'max_depth': 3, 'n_estimators': 288, 'subsample': 0.9961993482349043}. Best is trial 48 with value: 0.998395.[0m
[02:21:11] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[480]	train-rmse:0.97769	valid-rmse:1.00083
[0]	train-rmse:1.09583	valid-rmse:1.09903
[840]	train-rmse:1.09773	valid-rmse:1.10099
[300]	train-rmse:0.99268	valid-rmse:0.99847
[40]	train-rmse:1.02313	valid-rmse:1.02653
[20]	train-rmse:1.04845	valid-rmse:1.05187
[320]	train-rmse:0.99238	valid-rmse:0.99847
[60]	train-rmse:1.00997	valid-rmse:1.01335
[40]	train-rmse:1.02331	valid-rmse:1.02679
[560]	train-rmse:1.09902	valid-rmse:1.10220
[860]	train-rmse:1.09769	valid-rmse:1.10096
[80]	train-rmse:1.00307	valid-rmse:1.00644
[340]	train-rmse:0.99209	valid-rmse:0.99848
[500]	train-rmse:0.97671	valid-rmse:1.00053
[60]	train-rmse:1.01011	valid-rmse:1.01352
[100]	train-rmse:0.99934	valid-rmse:1.00280
[360]	train-rmse:0.99180	valid-rmse:0.99846
[80]	train-rmse:1.00312	valid-rmse:1.00655
[880]	train-rmse:1.09766	valid-rmse:1.10093
[120]	train-rmse:0.99730	valid-rmse:1.00087
[380]	train-rmse:0.99152	valid-rmse:0.99845
[580]	train-rmse:1.09902	valid-rmse:1.10220
[100]	train-rmse:0.99938	valid-rmse:1.00289
[520]	train-rmse:0.97587	valid-rmse:1.00026
[140]	train-rmse:0.99612	valid-rmse:0.99982
[400]	train-rmse:0.99124	valid-rmse:0.99844
[120]	train-rmse:0.99730	valid-rmse:1.00092
[900]	train-rmse:1.09763	valid-rmse:1.10090
[160]	train-rmse:0.99535	valid-rmse:0.99926
[420]	train-rmse:0.99094	valid-rmse:0.99844
[140]	train-rmse:0.99610	valid-rmse:0.99986
[600]	train-rmse:1.09902	valid-rmse:1.10219
[180]	train-rmse:0.99481	valid-rmse:0.99892
[540]	train-rmse:0.97499	valid-rmse:1.00005
[440]	train-rmse:0.99065	valid-rmse:0.99844
[160]	train-rmse:0.99534	valid-rmse:0.99928
[920]	train-rmse:1.09760	valid-rmse:1.10087
[200]	train-rmse:0.99438	valid-rmse:0.99875
[460]	train-rmse:0.99038	valid-rmse:0.99844
[180]	train-rmse:0.99479	valid-rmse:0.99897
[220]	train-rmse:0.99400	valid-rmse:0.99864
[480]	train-rmse:0.99007	valid-rmse:0.99843
[620]	train-rmse:1.09901	valid-rmse:1.10219
[200]	train-rmse:0.99433	valid-rmse:0.99876
[560]	train-rmse:0.97420	valid-rmse:0.99985
[940]	train-rmse:1.09757	valid-rmse:1.10084
[240]	train-rmse:0.99369	valid-rmse:0.99856
[500]	train-rmse:0.98980	valid-rmse:0.99842
[220]	train-rmse:0.99396	valid-rmse:0.99865
[260]	train-rmse:0.99338	valid-rmse:0.99852
[520]	train-rmse:0.98953	valid-rmse:0.99843
[240]	train-rmse:0.99363	valid-rmse:0.99859
[960]	train-rmse:1.09754	valid-rmse:1.10081
[640]	train-rmse:1.09901	valid-rmse:1.10219
[580]	train-rmse:0.97336	valid-rmse:0.99969
[280]	train-rmse:0.99306	valid-rmse:0.99849
[538]	train-rmse:0.98928	valid-rmse:0.99843
[32m[I 2022-04-17 02:34:38,592][0m Trial 95 finished with value: 0.998414 and parameters: {'colsample_bytree': 0.8401936859345445, 'eta': 0.017433624692366173, 'max_depth': 3, 'n_estimators': 760, 'subsample': 0.9993877804442846}. Best is trial 48 with value: 0.998395.[0m
[02:34:42] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09591	valid-rmse:1.09912
[260]	train-rmse:0.99334	valid-rmse:0.99855
[300]	train-rmse:0.99276	valid-rmse:0.99848
[20]	train-rmse:1.04937	valid-rmse:1.05279
[280]	train-rmse:0.99303	valid-rmse:0.99851
[980]	train-rmse:1.09750	valid-rmse:1.10078
[320]	train-rmse:0.99247	valid-rmse:0.99847
[40]	train-rmse:1.02427	valid-rmse:1.02772
[300]	train-rmse:0.99272	valid-rmse:0.99848
[660]	train-rmse:1.09901	valid-rmse:1.10219
[600]	train-rmse:0.97262	valid-rmse:0.99956
[60]	train-rmse:1.01087	valid-rmse:1.01426
[340]	train-rmse:0.99223	valid-rmse:0.99846
[320]	train-rmse:0.99242	valid-rmse:0.99848
[999]	train-rmse:1.09747	valid-rmse:1.10075
[32m[I 2022-04-17 02:38:31,945][0m Trial 85 finished with value: 1.100755 and parameters: {'colsample_bytree': 0.633700033305616, 'eta': 7.767929842187007e-06, 'max_depth': 7, 'n_estimators': 338, 'subsample': 0.9616916475090961}. Best is trial 48 with value: 0.998395.[0m
[02:38:36] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:1.00368	valid-rmse:1.00707
[0]	train-rmse:1.09595	valid-rmse:1.09916
[360]	train-rmse:0.99194	valid-rmse:0.99846
[340]	train-rmse:0.99213	valid-rmse:0.99847
[100]	train-rmse:0.99977	valid-rmse:1.00324
[680]	train-rmse:1.09901	valid-rmse:1.10219
[620]	train-rmse:0.97184	valid-rmse:0.99946
[20]	train-rmse:1.04977	valid-rmse:1.05319
[380]	train-rmse:0.99168	valid-rmse:0.99846
[360]	train-rmse:0.99188	valid-rmse:0.99847
[120]	train-rmse:0.99759	valid-rmse:1.00116
[40]	train-rmse:1.02468	valid-rmse:1.02818
[400]	train-rmse:0.99143	valid-rmse:0.99845
[380]	train-rmse:0.99160	valid-rmse:0.99846
[140]	train-rmse:0.99630	valid-rmse:1.00001
[60]	train-rmse:1.01119	valid-rmse:1.01463
[420]	train-rmse:0.99113	valid-rmse:0.99847
[400]	train-rmse:0.99130	valid-rmse:0.99848
[700]	train-rmse:1.09901	valid-rmse:1.10218
[640]	train-rmse:0.97108	valid-rmse:0.99937
[160]	train-rmse:0.99548	valid-rmse:0.99936
[80]	train-rmse:1.00388	valid-rmse:1.00730
[440]	train-rmse:0.99089	valid-rmse:0.99848
[420]	train-rmse:0.99100	valid-rmse:0.99848
[180]	train-rmse:0.99492	valid-rmse:0.99900
[445]	train-rmse:0.99083	valid-rmse:0.99847
[32m[I 2022-04-17 02:43:37,018][0m Trial 96 finished with value: 0.998445 and parameters: {'colsample_bytree': 0.8421217754865888, 'eta': 0.016845918695954587, 'max_depth': 3, 'n_estimators': 130, 'subsample': 0.997907671098774}. Best is trial 48 with value: 0.998395.[0m
[02:43:41] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09611	valid-rmse:1.09932
[430]	train-rmse:0.99084	valid-rmse:0.99848
[32m[I 2022-04-17 02:43:50,349][0m Trial 97 finished with value: 0.99846 and parameters: {'colsample_bytree': 0.8385652235659121, 'eta': 0.016757047126864672, 'max_depth': 3, 'n_estimators': 404, 'subsample': 0.9679972102526602}. Best is trial 48 with value: 0.998395.[0m
[02:43:54] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[100]	train-rmse:0.99990	valid-rmse:1.00339
[0]	train-rmse:1.09595	valid-rmse:1.09916
[200]	train-rmse:0.99449	valid-rmse:0.99879
[20]	train-rmse:1.04963	valid-rmse:1.05297
[40]	train-rmse:1.02451	valid-rmse:1.02794
[20]	train-rmse:1.05177	valid-rmse:1.05515
[720]	train-rmse:1.09900	valid-rmse:1.10218
[120]	train-rmse:0.99769	valid-rmse:1.00125
[660]	train-rmse:0.97033	valid-rmse:0.99928
[60]	train-rmse:1.01108	valid-rmse:1.01449
[220]	train-rmse:0.99413	valid-rmse:0.99867
[80]	train-rmse:1.00392	valid-rmse:1.00737
[40]	train-rmse:1.02684	valid-rmse:1.03024
[140]	train-rmse:0.99636	valid-rmse:1.00006
[100]	train-rmse:0.99999	valid-rmse:1.00341
[240]	train-rmse:0.99382	valid-rmse:0.99860
[120]	train-rmse:0.99781	valid-rmse:1.00134
[60]	train-rmse:1.01294	valid-rmse:1.01633
[140]	train-rmse:0.99651	valid-rmse:1.00019
[160]	train-rmse:0.99547	valid-rmse:0.99939
[260]	train-rmse:0.99355	valid-rmse:0.99855
[160]	train-rmse:0.99566	valid-rmse:0.99951
[740]	train-rmse:1.09900	valid-rmse:1.10218
[680]	train-rmse:0.96959	valid-rmse:0.99922
[180]	train-rmse:0.99508	valid-rmse:0.99918
[80]	train-rmse:1.00521	valid-rmse:1.00859
[180]	train-rmse:0.99491	valid-rmse:0.99903
[280]	train-rmse:0.99325	valid-rmse:0.99851
[200]	train-rmse:0.99465	valid-rmse:0.99900
[220]	train-rmse:0.99424	valid-rmse:0.99888
[100]	train-rmse:1.00083	valid-rmse:1.00427
[240]	train-rmse:0.99391	valid-rmse:0.99877
[200]	train-rmse:0.99443	valid-rmse:0.99881
[300]	train-rmse:0.99291	valid-rmse:0.99848
[260]	train-rmse:0.99360	valid-rmse:0.99873
[280]	train-rmse:0.99328	valid-rmse:0.99867
[120]	train-rmse:0.99833	valid-rmse:1.00183
[320]	train-rmse:0.99262	valid-rmse:0.99849
[220]	train-rmse:0.99408	valid-rmse:0.99868
[760]	train-rmse:1.09900	valid-rmse:1.10218
[700]	train-rmse:0.96896	valid-rmse:0.99916
[300]	train-rmse:0.99301	valid-rmse:0.99870
[320]	train-rmse:0.99267	valid-rmse:0.99869
[140]	train-rmse:0.99685	valid-rmse:1.00046
[340]	train-rmse:0.99233	valid-rmse:0.99847
[340]	train-rmse:0.99237	valid-rmse:0.99871
[240]	train-rmse:0.99377	valid-rmse:0.99860
[32m[I 2022-04-17 02:51:22,851][0m Trial 101 finished with value: 0.998657 and parameters: {'colsample_bytree': 0.7725777671305666, 'eta': 0.01634323756420195, 'max_depth': 3, 'n_estimators': 181, 'subsample': 0.20902327841500234}. Best is trial 48 with value: 0.998395.[0m
[02:51:27] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09832	valid-rmse:1.10150
[360]	train-rmse:0.99209	valid-rmse:0.99848
[160]	train-rmse:0.99591	valid-rmse:0.99966
[260]	train-rmse:0.99351	valid-rmse:0.99854
[20]	train-rmse:1.08442	valid-rmse:1.08768
[780]	train-rmse:1.09900	valid-rmse:1.10218
[720]	train-rmse:0.96823	valid-rmse:0.99910
[380]	train-rmse:0.99180	valid-rmse:0.99848
[180]	train-rmse:0.99527	valid-rmse:0.99921
[280]	train-rmse:0.99318	valid-rmse:0.99850
[40]	train-rmse:1.07236	valid-rmse:1.07568
[390]	train-rmse:0.99168	valid-rmse:0.99848
[32m[I 2022-04-17 02:53:42,761][0m Trial 98 finished with value: 0.998474 and parameters: {'colsample_bytree': 0.7581163550071378, 'eta': 0.01633789371121137, 'max_depth': 3, 'n_estimators': 764, 'subsample': 0.970250962045411}. Best is trial 48 with value: 0.998395.[0m
[02:53:46] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09819	valid-rmse:1.10137
[200]	train-rmse:0.99479	valid-rmse:0.99892
[300]	train-rmse:0.99287	valid-rmse:0.99847
[60]	train-rmse:1.06191	valid-rmse:1.06527
[20]	train-rmse:1.08215	valid-rmse:1.08543
[220]	train-rmse:0.99440	valid-rmse:0.99876
[320]	train-rmse:0.99260	valid-rmse:0.99848
[800]	train-rmse:1.09900	valid-rmse:1.10218
[80]	train-rmse:1.05286	valid-rmse:1.05625
[740]	train-rmse:0.96748	valid-rmse:0.99907
[40]	train-rmse:1.06856	valid-rmse:1.07190
[240]	train-rmse:0.99410	valid-rmse:0.99865
[340]	train-rmse:0.99232	valid-rmse:0.99847
[100]	train-rmse:1.04503	valid-rmse:1.04844
[60]	train-rmse:1.05707	valid-rmse:1.06045
[260]	train-rmse:0.99377	valid-rmse:0.99859
[360]	train-rmse:0.99208	valid-rmse:0.99847
[120]	train-rmse:1.03826	valid-rmse:1.04168
[80]	train-rmse:1.04736	valid-rmse:1.05078
[820]	train-rmse:1.09900	valid-rmse:1.10218
[760]	train-rmse:0.96680	valid-rmse:0.99905
[280]	train-rmse:0.99346	valid-rmse:0.99854
[380]	train-rmse:0.99180	valid-rmse:0.99846
[140]	train-rmse:1.03242	valid-rmse:1.03584
[100]	train-rmse:1.03918	valid-rmse:1.04263
[300]	train-rmse:0.99319	valid-rmse:0.99852
[400]	train-rmse:0.99152	valid-rmse:0.99846
[160]	train-rmse:1.02736	valid-rmse:1.03078
[120]	train-rmse:1.03228	valid-rmse:1.03574
[415]	train-rmse:0.99130	valid-rmse:0.99846
[32m[I 2022-04-17 03:00:46,020][0m Trial 99 finished with value: 0.998456 and parameters: {'colsample_bytree': 0.8477305225166848, 'eta': 0.016148660851757944, 'max_depth': 3, 'n_estimators': 182, 'subsample': 0.97729362124961}. Best is trial 48 with value: 0.998395.[0m
[320]	train-rmse:0.99294	valid-rmse:0.99850
[03:00:50] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09560	valid-rmse:1.09880
[840]	train-rmse:1.09899	valid-rmse:1.10217
[180]	train-rmse:1.02300	valid-rmse:1.02641
[780]	train-rmse:0.96600	valid-rmse:0.99901
[140]	train-rmse:1.02647	valid-rmse:1.02994
[340]	train-rmse:0.99267	valid-rmse:0.99849
[20]	train-rmse:1.04595	valid-rmse:1.04935
[200]	train-rmse:1.01923	valid-rmse:1.02264
[160]	train-rmse:1.02157	valid-rmse:1.02504
[360]	train-rmse:0.99242	valid-rmse:0.99848
[40]	train-rmse:1.02080	valid-rmse:1.02421
[220]	train-rmse:1.01598	valid-rmse:1.01938
[180]	train-rmse:1.01744	valid-rmse:1.02091
[860]	train-rmse:1.09899	valid-rmse:1.10217
[800]	train-rmse:0.96522	valid-rmse:0.99898
[380]	train-rmse:0.99217	valid-rmse:0.99848
[60]	train-rmse:1.00821	valid-rmse:1.01157
[240]	train-rmse:1.01318	valid-rmse:1.01657
[200]	train-rmse:1.01398	valid-rmse:1.01743
[400]	train-rmse:0.99193	valid-rmse:0.99847
[80]	train-rmse:1.00183	valid-rmse:1.00522
[260]	train-rmse:1.01076	valid-rmse:1.01415
[220]	train-rmse:1.01106	valid-rmse:1.01449
[420]	train-rmse:0.99165	valid-rmse:0.99846
[100]	train-rmse:0.99853	valid-rmse:1.00202
[880]	train-rmse:1.09899	valid-rmse:1.10217
[280]	train-rmse:1.00868	valid-rmse:1.01205
[240]	train-rmse:1.00860	valid-rmse:1.01202
[820]	train-rmse:0.96462	valid-rmse:0.99895
[440]	train-rmse:0.99141	valid-rmse:0.99846
[120]	train-rmse:0.99678	valid-rmse:1.00041
[300]	train-rmse:1.00687	valid-rmse:1.01024
[260]	train-rmse:1.00655	valid-rmse:1.00994
[140]	train-rmse:0.99574	valid-rmse:0.99955
[460]	train-rmse:0.99115	valid-rmse:0.99846
[320]	train-rmse:1.00531	valid-rmse:1.00869
[280]	train-rmse:1.00478	valid-rmse:1.00819
[900]	train-rmse:1.09899	valid-rmse:1.10217
[840]	train-rmse:0.96391	valid-rmse:0.99893
[160]	train-rmse:0.99507	valid-rmse:0.99910
[480]	train-rmse:0.99089	valid-rmse:0.99847
[340]	train-rmse:1.00396	valid-rmse:1.00734
[300]	train-rmse:1.00331	valid-rmse:1.00671
[180]	train-rmse:0.99457	valid-rmse:0.99885
[500]	train-rmse:0.99064	valid-rmse:0.99848
[360]	train-rmse:1.00279	valid-rmse:1.00617
[320]	train-rmse:1.00205	valid-rmse:1.00546
[509]	train-rmse:0.99055	valid-rmse:0.99848
[32m[I 2022-04-17 03:11:06,734][0m Trial 100 finished with value: 0.998457 and parameters: {'colsample_bytree': 0.8324883582693274, 'eta': 0.015256587752254129, 'max_depth': 3, 'n_estimators': 130, 'subsample': 0.9971508223484419}. Best is trial 48 with value: 0.998395.[0m
[03:11:10] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09819	valid-rmse:1.10137
[200]	train-rmse:0.99417	valid-rmse:0.99871
[920]	train-rmse:1.09899	valid-rmse:1.10217
[380]	train-rmse:1.00178	valid-rmse:1.00516
[340]	train-rmse:1.00099	valid-rmse:1.00441
[860]	train-rmse:0.96326	valid-rmse:0.99891
[20]	train-rmse:1.08217	valid-rmse:1.08544
[220]	train-rmse:0.99380	valid-rmse:0.99863
[400]	train-rmse:1.00090	valid-rmse:1.00429
[360]	train-rmse:1.00008	valid-rmse:1.00352
[40]	train-rmse:1.06859	valid-rmse:1.07193
[240]	train-rmse:0.99348	valid-rmse:0.99857
[420]	train-rmse:1.00012	valid-rmse:1.00354
[380]	train-rmse:0.99932	valid-rmse:1.00277
[940]	train-rmse:1.09899	valid-rmse:1.10217
[60]	train-rmse:1.05712	valid-rmse:1.06049
[880]	train-rmse:0.96254	valid-rmse:0.99889
[260]	train-rmse:0.99317	valid-rmse:0.99854
[440]	train-rmse:0.99946	valid-rmse:1.00288
[400]	train-rmse:0.99866	valid-rmse:1.00213
[80]	train-rmse:1.04742	valid-rmse:1.05082
[460]	train-rmse:0.99888	valid-rmse:1.00232
[280]	train-rmse:0.99286	valid-rmse:0.99853
[420]	train-rmse:0.99809	valid-rmse:1.00160
[100]	train-rmse:1.03924	valid-rmse:1.04265
[960]	train-rmse:1.09899	valid-rmse:1.10217
[480]	train-rmse:0.99837	valid-rmse:1.00183
[300]	train-rmse:0.99254	valid-rmse:0.99851
[440]	train-rmse:0.99761	valid-rmse:1.00115
[900]	train-rmse:0.96187	valid-rmse:0.99888
[120]	train-rmse:1.03234	valid-rmse:1.03577
[500]	train-rmse:0.99792	valid-rmse:1.00141
[320]	train-rmse:0.99224	valid-rmse:0.99850
[460]	train-rmse:0.99718	valid-rmse:1.00076
[140]	train-rmse:1.02652	valid-rmse:1.02995
[520]	train-rmse:0.99752	valid-rmse:1.00104
[340]	train-rmse:0.99195	valid-rmse:0.99849
[480]	train-rmse:0.99681	valid-rmse:1.00043
[980]	train-rmse:1.09898	valid-rmse:1.10216
[160]	train-rmse:1.02162	valid-rmse:1.02503
[540]	train-rmse:0.99718	valid-rmse:1.00072
[920]	train-rmse:0.96123	valid-rmse:0.99886
[500]	train-rmse:0.99649	valid-rmse:1.00016
[360]	train-rmse:0.99165	valid-rmse:0.99850
[180]	train-rmse:1.01749	valid-rmse:1.02089
[560]	train-rmse:0.99687	valid-rmse:1.00044
[520]	train-rmse:0.99621	valid-rmse:0.99991
[380]	train-rmse:0.99136	valid-rmse:0.99850
[200]	train-rmse:1.01403	valid-rmse:1.01742
[999]	train-rmse:1.09898	valid-rmse:1.10216
[580]	train-rmse:0.99660	valid-rmse:1.00020
[32m[I 2022-04-17 03:22:17,500][0m Trial 88 finished with value: 1.102163 and parameters: {'colsample_bytree': 0.9625988610791189, 'eta': 3.9311754884145435e-07, 'max_depth': 7, 'n_estimators': 841, 'subsample': 0.8074397776110054}. Best is trial 48 with value: 0.998395.[0m
[540]	train-rmse:0.99596	valid-rmse:0.99972
[03:22:21] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[400]	train-rmse:0.99107	valid-rmse:0.99850
[0]	train-rmse:1.09826	valid-rmse:1.10144
[220]	train-rmse:1.01110	valid-rmse:1.01450
[940]	train-rmse:0.96049	valid-rmse:0.99884
[600]	train-rmse:0.99635	valid-rmse:0.99999
[560]	train-rmse:0.99574	valid-rmse:0.99954
[418]	train-rmse:0.99079	valid-rmse:0.99850
[32m[I 2022-04-17 03:23:22,150][0m Trial 104 finished with value: 0.998489 and parameters: {'colsample_bytree': 0.8354279332193445, 'eta': 0.017948480093832958, 'max_depth': 3, 'n_estimators': 115, 'subsample': 0.9970076159411958}. Best is trial 48 with value: 0.998395.[0m
[03:23:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09823	valid-rmse:1.10141
[20]	train-rmse:1.08342	valid-rmse:1.08669
[240]	train-rmse:1.00865	valid-rmse:1.01203
[620]	train-rmse:0.99612	valid-rmse:0.99980
[580]	train-rmse:0.99553	valid-rmse:0.99940
[20]	train-rmse:1.08295	valid-rmse:1.08622
[40]	train-rmse:1.07069	valid-rmse:1.07402
[260]	train-rmse:1.00657	valid-rmse:1.00995
[640]	train-rmse:0.99592	valid-rmse:0.99964
[600]	train-rmse:0.99536	valid-rmse:0.99928
[960]	train-rmse:0.95984	valid-rmse:0.99884
[40]	train-rmse:1.06988	valid-rmse:1.07322
[60]	train-rmse:1.05977	valid-rmse:1.06313
[280]	train-rmse:1.00481	valid-rmse:1.00820
[660]	train-rmse:0.99574	valid-rmse:0.99950
[620]	train-rmse:0.99518	valid-rmse:0.99916
[60]	train-rmse:1.05874	valid-rmse:1.06212
[80]	train-rmse:1.05041	valid-rmse:1.05381
[300]	train-rmse:1.00332	valid-rmse:1.00672
[680]	train-rmse:0.99558	valid-rmse:0.99937
[640]	train-rmse:0.99504	valid-rmse:0.99907
[80]	train-rmse:1.04925	valid-rmse:1.05266
[100]	train-rmse:1.04241	valid-rmse:1.04582
[320]	train-rmse:1.00206	valid-rmse:1.00547
[980]	train-rmse:0.95916	valid-rmse:0.99884
[700]	train-rmse:0.99543	valid-rmse:0.99927
[660]	train-rmse:0.99489	valid-rmse:0.99899
[100]	train-rmse:1.04117	valid-rmse:1.04461
[340]	train-rmse:1.00101	valid-rmse:1.00442
[120]	train-rmse:1.03556	valid-rmse:1.03898
[720]	train-rmse:0.99528	valid-rmse:0.99917
[680]	train-rmse:0.99476	valid-rmse:0.99891
[360]	train-rmse:1.00011	valid-rmse:1.00353
[120]	train-rmse:1.03430	valid-rmse:1.03775
[140]	train-rmse:1.02971	valid-rmse:1.03314
[740]	train-rmse:0.99514	valid-rmse:0.99909
[700]	train-rmse:0.99463	valid-rmse:0.99885
[999]	train-rmse:0.95857	valid-rmse:0.99884
[32m[I 2022-04-17 03:31:03,609][0m Trial 89 finished with value: 0.998835 and parameters: {'colsample_bytree': 0.965909936257697, 'eta': 0.004392682827875594, 'max_depth': 7, 'n_estimators': 839, 'subsample': 0.8153741859954279}. Best is trial 48 with value: 0.998395.[0m
[03:31:07] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09835	valid-rmse:1.10153
[380]	train-rmse:0.99934	valid-rmse:1.00279
[140]	train-rmse:1.02846	valid-rmse:1.03191
[160]	train-rmse:1.02470	valid-rmse:1.02813
[760]	train-rmse:0.99503	valid-rmse:0.99901
[720]	train-rmse:0.99453	valid-rmse:0.99880
[400]	train-rmse:0.99869	valid-rmse:1.00216
[20]	train-rmse:1.08502	valid-rmse:1.08828
[160]	train-rmse:1.02349	valid-rmse:1.02695
[180]	train-rmse:1.02043	valid-rmse:1.02385
[780]	train-rmse:0.99491	valid-rmse:0.99895
[740]	train-rmse:0.99442	valid-rmse:0.99875
[420]	train-rmse:0.99813	valid-rmse:1.00162
[40]	train-rmse:1.07337	valid-rmse:1.07669
[180]	train-rmse:1.01927	valid-rmse:1.02272
[200]	train-rmse:1.01679	valid-rmse:1.02020
[800]	train-rmse:0.99481	valid-rmse:0.99890
[760]	train-rmse:0.99431	valid-rmse:0.99872
[440]	train-rmse:0.99764	valid-rmse:1.00116
[60]	train-rmse:1.06321	valid-rmse:1.06657
[200]	train-rmse:1.01569	valid-rmse:1.01914
[820]	train-rmse:0.99470	valid-rmse:0.99885
[220]	train-rmse:1.01368	valid-rmse:1.01708
[780]	train-rmse:0.99421	valid-rmse:0.99868
[460]	train-rmse:0.99723	valid-rmse:1.00077
[80]	train-rmse:1.05436	valid-rmse:1.05776
[840]	train-rmse:0.99459	valid-rmse:0.99880
[220]	train-rmse:1.01265	valid-rmse:1.01608
[240]	train-rmse:1.01103	valid-rmse:1.01442
[800]	train-rmse:0.99412	valid-rmse:0.99865
[480]	train-rmse:0.99687	valid-rmse:1.00044
[100]	train-rmse:1.04665	valid-rmse:1.05008
[860]	train-rmse:0.99450	valid-rmse:0.99876
[240]	train-rmse:1.01006	valid-rmse:1.01349
[820]	train-rmse:0.99402	valid-rmse:0.99863
[260]	train-rmse:1.00876	valid-rmse:1.01215
[500]	train-rmse:0.99655	valid-rmse:1.00017
[880]	train-rmse:0.99441	valid-rmse:0.99873
[120]	train-rmse:1.03995	valid-rmse:1.04339
[840]	train-rmse:0.99391	valid-rmse:0.99861
[260]	train-rmse:1.00787	valid-rmse:1.01128
[280]	train-rmse:1.00682	valid-rmse:1.01020
[520]	train-rmse:0.99626	valid-rmse:0.99993
[900]	train-rmse:0.99432	valid-rmse:0.99869
[140]	train-rmse:1.03412	valid-rmse:1.03756
[860]	train-rmse:0.99382	valid-rmse:0.99859
[280]	train-rmse:1.00600	valid-rmse:1.00942
[300]	train-rmse:1.00516	valid-rmse:1.00855
[540]	train-rmse:0.99601	valid-rmse:0.99973
[920]	train-rmse:0.99423	valid-rmse:0.99868
[160]	train-rmse:1.02905	valid-rmse:1.03251
[880]	train-rmse:0.99373	valid-rmse:0.99857
[300]	train-rmse:1.00441	valid-rmse:1.00783
[320]	train-rmse:1.00374	valid-rmse:1.00713
[560]	train-rmse:0.99579	valid-rmse:0.99955
[940]	train-rmse:0.99415	valid-rmse:0.99865
[900]	train-rmse:0.99365	valid-rmse:0.99856
[180]	train-rmse:1.02464	valid-rmse:1.02809
[320]	train-rmse:1.00304	valid-rmse:1.00647
[340]	train-rmse:1.00253	valid-rmse:1.00591
[580]	train-rmse:0.99559	valid-rmse:0.99941
[960]	train-rmse:0.99408	valid-rmse:0.99863
[920]	train-rmse:0.99357	valid-rmse:0.99855
[200]	train-rmse:1.02081	valid-rmse:1.02427
[340]	train-rmse:1.00189	valid-rmse:1.00532
[360]	train-rmse:1.00148	valid-rmse:1.00487
[600]	train-rmse:0.99541	valid-rmse:0.99928
[980]	train-rmse:0.99400	valid-rmse:0.99861
[940]	train-rmse:0.99349	valid-rmse:0.99853
[220]	train-rmse:1.01749	valid-rmse:1.02093
[360]	train-rmse:1.00090	valid-rmse:1.00433
[620]	train-rmse:0.99525	valid-rmse:0.99917
[380]	train-rmse:1.00059	valid-rmse:1.00398
[999]	train-rmse:0.99392	valid-rmse:0.99859
[32m[I 2022-04-17 03:44:22,606][0m Trial 102 finished with value: 0.99859 and parameters: {'colsample_bytree': 0.8326420893083085, 'eta': 0.0038536662782712454, 'max_depth': 3, 'n_estimators': 135, 'subsample': 0.997738980306797}. Best is trial 48 with value: 0.998395.[0m
[03:44:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09644	valid-rmse:1.09964
[960]	train-rmse:0.99340	valid-rmse:0.99852
[240]	train-rmse:1.01460	valid-rmse:1.01803
[640]	train-rmse:0.99509	valid-rmse:0.99909
[380]	train-rmse:1.00005	valid-rmse:1.00349
[400]	train-rmse:0.99981	valid-rmse:1.00321
[20]	train-rmse:1.05583	valid-rmse:1.05922
[980]	train-rmse:0.99333	valid-rmse:0.99852
[260]	train-rmse:1.01210	valid-rmse:1.01552
[660]	train-rmse:0.99496	valid-rmse:0.99900
[400]	train-rmse:0.99932	valid-rmse:1.00278
[420]	train-rmse:0.99913	valid-rmse:1.00257
[999]	train-rmse:0.99324	valid-rmse:0.99851
[32m[I 2022-04-17 03:46:42,933][0m Trial 103 finished with value: 0.998508 and parameters: {'colsample_bytree': 0.8440302821284009, 'eta': 0.004503894142428696, 'max_depth': 3, 'n_estimators': 391, 'subsample': 0.9762821635137916}. Best is trial 48 with value: 0.998395.[0m
[40]	train-rmse:1.03141	valid-rmse:1.03486
[03:46:47] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09487	valid-rmse:1.09807
[680]	train-rmse:0.99483	valid-rmse:0.99893
[280]	train-rmse:1.00991	valid-rmse:1.01334
[420]	train-rmse:0.99869	valid-rmse:1.00218
[440]	train-rmse:0.99855	valid-rmse:1.00201
[60]	train-rmse:1.01686	valid-rmse:1.02030
[20]	train-rmse:1.03869	valid-rmse:1.04215
[700]	train-rmse:0.99471	valid-rmse:0.99887
[300]	train-rmse:1.00802	valid-rmse:1.01144
[440]	train-rmse:0.99814	valid-rmse:1.00166
[460]	train-rmse:0.99806	valid-rmse:1.00153
[80]	train-rmse:1.00820	valid-rmse:1.01160
[40]	train-rmse:1.01416	valid-rmse:1.01763
[720]	train-rmse:0.99458	valid-rmse:0.99882
[320]	train-rmse:1.00636	valid-rmse:1.00978
[460]	train-rmse:0.99768	valid-rmse:1.00121
[480]	train-rmse:0.99762	valid-rmse:1.00112
[100]	train-rmse:1.00301	valid-rmse:1.00645
[740]	train-rmse:0.99447	valid-rmse:0.99878
[60]	train-rmse:1.00357	valid-rmse:1.00697
[340]	train-rmse:1.00494	valid-rmse:1.00835
[480]	train-rmse:0.99725	valid-rmse:1.00084
[500]	train-rmse:0.99723	valid-rmse:1.00077
[120]	train-rmse:0.99991	valid-rmse:1.00334
[760]	train-rmse:0.99437	valid-rmse:0.99874
[80]	train-rmse:0.99882	valid-rmse:1.00234
[360]	train-rmse:1.00368	valid-rmse:1.00710
[500]	train-rmse:0.99689	valid-rmse:1.00052
[520]	train-rmse:0.99689	valid-rmse:1.00046
[140]	train-rmse:0.99794	valid-rmse:1.00147
[780]	train-rmse:0.99428	valid-rmse:0.99870
[100]	train-rmse:0.99658	valid-rmse:1.00030
[380]	train-rmse:1.00259	valid-rmse:1.00601
[520]	train-rmse:0.99658	valid-rmse:1.00024
[540]	train-rmse:0.99660	valid-rmse:1.00020
[800]	train-rmse:0.99418	valid-rmse:0.99867
[160]	train-rmse:0.99668	valid-rmse:1.00036
[120]	train-rmse:0.99545	valid-rmse:0.99936
[400]	train-rmse:1.00164	valid-rmse:1.00507
[540]	train-rmse:0.99630	valid-rmse:1.00001
[560]	train-rmse:0.99633	valid-rmse:0.99997
[820]	train-rmse:0.99409	valid-rmse:0.99864
[180]	train-rmse:0.99587	valid-rmse:0.99967
[140]	train-rmse:0.99469	valid-rmse:0.99893
[420]	train-rmse:1.00080	valid-rmse:1.00424
[560]	train-rmse:0.99605	valid-rmse:0.99980
[580]	train-rmse:0.99609	valid-rmse:0.99978
[840]	train-rmse:0.99399	valid-rmse:0.99862
[200]	train-rmse:0.99528	valid-rmse:0.99925
[160]	train-rmse:0.99415	valid-rmse:0.99870
[440]	train-rmse:1.00007	valid-rmse:1.00353
[580]	train-rmse:0.99583	valid-rmse:0.99962
[600]	train-rmse:0.99587	valid-rmse:0.99961
[860]	train-rmse:0.99391	valid-rmse:0.99860
[220]	train-rmse:0.99484	valid-rmse:0.99897
[180]	train-rmse:0.99370	valid-rmse:0.99860
[460]	train-rmse:0.99943	valid-rmse:1.00290
[600]	train-rmse:0.99562	valid-rmse:0.99947
[620]	train-rmse:0.99569	valid-rmse:0.99946
[880]	train-rmse:0.99382	valid-rmse:0.99858
[240]	train-rmse:0.99448	valid-rmse:0.99879
[200]	train-rmse:0.99330	valid-rmse:0.99853
[480]	train-rmse:0.99886	valid-rmse:1.00236
[620]	train-rmse:0.99543	valid-rmse:0.99935
[640]	train-rmse:0.99551	valid-rmse:0.99934
[900]	train-rmse:0.99373	valid-rmse:0.99856
[260]	train-rmse:0.99419	valid-rmse:0.99868
[220]	train-rmse:0.99291	valid-rmse:0.99850
[500]	train-rmse:0.99836	valid-rmse:1.00189
[640]	train-rmse:0.99526	valid-rmse:0.99923
[660]	train-rmse:0.99535	valid-rmse:0.99923
[920]	train-rmse:0.99364	valid-rmse:0.99855
[280]	train-rmse:0.99390	valid-rmse:0.99859
[240]	train-rmse:0.99255	valid-rmse:0.99849
[520]	train-rmse:0.99793	valid-rmse:1.00147
[660]	train-rmse:0.99510	valid-rmse:0.99913
[680]	train-rmse:0.99521	valid-rmse:0.99913
[940]	train-rmse:0.99356	valid-rmse:0.99854
[300]	train-rmse:0.99360	valid-rmse:0.99853
[260]	train-rmse:0.99220	valid-rmse:0.99847
[540]	train-rmse:0.99754	valid-rmse:1.00111
[680]	train-rmse:0.99497	valid-rmse:0.99905
[960]	train-rmse:0.99348	valid-rmse:0.99853
[700]	train-rmse:0.99507	valid-rmse:0.99905
[320]	train-rmse:0.99335	valid-rmse:0.99850
[280]	train-rmse:0.99179	valid-rmse:0.99846
[560]	train-rmse:0.99719	valid-rmse:1.00079
[700]	train-rmse:0.99484	valid-rmse:0.99897
[980]	train-rmse:0.99340	valid-rmse:0.99852
[720]	train-rmse:0.99494	valid-rmse:0.99898
[340]	train-rmse:0.99306	valid-rmse:0.99847
[300]	train-rmse:0.99146	valid-rmse:0.99845
[580]	train-rmse:0.99688	valid-rmse:1.00052
[999]	train-rmse:0.99333	valid-rmse:0.99851
[32m[I 2022-04-17 04:04:08,035][0m Trial 105 finished with value: 0.998511 and parameters: {'colsample_bytree': 0.832729595859015, 'eta': 0.004498727920290569, 'max_depth': 3, 'n_estimators': 133, 'subsample': 0.9990679868645642}. Best is trial 48 with value: 0.998395.[0m
[720]	train-rmse:0.99472	valid-rmse:0.99891
[04:04:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09475	valid-rmse:1.09795
[740]	train-rmse:0.99482	valid-rmse:0.99891
[360]	train-rmse:0.99284	valid-rmse:0.99846
[320]	train-rmse:0.99106	valid-rmse:0.99846
[600]	train-rmse:0.99661	valid-rmse:1.00028
[740]	train-rmse:0.99461	valid-rmse:0.99885
[20]	train-rmse:1.03754	valid-rmse:1.04098
[760]	train-rmse:0.99471	valid-rmse:0.99886
[380]	train-rmse:0.99260	valid-rmse:0.99844
[340]	train-rmse:0.99070	valid-rmse:0.99846
[620]	train-rmse:0.99635	valid-rmse:1.00006
[760]	train-rmse:0.99451	valid-rmse:0.99880
[344]	train-rmse:0.99062	valid-rmse:0.99846
[32m[I 2022-04-17 04:06:30,277][0m Trial 110 finished with value: 0.998436 and parameters: {'colsample_bytree': 0.9054689697352344, 'eta': 0.021754913053207953, 'max_depth': 3, 'n_estimators': 158, 'subsample': 0.981482969562427}. Best is trial 48 with value: 0.998395.[0m
[40]	train-rmse:1.01320	valid-rmse:1.01668
[780]	train-rmse:0.99461	valid-rmse:0.99881
[04:06:34] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09674	valid-rmse:1.09993
[400]	train-rmse:0.99236	valid-rmse:0.99845
[640]	train-rmse:0.99613	valid-rmse:0.99988
[780]	train-rmse:0.99440	valid-rmse:0.99875
[60]	train-rmse:1.00293	valid-rmse:1.00637
[800]	train-rmse:0.99450	valid-rmse:0.99876
[20]	train-rmse:1.05968	valid-rmse:1.06306
[420]	train-rmse:0.99213	valid-rmse:0.99846
[660]	train-rmse:0.99593	valid-rmse:0.99971
[800]	train-rmse:0.99430	valid-rmse:0.99872
[80]	train-rmse:0.99845	valid-rmse:1.00200
[820]	train-rmse:0.99440	valid-rmse:0.99873
[40]	train-rmse:1.03605	valid-rmse:1.03947
[440]	train-rmse:0.99191	valid-rmse:0.99845
[32m[I 2022-04-17 04:09:26,386][0m Trial 109 finished with value: 0.998441 and parameters: {'colsample_bytree': 0.9077666626632006, 'eta': 0.013534666927636165, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.9760535834581956}. Best is trial 48 with value: 0.998395.[0m
[04:09:30] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09677	valid-rmse:1.09996
[680]	train-rmse:0.99575	valid-rmse:0.99957
[820]	train-rmse:0.99420	valid-rmse:0.99868
[100]	train-rmse:0.99636	valid-rmse:1.00013
[840]	train-rmse:0.99430	valid-rmse:0.99869
[60]	train-rmse:1.02109	valid-rmse:1.02452
[20]	train-rmse:1.06001	valid-rmse:1.06340
[700]	train-rmse:0.99558	valid-rmse:0.99944
[840]	train-rmse:0.99410	valid-rmse:0.99866
[120]	train-rmse:0.99530	valid-rmse:0.99929
[860]	train-rmse:0.99421	valid-rmse:0.99865
[80]	train-rmse:1.01165	valid-rmse:1.01504
[40]	train-rmse:1.03647	valid-rmse:1.03991
[720]	train-rmse:0.99543	valid-rmse:0.99933
[860]	train-rmse:0.99399	valid-rmse:0.99864
[140]	train-rmse:0.99460	valid-rmse:0.99889
[880]	train-rmse:0.99412	valid-rmse:0.99863
[100]	train-rmse:1.00568	valid-rmse:1.00910
[60]	train-rmse:1.02148	valid-rmse:1.02493
[740]	train-rmse:0.99529	valid-rmse:0.99923
[880]	train-rmse:0.99391	valid-rmse:0.99862
[160]	train-rmse:0.99406	valid-rmse:0.99869
[900]	train-rmse:0.99403	valid-rmse:0.99861
[120]	train-rmse:1.00190	valid-rmse:1.00531
[80]	train-rmse:1.01197	valid-rmse:1.01540
[760]	train-rmse:0.99516	valid-rmse:0.99914
[900]	train-rmse:0.99383	valid-rmse:0.99860
[180]	train-rmse:0.99360	valid-rmse:0.99860
[920]	train-rmse:0.99394	valid-rmse:0.99859
[140]	train-rmse:0.99944	valid-rmse:1.00292
[100]	train-rmse:1.00593	valid-rmse:1.00938
[780]	train-rmse:0.99504	valid-rmse:0.99907
[920]	train-rmse:0.99374	valid-rmse:0.99858
[200]	train-rmse:0.99315	valid-rmse:0.99855
[940]	train-rmse:0.99386	valid-rmse:0.99857
[160]	train-rmse:0.99781	valid-rmse:1.00140
[120]	train-rmse:1.00208	valid-rmse:1.00553
[800]	train-rmse:0.99492	valid-rmse:0.99900
[940]	train-rmse:0.99366	valid-rmse:0.99857
[220]	train-rmse:0.99278	valid-rmse:0.99852
[180]	train-rmse:0.99674	valid-rmse:1.00042
[960]	train-rmse:0.99379	valid-rmse:0.99856
[140]	train-rmse:0.99957	valid-rmse:1.00306
[820]	train-rmse:0.99481	valid-rmse:0.99894
[960]	train-rmse:0.99358	valid-rmse:0.99855
[240]	train-rmse:0.99243	valid-rmse:0.99851
[200]	train-rmse:0.99598	valid-rmse:0.99979
[980]	train-rmse:0.99371	valid-rmse:0.99854
[160]	train-rmse:0.99790	valid-rmse:1.00151
[840]	train-rmse:0.99470	valid-rmse:0.99889
[980]	train-rmse:0.99350	valid-rmse:0.99854
[220]	train-rmse:0.99542	valid-rmse:0.99939
[999]	train-rmse:0.99364	valid-rmse:0.99853
[260]	train-rmse:0.99211	valid-rmse:0.99850
[32m[I 2022-04-17 04:19:07,195][0m Trial 106 finished with value: 0.998528 and parameters: {'colsample_bytree': 0.9018221356946151, 'eta': 0.0041356456727527965, 'max_depth': 3, 'n_estimators': 132, 'subsample': 0.9974578817277703}. Best is trial 48 with value: 0.998395.[0m
[04:19:11] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09500	valid-rmse:1.09821
[180]	train-rmse:0.99681	valid-rmse:1.00050
[860]	train-rmse:0.99460	valid-rmse:0.99885
[999]	train-rmse:0.99341	valid-rmse:0.99853
[32m[I 2022-04-17 04:20:02,694][0m Trial 107 finished with value: 0.998533 and parameters: {'colsample_bytree': 0.9088448918555672, 'eta': 0.0042730882616288345, 'max_depth': 3, 'n_estimators': 157, 'subsample': 0.9810673816144599}. Best is trial 48 with value: 0.998395.[0m
[04:20:06] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[240]	train-rmse:0.99500	valid-rmse:0.99912
[0]	train-rmse:1.09651	valid-rmse:1.09971
[280]	train-rmse:0.99170	valid-rmse:0.99849
[20]	train-rmse:1.03993	valid-rmse:1.04337
[200]	train-rmse:0.99603	valid-rmse:0.99985
[880]	train-rmse:0.99450	valid-rmse:0.99881
[20]	train-rmse:1.05652	valid-rmse:1.05991
[260]	train-rmse:0.99467	valid-rmse:0.99893
[300]	train-rmse:0.99132	valid-rmse:0.99847
[40]	train-rmse:1.01522	valid-rmse:1.01868
[220]	train-rmse:0.99545	valid-rmse:0.99942
[900]	train-rmse:0.99442	valid-rmse:0.99878
[40]	train-rmse:1.03222	valid-rmse:1.03570
[280]	train-rmse:0.99434	valid-rmse:0.99880
[60]	train-rmse:1.00425	valid-rmse:1.00766
[320]	train-rmse:0.99091	valid-rmse:0.99848
[240]	train-rmse:0.99503	valid-rmse:0.99913
[920]	train-rmse:0.99433	valid-rmse:0.99874
[60]	train-rmse:1.01758	valid-rmse:1.02103
[80]	train-rmse:0.99923	valid-rmse:1.00274
[300]	train-rmse:0.99406	valid-rmse:0.99870
[340]	train-rmse:0.99052	valid-rmse:0.99849
[351]	train-rmse:0.99031	valid-rmse:0.99850
[32m[I 2022-04-17 04:24:19,876][0m Trial 111 finished with value: 0.99847 and parameters: {'colsample_bytree': 0.9088327701561879, 'eta': 0.022416792674356745, 'max_depth': 3, 'n_estimators': 186, 'subsample': 0.9788446809789274}. Best is trial 48 with value: 0.998395.[0m
[260]	train-rmse:0.99472	valid-rmse:0.99894
[940]	train-rmse:0.99425	valid-rmse:0.99872
[04:24:24] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:1.00876	valid-rmse:1.01221
[0]	train-rmse:1.09660	valid-rmse:1.09980
[100]	train-rmse:0.99685	valid-rmse:1.00052
[320]	train-rmse:0.99381	valid-rmse:0.99864
[280]	train-rmse:0.99439	valid-rmse:0.99880
[100]	train-rmse:1.00343	valid-rmse:1.00691
[960]	train-rmse:0.99417	valid-rmse:0.99868
[20]	train-rmse:1.05772	valid-rmse:1.06111
[120]	train-rmse:0.99561	valid-rmse:0.99948
[340]	train-rmse:0.99355	valid-rmse:0.99859
[120]	train-rmse:1.00017	valid-rmse:1.00368
[300]	train-rmse:0.99409	valid-rmse:0.99870
[40]	train-rmse:1.03366	valid-rmse:1.03713
[980]	train-rmse:0.99409	valid-rmse:0.99866
[140]	train-rmse:0.99486	valid-rmse:0.99898
[360]	train-rmse:0.99333	valid-rmse:0.99856
[140]	train-rmse:0.99814	valid-rmse:1.00174
[60]	train-rmse:1.01887	valid-rmse:1.02235
[999]	train-rmse:0.99401	valid-rmse:0.99865
[32m[I 2022-04-17 04:27:44,169][0m Trial 108 finished with value: 0.998645 and parameters: {'colsample_bytree': 0.9094555849812863, 'eta': 0.0036852027615267577, 'max_depth': 3, 'n_estimators': 169, 'subsample': 0.9796925482986081}. Best is trial 48 with value: 0.998395.[0m
[320]	train-rmse:0.99384	valid-rmse:0.99864
[04:27:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[160]	train-rmse:0.99427	valid-rmse:0.99872
[0]	train-rmse:1.09661	valid-rmse:1.09981
[380]	train-rmse:0.99313	valid-rmse:0.99854
[160]	train-rmse:0.99683	valid-rmse:1.00054
[80]	train-rmse:1.00981	valid-rmse:1.01326
[340]	train-rmse:0.99359	valid-rmse:0.99859
[20]	train-rmse:1.05791	valid-rmse:1.06130
[180]	train-rmse:0.99381	valid-rmse:0.99861
[400]	train-rmse:0.99291	valid-rmse:0.99852
[180]	train-rmse:0.99596	valid-rmse:0.99980
[100]	train-rmse:1.00422	valid-rmse:1.00771
[40]	train-rmse:1.03388	valid-rmse:1.03733
[360]	train-rmse:0.99338	valid-rmse:0.99857
[200]	train-rmse:0.99340	valid-rmse:0.99853
[420]	train-rmse:0.99269	valid-rmse:0.99851
[200]	train-rmse:0.99535	valid-rmse:0.99934
[120]	train-rmse:1.00078	valid-rmse:1.00427
[60]	train-rmse:1.01907	valid-rmse:1.02255
[380]	train-rmse:0.99315	valid-rmse:0.99854
[220]	train-rmse:0.99305	valid-rmse:0.99849
[440]	train-rmse:0.99248	valid-rmse:0.99850
[220]	train-rmse:0.99491	valid-rmse:0.99906
[140]	train-rmse:0.99859	valid-rmse:1.00216
[80]	train-rmse:1.00998	valid-rmse:1.01344
[240]	train-rmse:0.99268	valid-rmse:0.99847
[400]	train-rmse:0.99293	valid-rmse:0.99853
[460]	train-rmse:0.99228	valid-rmse:0.99849
[240]	train-rmse:0.99455	valid-rmse:0.99888
[160]	train-rmse:0.99718	valid-rmse:1.00084
[100]	train-rmse:1.00437	valid-rmse:1.00786
[260]	train-rmse:0.99235	valid-rmse:0.99845
[420]	train-rmse:0.99272	valid-rmse:0.99852
[260]	train-rmse:0.99427	valid-rmse:0.99876
[480]	train-rmse:0.99207	valid-rmse:0.99849
[180]	train-rmse:0.99623	valid-rmse:1.00001
[120]	train-rmse:1.00087	valid-rmse:1.00438
[280]	train-rmse:0.99197	valid-rmse:0.99846
[440]	train-rmse:0.99252	valid-rmse:0.99851
[280]	train-rmse:0.99401	valid-rmse:0.99867
[200]	train-rmse:0.99556	valid-rmse:0.99951
[500]	train-rmse:0.99186	valid-rmse:0.99848
[140]	train-rmse:0.99866	valid-rmse:1.00224
[300]	train-rmse:0.99160	valid-rmse:0.99845
[460]	train-rmse:0.99230	valid-rmse:0.99850
[300]	train-rmse:0.99369	valid-rmse:0.99861
[220]	train-rmse:0.99508	valid-rmse:0.99918
[520]	train-rmse:0.99169	valid-rmse:0.99848
[160]	train-rmse:0.99724	valid-rmse:1.00090
[320]	train-rmse:0.99124	valid-rmse:0.99847
[480]	train-rmse:0.99209	valid-rmse:0.99849
[320]	train-rmse:0.99343	valid-rmse:0.99857
[240]	train-rmse:0.99471	valid-rmse:0.99896
[180]	train-rmse:0.99629	valid-rmse:1.00007
[540]	train-rmse:0.99148	valid-rmse:0.99850
[339]	train-rmse:0.99089	valid-rmse:0.99847
[32m[I 2022-04-17 04:37:43,736][0m Trial 114 finished with value: 0.998438 and parameters: {'colsample_bytree': 0.864237059455353, 'eta': 0.021065588450337423, 'max_depth': 3, 'n_estimators': 257, 'subsample': 0.9761320184915492}. Best is trial 48 with value: 0.998395.[0m
[04:37:47] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09684	valid-rmse:1.10003
[500]	train-rmse:0.99188	valid-rmse:0.99850
[340]	train-rmse:0.99316	valid-rmse:0.99855
[260]	train-rmse:0.99441	valid-rmse:0.99882
[200]	train-rmse:0.99561	valid-rmse:0.99954
[558]	train-rmse:0.99129	valid-rmse:0.99849
[32m[I 2022-04-17 04:38:27,654][0m Trial 112 finished with value: 0.998478 and parameters: {'colsample_bytree': 0.9105642790788424, 'eta': 0.012002371932312064, 'max_depth': 3, 'n_estimators': 189, 'subsample': 0.9806340948427654}. Best is trial 48 with value: 0.998395.[0m
[04:38:31] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08850	valid-rmse:1.09176
[20]	train-rmse:1.06094	valid-rmse:1.06431
[360]	train-rmse:0.99291	valid-rmse:0.99853
[520]	train-rmse:0.99170	valid-rmse:0.99849
[280]	train-rmse:0.99413	valid-rmse:0.99871
[220]	train-rmse:0.99512	valid-rmse:0.99920
[20]	train-rmse:1.00603	valid-rmse:1.00945
[40]	train-rmse:1.03762	valid-rmse:1.04106
[380]	train-rmse:0.99267	valid-rmse:0.99852
[300]	train-rmse:0.99382	valid-rmse:0.99865
[540]	train-rmse:0.99147	valid-rmse:0.99850
[240]	train-rmse:0.99473	valid-rmse:0.99897
[40]	train-rmse:0.99614	valid-rmse:1.00002
[60]	train-rmse:1.02257	valid-rmse:1.02604
[400]	train-rmse:0.99244	valid-rmse:0.99850
[320]	train-rmse:0.99357	valid-rmse:0.99860
[260]	train-rmse:0.99445	valid-rmse:0.99883
[560]	train-rmse:0.99128	valid-rmse:0.99850
[60]	train-rmse:0.99424	valid-rmse:0.99881
[80]	train-rmse:1.01290	valid-rmse:1.01636
[420]	train-rmse:0.99219	valid-rmse:0.99849
[340]	train-rmse:0.99332	valid-rmse:0.99858
[280]	train-rmse:0.99416	valid-rmse:0.99873
[578]	train-rmse:0.99110	valid-rmse:0.99850
[32m[I 2022-04-17 04:42:36,753][0m Trial 113 finished with value: 0.99849 and parameters: {'colsample_bytree': 0.911502925974628, 'eta': 0.011869837490032587, 'max_depth': 3, 'n_estimators': 192, 'subsample': 0.9772810495783424}. Best is trial 48 with value: 0.998395.[0m
[04:42:40] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08968	valid-rmse:1.09293
[80]	train-rmse:0.99315	valid-rmse:0.99865
[100]	train-rmse:1.00666	valid-rmse:1.01015
[440]	train-rmse:0.99197	valid-rmse:0.99849
[360]	train-rmse:0.99308	valid-rmse:0.99855
[300]	train-rmse:0.99386	valid-rmse:0.99866
[20]	train-rmse:1.00930	valid-rmse:1.01276
[100]	train-rmse:0.99210	valid-rmse:0.99857
[120]	train-rmse:1.00262	valid-rmse:1.00612
[460]	train-rmse:0.99177	valid-rmse:0.99849
[380]	train-rmse:0.99286	valid-rmse:0.99853
[320]	train-rmse:0.99361	valid-rmse:0.99862
[40]	train-rmse:0.99718	valid-rmse:1.00093
[120]	train-rmse:0.99113	valid-rmse:0.99861
[473]	train-rmse:0.99161	valid-rmse:0.99850
[32m[I 2022-04-17 04:45:13,480][0m Trial 115 finished with value: 0.998485 and parameters: {'colsample_bytree': 0.8537400463801017, 'eta': 0.013258045167978606, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.9553065433772585}. Best is trial 48 with value: 0.998395.[0m
[140]	train-rmse:0.99999	valid-rmse:1.00354
[04:45:17] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08930	valid-rmse:1.09256
[400]	train-rmse:0.99263	valid-rmse:0.99852
[340]	train-rmse:0.99335	valid-rmse:0.99858
[60]	train-rmse:0.99472	valid-rmse:0.99902
[140]	train-rmse:0.99020	valid-rmse:0.99859
[160]	train-rmse:0.99825	valid-rmse:1.00185
[20]	train-rmse:1.00812	valid-rmse:1.01159
[420]	train-rmse:0.99240	valid-rmse:0.99850
[152]	train-rmse:0.98967	valid-rmse:0.99859
[32m[I 2022-04-17 04:46:49,309][0m Trial 119 finished with value: 0.998553 and parameters: {'colsample_bytree': 0.861891861752015, 'eta': 0.05570307281432461, 'max_depth': 3, 'n_estimators': 255, 'subsample': 0.954246530806525}. Best is trial 48 with value: 0.998395.[0m
[360]	train-rmse:0.99310	valid-rmse:0.99856
[04:46:53] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:0.99358	valid-rmse:0.99867
[0]	train-rmse:1.09445	valid-rmse:1.09766
[180]	train-rmse:0.99705	valid-rmse:1.00076
[40]	train-rmse:0.99687	valid-rmse:1.00051
[440]	train-rmse:0.99217	valid-rmse:0.99850
[380]	train-rmse:0.99287	valid-rmse:0.99853
[100]	train-rmse:0.99267	valid-rmse:0.99856
[20]	train-rmse:1.03490	valid-rmse:1.03837
[200]	train-rmse:0.99621	valid-rmse:1.00005
[60]	train-rmse:0.99460	valid-rmse:0.99889
[460]	train-rmse:0.99194	valid-rmse:0.99849
[400]	train-rmse:0.99264	valid-rmse:0.99851
[120]	train-rmse:0.99171	valid-rmse:0.99864
[40]	train-rmse:1.01108	valid-rmse:1.01461
[220]	train-rmse:0.99562	valid-rmse:0.99957
[80]	train-rmse:0.99354	valid-rmse:0.99861
[480]	train-rmse:0.99172	valid-rmse:0.99849
[420]	train-rmse:0.99242	valid-rmse:0.99849
[140]	train-rmse:0.99082	valid-rmse:0.99867
[60]	train-rmse:1.00161	valid-rmse:1.00512
[240]	train-rmse:0.99515	valid-rmse:0.99925
[100]	train-rmse:0.99252	valid-rmse:0.99853
[153]	train-rmse:0.99038	valid-rmse:0.99868
[32m[I 2022-04-17 04:50:54,690][0m Trial 120 finished with value: 0.998549 and parameters: {'colsample_bytree': 0.872589446644262, 'eta': 0.049318196107538806, 'max_depth': 3, 'n_estimators': 224, 'subsample': 0.902275881218962}. Best is trial 48 with value: 0.998395.[0m
[500]	train-rmse:0.99148	valid-rmse:0.99848
[04:50:58] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[440]	train-rmse:0.99220	valid-rmse:0.99849
[0]	train-rmse:1.09489	valid-rmse:1.09811
[80]	train-rmse:0.99770	valid-rmse:1.00131
[260]	train-rmse:0.99482	valid-rmse:0.99904
[120]	train-rmse:0.99158	valid-rmse:0.99857
[520]	train-rmse:0.99127	valid-rmse:0.99849
[460]	train-rmse:0.99199	valid-rmse:0.99849
[20]	train-rmse:1.03884	valid-rmse:1.04233
[100]	train-rmse:0.99589	valid-rmse:0.99977
[280]	train-rmse:0.99451	valid-rmse:0.99889
[140]	train-rmse:0.99072	valid-rmse:0.99866
[40]	train-rmse:1.01429	valid-rmse:1.01782
[540]	train-rmse:0.99106	valid-rmse:0.99850
[479]	train-rmse:0.99179	valid-rmse:0.99849
[32m[I 2022-04-17 04:53:10,878][0m Trial 117 finished with value: 0.998485 and parameters: {'colsample_bytree': 0.8606303102810513, 'eta': 0.01269879765492121, 'max_depth': 3, 'n_estimators': 254, 'subsample': 0.9511750082830448}. Best is trial 48 with value: 0.998395.[0m
[04:53:15] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09431	valid-rmse:1.09753
[150]	train-rmse:0.99024	valid-rmse:0.99868
[32m[I 2022-04-17 04:53:21,623][0m Trial 121 finished with value: 0.99853 and parameters: {'colsample_bytree': 0.8621608559901863, 'eta': 0.051404514089689796, 'max_depth': 3, 'n_estimators': 255, 'subsample': 0.9308773262426107}. Best is trial 48 with value: 0.998395.[0m
[04:53:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[120]	train-rmse:0.99488	valid-rmse:0.99910
[0]	train-rmse:1.09531	valid-rmse:1.09853
[300]	train-rmse:0.99421	valid-rmse:0.99879
[556]	train-rmse:0.99088	valid-rmse:0.99849
[32m[I 2022-04-17 04:53:57,889][0m Trial 116 finished with value: 0.998481 and parameters: {'colsample_bytree': 0.8560504096961885, 'eta': 0.012772637827485339, 'max_depth': 3, 'n_estimators': 245, 'subsample': 0.9561542706478211}. Best is trial 48 with value: 0.998395.[0m
[04:54:02] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.00360	valid-rmse:1.00711
[0]	train-rmse:1.09765	valid-rmse:1.10084
[20]	train-rmse:1.04264	valid-rmse:1.04613
[20]	train-rmse:1.03369	valid-rmse:1.03714
[140]	train-rmse:0.99422	valid-rmse:0.99882
[320]	train-rmse:0.99397	valid-rmse:0.99871
[80]	train-rmse:0.99885	valid-rmse:1.00247
[20]	train-rmse:1.07302	valid-rmse:1.07635
[40]	train-rmse:1.01768	valid-rmse:1.02118
[40]	train-rmse:1.01018	valid-rmse:1.01367
[160]	train-rmse:0.99367	valid-rmse:0.99869
[340]	train-rmse:0.99372	valid-rmse:0.99866
[60]	train-rmse:1.00586	valid-rmse:1.00934
[100]	train-rmse:0.99659	valid-rmse:1.00042
[40]	train-rmse:1.05424	valid-rmse:1.05764
[60]	train-rmse:1.00107	valid-rmse:1.00454
[180]	train-rmse:0.99319	valid-rmse:0.99857
[80]	train-rmse:1.00027	valid-rmse:1.00383
[360]	train-rmse:0.99350	valid-rmse:0.99862
[120]	train-rmse:0.99540	valid-rmse:0.99946
[60]	train-rmse:1.03995	valid-rmse:1.04339
[80]	train-rmse:0.99739	valid-rmse:1.00102
[100]	train-rmse:0.99748	valid-rmse:1.00119
[200]	train-rmse:0.99272	valid-rmse:0.99853
[380]	train-rmse:0.99327	valid-rmse:0.99857
[140]	train-rmse:0.99467	valid-rmse:0.99902
[80]	train-rmse:1.02912	valid-rmse:1.03257
[100]	train-rmse:0.99569	valid-rmse:0.99962
[120]	train-rmse:0.99598	valid-rmse:0.99991
[220]	train-rmse:0.99237	valid-rmse:0.99852
[400]	train-rmse:0.99306	valid-rmse:0.99855
[160]	train-rmse:0.99410	valid-rmse:0.99883
[100]	train-rmse:1.02093	valid-rmse:1.02440
[140]	train-rmse:0.99508	valid-rmse:0.99927
[120]	train-rmse:0.99474	valid-rmse:0.99907
[240]	train-rmse:0.99195	valid-rmse:0.99851
[180]	train-rmse:0.99362	valid-rmse:0.99871
[420]	train-rmse:0.99284	valid-rmse:0.99853
[160]	train-rmse:0.99446	valid-rmse:0.99892
[120]	train-rmse:1.01473	valid-rmse:1.01821
[140]	train-rmse:0.99411	valid-rmse:0.99882
[180]	train-rmse:0.99394	valid-rmse:0.99874
[260]	train-rmse:0.99158	valid-rmse:0.99850
[200]	train-rmse:0.99317	valid-rmse:0.99865
[140]	train-rmse:1.01003	valid-rmse:1.01349
[440]	train-rmse:0.99264	valid-rmse:0.99852
[160]	train-rmse:0.99352	valid-rmse:0.99873
[200]	train-rmse:0.99348	valid-rmse:0.99864
[280]	train-rmse:0.99117	valid-rmse:0.99848
[220]	train-rmse:0.99281	valid-rmse:0.99861
[160]	train-rmse:1.00647	valid-rmse:1.00992
[460]	train-rmse:0.99243	valid-rmse:0.99851
[180]	train-rmse:0.99304	valid-rmse:0.99864
[220]	train-rmse:0.99308	valid-rmse:0.99860
[240]	train-rmse:0.99241	valid-rmse:0.99857
[180]	train-rmse:1.00375	valid-rmse:1.00722
[300]	train-rmse:0.99074	valid-rmse:0.99847
[480]	train-rmse:0.99224	valid-rmse:0.99851
[200]	train-rmse:0.99260	valid-rmse:0.99860
[240]	train-rmse:0.99270	valid-rmse:0.99860
[260]	train-rmse:0.99208	valid-rmse:0.99856
[200]	train-rmse:1.00171	valid-rmse:1.00519
[320]	train-rmse:0.99033	valid-rmse:0.99850
[260]	train-rmse:0.99233	valid-rmse:0.99860
[220]	train-rmse:0.99225	valid-rmse:0.99858
[500]	train-rmse:0.99203	valid-rmse:0.99850
[334]	train-rmse:0.99004	valid-rmse:0.99853
[32m[I 2022-04-17 05:05:12,562][0m Trial 122 finished with value: 0.998466 and parameters: {'colsample_bytree': 0.8883153803773723, 'eta': 0.024006344982643684, 'max_depth': 3, 'n_estimators': 216, 'subsample': 0.9354131883721892}. Best is trial 48 with value: 0.998395.[0m
[220]	train-rmse:1.00013	valid-rmse:1.00366
[280]	train-rmse:0.99169	valid-rmse:0.99853
[280]	train-rmse:0.99199	valid-rmse:0.99859
[05:05:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09765	valid-rmse:1.10083
[240]	train-rmse:0.99182	valid-rmse:0.99855
[520]	train-rmse:0.99184	valid-rmse:0.99851
[300]	train-rmse:0.99160	valid-rmse:0.99859
[240]	train-rmse:0.99892	valid-rmse:1.00248
[300]	train-rmse:0.99129	valid-rmse:0.99853
[20]	train-rmse:1.07303	valid-rmse:1.07635
[260]	train-rmse:0.99144	valid-rmse:0.99856
[540]	train-rmse:0.99162	valid-rmse:0.99851
[320]	train-rmse:0.99123	valid-rmse:0.99860
[260]	train-rmse:0.99798	valid-rmse:1.00158
[320]	train-rmse:0.99094	valid-rmse:0.99853
[40]	train-rmse:1.05425	valid-rmse:1.05764
[280]	train-rmse:0.99103	valid-rmse:0.99854
[556]	train-rmse:0.99146	valid-rmse:0.99851
[32m[I 2022-04-17 05:07:35,032][0m Trial 118 finished with value: 0.998498 and parameters: {'colsample_bytree': 0.8687868950856045, 'eta': 0.01152319039091817, 'max_depth': 3, 'n_estimators': 206, 'subsample': 0.9486703209676254}. Best is trial 48 with value: 0.998395.[0m
[05:07:39] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[336]	train-rmse:0.99094	valid-rmse:0.99861
[0]	train-rmse:1.09784	valid-rmse:1.10103
[32m[I 2022-04-17 05:07:44,836][0m Trial 125 finished with value: 0.99858 and parameters: {'colsample_bytree': 0.889589421945668, 'eta': 0.01964253028471077, 'max_depth': 3, 'n_estimators': 157, 'subsample': 0.5702795433474948}. Best is trial 48 with value: 0.998395.[0m
[05:07:48] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.07341	valid-rmse:1.07682
[337]	train-rmse:0.99062	valid-rmse:0.99853
[32m[I 2022-04-17 05:08:11,634][0m Trial 123 finished with value: 0.998519 and parameters: {'colsample_bytree': 0.8179610686211691, 'eta': 0.0216699485807749, 'max_depth': 3, 'n_estimators': 97, 'subsample': 0.9386854824637496}. Best is trial 48 with value: 0.998395.[0m
[280]	train-rmse:0.99724	valid-rmse:1.00089
[05:08:15] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:1.03998	valid-rmse:1.04341
[0]	train-rmse:1.09878	valid-rmse:1.10195
[300]	train-rmse:0.99057	valid-rmse:0.99855
[20]	train-rmse:1.07604	valid-rmse:1.07936
[20]	train-rmse:0.99479	valid-rmse:0.99901
[300]	train-rmse:0.99664	valid-rmse:1.00037
[20]	train-rmse:1.09317	valid-rmse:1.09638
[80]	train-rmse:1.02915	valid-rmse:1.03259
[40]	train-rmse:1.05881	valid-rmse:1.06220
[320]	train-rmse:0.99016	valid-rmse:0.99856
[40]	train-rmse:0.99196	valid-rmse:0.99869
[40]	train-rmse:1.08785	valid-rmse:1.09110
[60]	train-rmse:1.04521	valid-rmse:1.04866
[320]	train-rmse:0.99616	valid-rmse:0.99996
[100]	train-rmse:1.02095	valid-rmse:1.02442
[333]	train-rmse:0.98989	valid-rmse:0.99857
[32m[I 2022-04-17 05:10:17,714][0m Trial 124 finished with value: 0.998527 and parameters: {'colsample_bytree': 0.8158509199956585, 'eta': 0.024772298783849657, 'max_depth': 3, 'n_estimators': 210, 'subsample': 0.9326887225832015}. Best is trial 48 with value: 0.998395.[0m
[05:10:21] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09776	valid-rmse:1.10095
[60]	train-rmse:0.98945	valid-rmse:0.99886
[60]	train-rmse:1.08282	valid-rmse:1.08609
[80]	train-rmse:1.03452	valid-rmse:1.03796
[120]	train-rmse:1.01475	valid-rmse:1.01821
[340]	train-rmse:0.99577	valid-rmse:0.99965
[20]	train-rmse:1.07478	valid-rmse:1.07810
[100]	train-rmse:1.02612	valid-rmse:1.02957
[80]	train-rmse:1.07805	valid-rmse:1.08136
[80]	train-rmse:0.98737	valid-rmse:0.99893
[140]	train-rmse:1.01006	valid-rmse:1.01351
[360]	train-rmse:0.99544	valid-rmse:0.99941
[91]	train-rmse:0.98616	valid-rmse:0.99899
[32m[I 2022-04-17 05:12:33,024][0m Trial 129 finished with value: 0.998663 and parameters: {'colsample_bytree': 0.8198224245078143, 'eta': 0.14058374617829206, 'max_depth': 3, 'n_estimators': 97, 'subsample': 0.9168443518842815}. Best is trial 48 with value: 0.998395.[0m
[05:12:37] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[40]	train-rmse:1.05688	valid-rmse:1.06029
[0]	train-rmse:1.09778	valid-rmse:1.10096
[120]	train-rmse:1.01950	valid-rmse:1.02297
[100]	train-rmse:1.07354	valid-rmse:1.07687
[160]	train-rmse:1.00651	valid-rmse:1.00994
[380]	train-rmse:0.99515	valid-rmse:0.99923
[140]	train-rmse:1.01431	valid-rmse:1.01776
[120]	train-rmse:1.06927	valid-rmse:1.07263
[60]	train-rmse:1.04296	valid-rmse:1.04641
[20]	train-rmse:1.07512	valid-rmse:1.07843
[180]	train-rmse:1.00381	valid-rmse:1.00726
[400]	train-rmse:0.99490	valid-rmse:0.99908
[160]	train-rmse:1.01025	valid-rmse:1.01370
[140]	train-rmse:1.06523	valid-rmse:1.06861
[40]	train-rmse:1.05740	valid-rmse:1.06078
[80]	train-rmse:1.03218	valid-rmse:1.03566
[200]	train-rmse:1.00175	valid-rmse:1.00521
[180]	train-rmse:1.00705	valid-rmse:1.01049
[420]	train-rmse:0.99467	valid-rmse:0.99897
[160]	train-rmse:1.06141	valid-rmse:1.06480
[60]	train-rmse:1.04357	valid-rmse:1.04700
[100]	train-rmse:1.02386	valid-rmse:1.02733
[200]	train-rmse:1.00451	valid-rmse:1.00799
[220]	train-rmse:1.00016	valid-rmse:1.00367
[440]	train-rmse:0.99447	valid-rmse:0.99887
[180]	train-rmse:1.05779	valid-rmse:1.06120
[220]	train-rmse:1.00252	valid-rmse:1.00603
[80]	train-rmse:1.03283	valid-rmse:1.03628
[120]	train-rmse:1.01741	valid-rmse:1.02090
[240]	train-rmse:0.99894	valid-rmse:1.00249
[200]	train-rmse:1.05437	valid-rmse:1.05779
[460]	train-rmse:0.99429	valid-rmse:0.99880
[240]	train-rmse:1.00096	valid-rmse:1.00447
[100]	train-rmse:1.02447	valid-rmse:1.02792
[260]	train-rmse:0.99803	valid-rmse:1.00158
[140]	train-rmse:1.01242	valid-rmse:1.01591
[220]	train-rmse:1.05114	valid-rmse:1.05457
[480]	train-rmse:0.99412	valid-rmse:0.99875
[260]	train-rmse:0.99970	valid-rmse:1.00326
[280]	train-rmse:0.99729	valid-rmse:1.00089
[120]	train-rmse:1.01798	valid-rmse:1.02142
[240]	train-rmse:1.04808	valid-rmse:1.05152
[160]	train-rmse:1.00856	valid-rmse:1.01205
[280]	train-rmse:0.99869	valid-rmse:1.00229
[500]	train-rmse:0.99394	valid-rmse:0.99871
[260]	train-rmse:1.04519	valid-rmse:1.04864
[300]	train-rmse:0.99668	valid-rmse:1.00036
[140]	train-rmse:1.01294	valid-rmse:1.01637
[300]	train-rmse:0.99788	valid-rmse:1.00154
[180]	train-rmse:1.00556	valid-rmse:1.00906
[520]	train-rmse:0.99379	valid-rmse:0.99868
[280]	train-rmse:1.04246	valid-rmse:1.04591
[320]	train-rmse:0.99721	valid-rmse:1.00093
[320]	train-rmse:0.99620	valid-rmse:0.99995
[160]	train-rmse:1.00903	valid-rmse:1.01245
[200]	train-rmse:1.00325	valid-rmse:1.00676
[540]	train-rmse:0.99363	valid-rmse:0.99866
[300]	train-rmse:1.03987	valid-rmse:1.04334
[340]	train-rmse:0.99668	valid-rmse:1.00046
[340]	train-rmse:0.99582	valid-rmse:0.99965
[180]	train-rmse:1.00599	valid-rmse:1.00942
[560]	train-rmse:0.99348	valid-rmse:0.99863
[220]	train-rmse:1.00143	valid-rmse:1.00497
[360]	train-rmse:0.99622	valid-rmse:1.00008
[320]	train-rmse:1.03743	valid-rmse:1.04089
[360]	train-rmse:0.99551	valid-rmse:0.99941
[200]	train-rmse:1.00362	valid-rmse:1.00705
[380]	train-rmse:0.99586	valid-rmse:0.99979
[580]	train-rmse:0.99333	valid-rmse:0.99861
[340]	train-rmse:1.03512	valid-rmse:1.03859
[240]	train-rmse:1.00003	valid-rmse:1.00358
[380]	train-rmse:0.99524	valid-rmse:0.99922
[400]	train-rmse:0.99553	valid-rmse:0.99954
[220]	train-rmse:1.00177	valid-rmse:1.00521
[360]	train-rmse:1.03294	valid-rmse:1.03642
[600]	train-rmse:0.99321	valid-rmse:0.99860
[260]	train-rmse:0.99894	valid-rmse:1.00251
[400]	train-rmse:0.99500	valid-rmse:0.99908
[420]	train-rmse:0.99524	valid-rmse:0.99934
[380]	train-rmse:1.03088	valid-rmse:1.03436
[240]	train-rmse:1.00033	valid-rmse:1.00377
[620]	train-rmse:0.99306	valid-rmse:0.99859
[280]	train-rmse:0.99805	valid-rmse:1.00166
[420]	train-rmse:0.99478	valid-rmse:0.99896
[440]	train-rmse:0.99500	valid-rmse:0.99918
[400]	train-rmse:1.02892	valid-rmse:1.03241
[260]	train-rmse:0.99920	valid-rmse:1.00266
[640]	train-rmse:0.99292	valid-rmse:0.99857
[460]	train-rmse:0.99476	valid-rmse:0.99906
[440]	train-rmse:0.99458	valid-rmse:0.99887
[300]	train-rmse:0.99733	valid-rmse:1.00101
[420]	train-rmse:1.02708	valid-rmse:1.03057
[280]	train-rmse:0.99827	valid-rmse:1.00179
[480]	train-rmse:0.99457	valid-rmse:0.99896
[660]	train-rmse:0.99278	valid-rmse:0.99856
[460]	train-rmse:0.99441	valid-rmse:0.99880
[320]	train-rmse:0.99675	valid-rmse:1.00050
[440]	train-rmse:1.02534	valid-rmse:1.02882
[500]	train-rmse:0.99438	valid-rmse:0.99889
[300]	train-rmse:0.99754	valid-rmse:1.00111
[680]	train-rmse:0.99264	valid-rmse:0.99856
[480]	train-rmse:0.99423	valid-rmse:0.99874
[460]	train-rmse:1.02369	valid-rmse:1.02717
[340]	train-rmse:0.99628	valid-rmse:1.00011
[520]	train-rmse:0.99421	valid-rmse:0.99882
[700]	train-rmse:0.99251	valid-rmse:0.99855
[320]	train-rmse:0.99695	valid-rmse:1.00057
[500]	train-rmse:0.99406	valid-rmse:0.99869
[480]	train-rmse:1.02213	valid-rmse:1.02562
[540]	train-rmse:0.99404	valid-rmse:0.99876
[360]	train-rmse:0.99589	valid-rmse:0.99980
[720]	train-rmse:0.99238	valid-rmse:0.99855
[340]	train-rmse:0.99648	valid-rmse:1.00014
[500]	train-rmse:1.02066	valid-rmse:1.02415
[520]	train-rmse:0.99391	valid-rmse:0.99865
[560]	train-rmse:0.99390	valid-rmse:0.99870
[380]	train-rmse:0.99555	valid-rmse:0.99955
[520]	train-rmse:1.01927	valid-rmse:1.02276
[740]	train-rmse:0.99225	valid-rmse:0.99854
[580]	train-rmse:0.99374	valid-rmse:0.99867
[540]	train-rmse:0.99375	valid-rmse:0.99863
[360]	train-rmse:0.99607	valid-rmse:0.99981
[400]	train-rmse:0.99526	valid-rmse:0.99934
[540]	train-rmse:1.01796	valid-rmse:1.02145
[600]	train-rmse:0.99360	valid-rmse:0.99863
[760]	train-rmse:0.99212	valid-rmse:0.99854
[560]	train-rmse:0.99361	valid-rmse:0.99860
[380]	train-rmse:0.99574	valid-rmse:0.99954
[620]	train-rmse:0.99345	valid-rmse:0.99861
[420]	train-rmse:0.99501	valid-rmse:0.99918
[560]	train-rmse:1.01672	valid-rmse:1.02021
[580]	train-rmse:0.99345	valid-rmse:0.99859
[780]	train-rmse:0.99198	valid-rmse:0.99855
[400]	train-rmse:0.99544	valid-rmse:0.99934
[640]	train-rmse:0.99331	valid-rmse:0.99858
[580]	train-rmse:1.01555	valid-rmse:1.01903
[440]	train-rmse:0.99481	valid-rmse:0.99905
[600]	train-rmse:0.99332	valid-rmse:0.99857
[800]	train-rmse:0.99185	valid-rmse:0.99854
[420]	train-rmse:0.99519	valid-rmse:0.99917
[660]	train-rmse:0.99318	valid-rmse:0.99856
[805]	train-rmse:0.99182	valid-rmse:0.99854
[32m[I 2022-04-17 05:35:18,231][0m Trial 126 finished with value: 0.998532 and parameters: {'colsample_bytree': 0.8218031343295101, 'eta': 0.00729674319381049, 'max_depth': 3, 'n_estimators': 102, 'subsample': 0.9374623359359221}. Best is trial 48 with value: 0.998395.[0m
[05:35:22] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[600]	train-rmse:1.01444	valid-rmse:1.01793
[0]	train-rmse:1.08403	valid-rmse:1.08730
[460]	train-rmse:0.99461	valid-rmse:0.99895
[620]	train-rmse:0.99317	valid-rmse:0.99856
[680]	train-rmse:0.99306	valid-rmse:0.99855
[440]	train-rmse:0.99496	valid-rmse:0.99904
[620]	train-rmse:1.01340	valid-rmse:1.01689
[20]	train-rmse:0.99913	valid-rmse:1.00261
[480]	train-rmse:0.99443	valid-rmse:0.99887
[640]	train-rmse:0.99305	valid-rmse:0.99855
[700]	train-rmse:0.99293	valid-rmse:0.99854
[640]	train-rmse:1.01241	valid-rmse:1.01589
[460]	train-rmse:0.99476	valid-rmse:0.99893
[40]	train-rmse:0.99453	valid-rmse:0.99878
[720]	train-rmse:0.99281	valid-rmse:0.99853
[660]	train-rmse:0.99292	valid-rmse:0.99854
[500]	train-rmse:0.99425	valid-rmse:0.99881
[660]	train-rmse:1.01148	valid-rmse:1.01496
[480]	train-rmse:0.99457	valid-rmse:0.99884
[60]	train-rmse:0.99306	valid-rmse:0.99853
[740]	train-rmse:0.99268	valid-rmse:0.99853
[680]	train-rmse:0.99279	valid-rmse:0.99853
[680]	train-rmse:1.01059	valid-rmse:1.01408
[520]	train-rmse:0.99410	valid-rmse:0.99876
[500]	train-rmse:0.99439	valid-rmse:0.99878
[760]	train-rmse:0.99256	valid-rmse:0.99853
[80]	train-rmse:0.99173	valid-rmse:0.99853
[700]	train-rmse:1.00976	valid-rmse:1.01324
[700]	train-rmse:0.99265	valid-rmse:0.99852
[540]	train-rmse:0.99395	valid-rmse:0.99872
[780]	train-rmse:0.99244	valid-rmse:0.99852
[520]	train-rmse:0.99426	valid-rmse:0.99872
[100]	train-rmse:0.99033	valid-rmse:0.99862
[720]	train-rmse:1.00897	valid-rmse:1.01245
[720]	train-rmse:0.99254	valid-rmse:0.99852
[800]	train-rmse:0.99232	valid-rmse:0.99852
[560]	train-rmse:0.99380	valid-rmse:0.99869
[117]	train-rmse:0.98932	valid-rmse:0.99867
[32m[I 2022-04-17 05:41:23,303][0m Trial 133 finished with value: 0.998524 and parameters: {'colsample_bytree': 0.7827945736682584, 'eta': 0.08005077472153455, 'max_depth': 3, 'n_estimators': 275, 'subsample': 0.9997805331918561}. Best is trial 48 with value: 0.998395.[0m
[05:41:27] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[540]	train-rmse:0.99410	valid-rmse:0.99867
[0]	train-rmse:1.09785	valid-rmse:1.10103
[740]	train-rmse:1.00822	valid-rmse:1.01170
[740]	train-rmse:0.99241	valid-rmse:0.99851
[820]	train-rmse:0.99220	valid-rmse:0.99851
[580]	train-rmse:0.99364	valid-rmse:0.99866
[560]	train-rmse:0.99396	valid-rmse:0.99863
[760]	train-rmse:1.00752	valid-rmse:1.01099
[20]	train-rmse:1.07623	valid-rmse:1.07954
[840]	train-rmse:0.99208	valid-rmse:0.99851
[760]	train-rmse:0.99230	valid-rmse:0.99851
[600]	train-rmse:0.99352	valid-rmse:0.99862
[780]	train-rmse:1.00685	valid-rmse:1.01033
[860]	train-rmse:0.99196	valid-rmse:0.99851
[580]	train-rmse:0.99383	valid-rmse:0.99860
[40]	train-rmse:1.05911	valid-rmse:1.06248
[780]	train-rmse:0.99216	valid-rmse:0.99851
[870]	train-rmse:0.99191	valid-rmse:0.99851
[32m[I 2022-04-17 05:44:06,525][0m Trial 128 finished with value: 0.998509 and parameters: {'colsample_bytree': 0.7826751004424989, 'eta': 0.006349921926503711, 'max_depth': 3, 'n_estimators': 95, 'subsample': 0.7108779811185248}. Best is trial 48 with value: 0.998395.[0m
[05:44:10] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09146	valid-rmse:1.09469
[800]	train-rmse:1.00622	valid-rmse:1.00970
[620]	train-rmse:0.99337	valid-rmse:0.99860
[600]	train-rmse:0.99370	valid-rmse:0.99858
[800]	train-rmse:0.99203	valid-rmse:0.99850
[60]	train-rmse:1.04557	valid-rmse:1.04899
[820]	train-rmse:1.00563	valid-rmse:1.00910
[20]	train-rmse:1.01613	valid-rmse:1.01951
[640]	train-rmse:0.99321	valid-rmse:0.99859
[620]	train-rmse:0.99357	valid-rmse:0.99855
[820]	train-rmse:0.99191	valid-rmse:0.99850
[80]	train-rmse:1.03488	valid-rmse:1.03834
[840]	train-rmse:1.00506	valid-rmse:1.00854
[40]	train-rmse:0.99982	valid-rmse:1.00322
[660]	train-rmse:0.99308	valid-rmse:0.99858
[640]	train-rmse:0.99345	valid-rmse:0.99853
[840]	train-rmse:0.99178	valid-rmse:0.99851
[860]	train-rmse:1.00453	valid-rmse:1.00801
[100]	train-rmse:1.02647	valid-rmse:1.02995
[60]	train-rmse:0.99590	valid-rmse:0.99965
[680]	train-rmse:0.99296	valid-rmse:0.99857
[860]	train-rmse:0.99167	valid-rmse:0.99851
[660]	train-rmse:0.99332	valid-rmse:0.99852
[880]	train-rmse:1.00402	valid-rmse:1.00751
[120]	train-rmse:1.01986	valid-rmse:1.02334
[870]	train-rmse:0.99161	valid-rmse:0.99851
[32m[I 2022-04-17 05:48:31,150][0m Trial 127 finished with value: 0.998499 and parameters: {'colsample_bytree': 0.7748046097506521, 'eta': 0.007293577002062341, 'max_depth': 3, 'n_estimators': 275, 'subsample': 0.968493470942219}. Best is trial 48 with value: 0.998395.[0m
[05:48:35] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09218	valid-rmse:1.09539
[80]	train-rmse:0.99445	valid-rmse:0.99883
[900]	train-rmse:1.00354	valid-rmse:1.00703
[700]	train-rmse:0.99282	valid-rmse:0.99856
[680]	train-rmse:0.99320	valid-rmse:0.99850
[140]	train-rmse:1.01466	valid-rmse:1.01811
[920]	train-rmse:1.00309	valid-rmse:1.00658
[20]	train-rmse:1.01955	valid-rmse:1.02299
[100]	train-rmse:0.99356	valid-rmse:0.99861
[700]	train-rmse:0.99308	valid-rmse:0.99849
[720]	train-rmse:0.99269	valid-rmse:0.99855
[160]	train-rmse:1.01056	valid-rmse:1.01402
[940]	train-rmse:1.00266	valid-rmse:1.00615
[40]	train-rmse:1.00138	valid-rmse:1.00481
[120]	train-rmse:0.99284	valid-rmse:0.99853
[720]	train-rmse:0.99296	valid-rmse:0.99847
[740]	train-rmse:0.99255	valid-rmse:0.99855
[960]	train-rmse:1.00226	valid-rmse:1.00575
[180]	train-rmse:1.00732	valid-rmse:1.01080
[60]	train-rmse:0.99662	valid-rmse:1.00021
[740]	train-rmse:0.99285	valid-rmse:0.99846
[140]	train-rmse:0.99216	valid-rmse:0.99851
[760]	train-rmse:0.99243	valid-rmse:0.99854
[980]	train-rmse:1.00188	valid-rmse:1.00537
[200]	train-rmse:1.00478	valid-rmse:1.00825
[80]	train-rmse:0.99494	valid-rmse:0.99904
[999]	train-rmse:1.00153	valid-rmse:1.00503
[32m[I 2022-04-17 05:53:20,990][0m Trial 130 finished with value: 1.005033 and parameters: {'colsample_bytree': 0.7360073723767419, 'eta': 0.0014864200988619052, 'max_depth': 3, 'n_estimators': 270, 'subsample': 0.9188330678745021}. Best is trial 48 with value: 0.998395.[0m
[760]	train-rmse:0.99274	valid-rmse:0.99845
[05:53:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09070	valid-rmse:1.09393
[160]	train-rmse:0.99147	valid-rmse:0.99852
[780]	train-rmse:0.99230	valid-rmse:0.99853
[220]	train-rmse:1.00278	valid-rmse:1.00624
[780]	train-rmse:0.99262	valid-rmse:0.99845
[100]	train-rmse:0.99403	valid-rmse:0.99869
[20]	train-rmse:1.01287	valid-rmse:1.01629
[180]	train-rmse:0.99088	valid-rmse:0.99846
[800]	train-rmse:0.99217	valid-rmse:0.99853
[240]	train-rmse:1.00118	valid-rmse:1.00466
[800]	train-rmse:0.99252	valid-rmse:0.99844
[120]	train-rmse:0.99339	valid-rmse:0.99855
[40]	train-rmse:0.99851	valid-rmse:1.00204
[820]	train-rmse:0.99205	valid-rmse:0.99853
[200]	train-rmse:0.99018	valid-rmse:0.99849
[260]	train-rmse:0.99993	valid-rmse:1.00341
[820]	train-rmse:0.99240	valid-rmse:0.99845
[140]	train-rmse:0.99272	valid-rmse:0.99852
[60]	train-rmse:0.99534	valid-rmse:0.99932
[840]	train-rmse:0.99192	valid-rmse:0.99852
[220]	train-rmse:0.98958	valid-rmse:0.99848
[223]	train-rmse:0.98946	valid-rmse:0.99848
[32m[I 2022-04-17 05:57:18,038][0m Trial 135 finished with value: 0.99846 and parameters: {'colsample_bytree': 0.9366682352980273, 'eta': 0.03971284115180005, 'max_depth': 3, 'n_estimators': 156, 'subsample': 0.9706837218094357}. Best is trial 48 with value: 0.998395.[0m
[05:57:22] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[280]	train-rmse:0.99892	valid-rmse:1.00242
[0]	train-rmse:1.09203	valid-rmse:1.09525
[840]	train-rmse:0.99229	valid-rmse:0.99844
[160]	train-rmse:0.99210	valid-rmse:0.99854
[860]	train-rmse:0.99179	valid-rmse:0.99851
[80]	train-rmse:0.99408	valid-rmse:0.99872
[300]	train-rmse:0.99808	valid-rmse:1.00164
[20]	train-rmse:1.01881	valid-rmse:1.02227
[860]	train-rmse:0.99217	valid-rmse:0.99843
[180]	train-rmse:0.99153	valid-rmse:0.99855
[880]	train-rmse:0.99168	valid-rmse:0.99851
[100]	train-rmse:0.99323	valid-rmse:0.99855
[320]	train-rmse:0.99742	valid-rmse:1.00103
[40]	train-rmse:1.00105	valid-rmse:1.00446
[190]	train-rmse:0.99127	valid-rmse:0.99854
[32m[I 2022-04-17 05:59:45,434][0m Trial 136 finished with value: 0.998516 and parameters: {'colsample_bytree': 0.929368429270613, 'eta': 0.03595623309267765, 'max_depth': 3, 'n_estimators': 306, 'subsample': 0.984089317315107}. Best is trial 48 with value: 0.998395.[0m
[05:59:49] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[880]	train-rmse:0.99207	valid-rmse:0.99844
[0]	train-rmse:1.09116	valid-rmse:1.09439
[900]	train-rmse:0.99155	valid-rmse:0.99851
[120]	train-rmse:0.99254	valid-rmse:0.99851
[340]	train-rmse:0.99687	valid-rmse:1.00054
[60]	train-rmse:0.99650	valid-rmse:1.00008
[900]	train-rmse:0.99196	valid-rmse:0.99843
[20]	train-rmse:1.01475	valid-rmse:1.01819
[920]	train-rmse:0.99143	valid-rmse:0.99850
[140]	train-rmse:0.99173	valid-rmse:0.99848
[360]	train-rmse:0.99643	valid-rmse:1.00015
[80]	train-rmse:0.99484	valid-rmse:0.99901
[920]	train-rmse:0.99185	valid-rmse:0.99843
[40]	train-rmse:0.99920	valid-rmse:1.00273
[940]	train-rmse:0.99131	valid-rmse:0.99851
[160]	train-rmse:0.99095	valid-rmse:0.99853
[940]	train-rmse:0.99174	valid-rmse:0.99843
[380]	train-rmse:0.99606	valid-rmse:0.99983
[100]	train-rmse:0.99386	valid-rmse:0.99867
[948]	train-rmse:0.99126	valid-rmse:0.99851
[32m[I 2022-04-17 06:03:09,077][0m Trial 131 finished with value: 0.998502 and parameters: {'colsample_bytree': 0.933702814586604, 'eta': 0.006735211340976579, 'max_depth': 3, 'n_estimators': 277, 'subsample': 0.9153507593078518}. Best is trial 48 with value: 0.998395.[0m
[06:03:13] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09123	valid-rmse:1.09447
[60]	train-rmse:0.99572	valid-rmse:0.99950
[180]	train-rmse:0.99021	valid-rmse:0.99852
[960]	train-rmse:0.99163	valid-rmse:0.99843
[400]	train-rmse:0.99574	valid-rmse:0.99958
[120]	train-rmse:0.99318	valid-rmse:0.99857
[20]	train-rmse:1.01504	valid-rmse:1.01847
[190]	train-rmse:0.98988	valid-rmse:0.99851
[32m[I 2022-04-17 06:04:36,573][0m Trial 137 finished with value: 0.99848 and parameters: {'colsample_bytree': 0.9317300583647626, 'eta': 0.0438001672752091, 'max_depth': 3, 'n_estimators': 308, 'subsample': 0.9855099675370941}. Best is trial 48 with value: 0.998395.[0m
[06:04:40] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[80]	train-rmse:0.99437	valid-rmse:0.99877
[0]	train-rmse:1.08593	valid-rmse:1.08920
[980]	train-rmse:0.99152	valid-rmse:0.99843
[420]	train-rmse:0.99547	valid-rmse:0.99938
[140]	train-rmse:0.99251	valid-rmse:0.99849
[40]	train-rmse:0.99931	valid-rmse:1.00285
[20]	train-rmse:1.00133	valid-rmse:1.00472
[100]	train-rmse:0.99353	valid-rmse:0.99859
[999]	train-rmse:0.99140	valid-rmse:0.99843
[32m[I 2022-04-17 06:06:19,019][0m Trial 132 finished with value: 0.998423 and parameters: {'colsample_bytree': 0.8443074635917809, 'eta': 0.006626845126356534, 'max_depth': 3, 'n_estimators': 288, 'subsample': 0.9862614249907917}. Best is trial 48 with value: 0.998395.[0m
[06:06:23] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[440]	train-rmse:0.99523	valid-rmse:0.99922
[0]	train-rmse:1.09357	valid-rmse:1.09681
[160]	train-rmse:0.99189	valid-rmse:0.99849
[60]	train-rmse:0.99574	valid-rmse:0.99952
[40]	train-rmse:0.99491	valid-rmse:0.99916
[120]	train-rmse:0.99277	valid-rmse:0.99851
[20]	train-rmse:1.02810	valid-rmse:1.03156
[460]	train-rmse:0.99502	valid-rmse:0.99909
[180]	train-rmse:0.99132	valid-rmse:0.99848
[80]	train-rmse:0.99439	valid-rmse:0.99878
[60]	train-rmse:0.99343	valid-rmse:0.99870
[140]	train-rmse:0.99203	valid-rmse:0.99847
[40]	train-rmse:1.00627	valid-rmse:1.00968
[480]	train-rmse:0.99481	valid-rmse:0.99898
[200]	train-rmse:0.99065	valid-rmse:0.99850
[100]	train-rmse:0.99345	valid-rmse:0.99860
[80]	train-rmse:0.99222	valid-rmse:0.99867
[160]	train-rmse:0.99127	valid-rmse:0.99845
[60]	train-rmse:0.99894	valid-rmse:1.00241
[500]	train-rmse:0.99463	valid-rmse:0.99889
[220]	train-rmse:0.99005	valid-rmse:0.99850
[224]	train-rmse:0.98996	valid-rmse:0.99851
[32m[I 2022-04-17 06:10:21,286][0m Trial 138 finished with value: 0.998465 and parameters: {'colsample_bytree': 0.9295359475623362, 'eta': 0.03675055748867596, 'max_depth': 3, 'n_estimators': 318, 'subsample': 0.967242047050153}. Best is trial 48 with value: 0.998395.[0m
[06:10:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[120]	train-rmse:0.99269	valid-rmse:0.99854
[0]	train-rmse:1.09482	valid-rmse:1.09804
[80]	train-rmse:0.99617	valid-rmse:0.99995
[100]	train-rmse:0.99094	valid-rmse:0.99867
[180]	train-rmse:0.99059	valid-rmse:0.99844
[520]	train-rmse:0.99448	valid-rmse:0.99882
[20]	train-rmse:1.03811	valid-rmse:1.04157
[100]	train-rmse:0.99492	valid-rmse:0.99908
[140]	train-rmse:0.99194	valid-rmse:0.99853
[120]	train-rmse:0.98986	valid-rmse:0.99868
[200]	train-rmse:0.98989	valid-rmse:0.99850
[540]	train-rmse:0.99432	valid-rmse:0.99877
[40]	train-rmse:1.01367	valid-rmse:1.01713
[120]	train-rmse:0.99415	valid-rmse:0.99876
[160]	train-rmse:0.99116	valid-rmse:0.99857
[139]	train-rmse:0.98877	valid-rmse:0.99869
[32m[I 2022-04-17 06:13:15,642][0m Trial 141 finished with value: 0.998638 and parameters: {'colsample_bytree': 0.9838101320257957, 'eta': 0.06968287003734874, 'max_depth': 3, 'n_estimators': 158, 'subsample': 0.9637368821567001}. Best is trial 48 with value: 0.998395.[0m
[560]	train-rmse:0.99417	valid-rmse:0.99872
[220]	train-rmse:0.98924	valid-rmse:0.99852
[06:13:19] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09522	valid-rmse:1.09843
[60]	train-rmse:1.00325	valid-rmse:1.00663
[140]	train-rmse:0.99359	valid-rmse:0.99862
[229]	train-rmse:0.98900	valid-rmse:0.99853
[32m[I 2022-04-17 06:13:56,556][0m Trial 139 finished with value: 0.998444 and parameters: {'colsample_bytree': 0.9904146618109516, 'eta': 0.04137208483493571, 'max_depth': 3, 'n_estimators': 146, 'subsample': 0.9666696714558498}. Best is trial 48 with value: 0.998395.[0m
[06:14:00] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09515	valid-rmse:1.09836
[180]	train-rmse:0.99052	valid-rmse:0.99855
[182]	train-rmse:0.99045	valid-rmse:0.99856
[32m[I 2022-04-17 06:14:19,278][0m Trial 140 finished with value: 0.998528 and parameters: {'colsample_bytree': 0.9862439934238957, 'eta': 0.0410243657435405, 'max_depth': 3, 'n_estimators': 146, 'subsample': 0.962889943844409}. Best is trial 48 with value: 0.998395.[0m
[06:14:23] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[580]	train-rmse:0.99402	valid-rmse:0.99869
[20]	train-rmse:1.04208	valid-rmse:1.04552
[0]	train-rmse:1.09560	valid-rmse:1.09879
[80]	train-rmse:0.99863	valid-rmse:1.00213
[160]	train-rmse:0.99301	valid-rmse:0.99856
[20]	train-rmse:1.04135	valid-rmse:1.04481
[40]	train-rmse:1.01713	valid-rmse:1.02060
[600]	train-rmse:0.99389	valid-rmse:0.99866
[20]	train-rmse:1.04594	valid-rmse:1.04933
[100]	train-rmse:0.99646	valid-rmse:1.00020
[180]	train-rmse:0.99253	valid-rmse:0.99852
[40]	train-rmse:1.01649	valid-rmse:1.01993
[60]	train-rmse:1.00558	valid-rmse:1.00896
[620]	train-rmse:0.99376	valid-rmse:0.99864
[40]	train-rmse:1.02079	valid-rmse:1.02418
[120]	train-rmse:0.99535	valid-rmse:0.99929
[200]	train-rmse:0.99201	valid-rmse:0.99849
[60]	train-rmse:1.00513	valid-rmse:1.00852
[80]	train-rmse:1.00008	valid-rmse:1.00354
[140]	train-rmse:0.99465	valid-rmse:0.99887
[640]	train-rmse:0.99364	valid-rmse:0.99861
[60]	train-rmse:1.00818	valid-rmse:1.01156
[220]	train-rmse:0.99155	valid-rmse:0.99848
[80]	train-rmse:0.99979	valid-rmse:1.00324
[100]	train-rmse:0.99740	valid-rmse:1.00099
[160]	train-rmse:0.99408	valid-rmse:0.99865
[660]	train-rmse:0.99351	valid-rmse:0.99859
[80]	train-rmse:1.00183	valid-rmse:1.00523
[240]	train-rmse:0.99109	valid-rmse:0.99851
[100]	train-rmse:0.99724	valid-rmse:1.00079
[120]	train-rmse:0.99601	valid-rmse:0.99975
[180]	train-rmse:0.99362	valid-rmse:0.99856
[680]	train-rmse:0.99338	valid-rmse:0.99858
[100]	train-rmse:0.99854	valid-rmse:1.00203
[260]	train-rmse:0.99064	valid-rmse:0.99851
[120]	train-rmse:0.99594	valid-rmse:0.99962
[140]	train-rmse:0.99515	valid-rmse:0.99916
[270]	train-rmse:0.99043	valid-rmse:0.99850
[32m[I 2022-04-17 06:20:47,156][0m Trial 142 finished with value: 0.998485 and parameters: {'colsample_bytree': 0.8461413147203778, 'eta': 0.028622939020710985, 'max_depth': 3, 'n_estimators': 155, 'subsample': 0.9650984737024777}. Best is trial 48 with value: 0.998395.[0m
[06:20:51] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.07609	valid-rmse:1.07938
[200]	train-rmse:0.99316	valid-rmse:0.99849
[120]	train-rmse:0.99679	valid-rmse:1.00038
[700]	train-rmse:0.99326	valid-rmse:0.99857
[140]	train-rmse:0.99509	valid-rmse:0.99906
[160]	train-rmse:0.99455	valid-rmse:0.99886
[220]	train-rmse:0.99279	valid-rmse:0.99844
[20]	train-rmse:0.99535	valid-rmse:0.99927
[140]	train-rmse:0.99575	valid-rmse:0.99952
[720]	train-rmse:0.99316	valid-rmse:0.99856
[160]	train-rmse:0.99448	valid-rmse:0.99877
[180]	train-rmse:0.99408	valid-rmse:0.99870
[240]	train-rmse:0.99243	valid-rmse:0.99843
[40]	train-rmse:0.99286	valid-rmse:0.99863
[160]	train-rmse:0.99508	valid-rmse:0.99906
[740]	train-rmse:0.99304	valid-rmse:0.99855
[180]	train-rmse:0.99402	valid-rmse:0.99863
[200]	train-rmse:0.99367	valid-rmse:0.99864
[260]	train-rmse:0.99211	valid-rmse:0.99843
[180]	train-rmse:0.99458	valid-rmse:0.99879
[60]	train-rmse:0.99078	valid-rmse:0.99859
[760]	train-rmse:0.99294	valid-rmse:0.99853
[200]	train-rmse:0.99362	valid-rmse:0.99854
[220]	train-rmse:0.99329	valid-rmse:0.99857
[280]	train-rmse:0.99174	valid-rmse:0.99841
[200]	train-rmse:0.99416	valid-rmse:0.99864
[220]	train-rmse:0.99325	valid-rmse:0.99850
[780]	train-rmse:0.99283	valid-rmse:0.99853
[80]	train-rmse:0.98859	valid-rmse:0.99873
[240]	train-rmse:0.99292	valid-rmse:0.99854
[300]	train-rmse:0.99129	valid-rmse:0.99841
[220]	train-rmse:0.99381	valid-rmse:0.99857
[240]	train-rmse:0.99292	valid-rmse:0.99847
[800]	train-rmse:0.99272	valid-rmse:0.99852
[260]	train-rmse:0.99261	valid-rmse:0.99852
[100]	train-rmse:0.98681	valid-rmse:0.99882
[320]	train-rmse:0.99092	valid-rmse:0.99843
[108]	train-rmse:0.98611	valid-rmse:0.99885
[32m[I 2022-04-17 06:27:47,550][0m Trial 147 finished with value: 0.998556 and parameters: {'colsample_bytree': 0.9971943048333668, 'eta': 0.12471353155906692, 'max_depth': 3, 'n_estimators': 121, 'subsample': 0.9996618893988417}. Best is trial 48 with value: 0.998395.[0m
[06:27:51] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.05580	valid-rmse:1.05913
[240]	train-rmse:0.99349	valid-rmse:0.99852
[260]	train-rmse:0.99258	valid-rmse:0.99845
[280]	train-rmse:0.99226	valid-rmse:0.99849
[820]	train-rmse:0.99260	valid-rmse:0.99851
[340]	train-rmse:0.99054	valid-rmse:0.99845
[32m[I 2022-04-17 06:28:34,626][0m Trial 143 finished with value: 0.998394 and parameters: {'colsample_bytree': 0.8442658569272272, 'eta': 0.022097230087882953, 'max_depth': 3, 'n_estimators': 166, 'subsample': 0.9626062337518138}. Best is trial 143 with value: 0.998394.[0m
[06:28:38] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.05146	valid-rmse:1.05479
[280]	train-rmse:0.99222	valid-rmse:0.99844
[260]	train-rmse:0.99319	valid-rmse:0.99849
[20]	train-rmse:0.99269	valid-rmse:0.99865
[300]	train-rmse:0.99192	valid-rmse:0.99848
[840]	train-rmse:0.99248	valid-rmse:0.99851
[20]	train-rmse:0.99243	valid-rmse:0.99886
[300]	train-rmse:0.99191	valid-rmse:0.99844
[280]	train-rmse:0.99289	valid-rmse:0.99847
[40]	train-rmse:0.98901	valid-rmse:0.99905
[320]	train-rmse:0.99156	valid-rmse:0.99849
[860]	train-rmse:0.99237	valid-rmse:0.99851
[40]	train-rmse:0.98786	valid-rmse:0.99900
[320]	train-rmse:0.99152	valid-rmse:0.99845
[300]	train-rmse:0.99257	valid-rmse:0.99847
[340]	train-rmse:0.99124	valid-rmse:0.99849
[32m[I 2022-04-17 06:31:31,777][0m Trial 144 finished with value: 0.998479 and parameters: {'colsample_bytree': 0.8430212439409827, 'eta': 0.019909048200718493, 'max_depth': 3, 'n_estimators': 236, 'subsample': 0.982634336768418}. Best is trial 143 with value: 0.998394.[0m
[60]	train-rmse:0.98514	valid-rmse:0.99925
[06:31:36] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.05868	valid-rmse:1.06209
[880]	train-rmse:0.99226	valid-rmse:0.99851
[67]	train-rmse:0.98386	valid-rmse:0.99941
[32m[I 2022-04-17 06:31:59,995][0m Trial 148 finished with value: 0.998612 and parameters: {'colsample_bytree': 0.9509164210843755, 'eta': 0.24924714329554012, 'max_depth': 3, 'n_estimators': 227, 'subsample': 0.9836686628258211}. Best is trial 143 with value: 0.998394.[0m
[06:32:04] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[60]	train-rmse:0.98384	valid-rmse:0.99938
[0]	train-rmse:1.08544	valid-rmse:1.08873
[62]	train-rmse:0.98351	valid-rmse:0.99946
[32m[I 2022-04-17 06:32:12,817][0m Trial 149 finished with value: 0.998719 and parameters: {'colsample_bytree': 0.8793032186820506, 'eta': 0.27810673420171933, 'max_depth': 3, 'n_estimators': 236, 'subsample': 0.9873917503948002}. Best is trial 143 with value: 0.998394.[0m
[06:32:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[339]	train-rmse:0.99120	valid-rmse:0.99845
[32m[I 2022-04-17 06:32:22,308][0m Trial 145 finished with value: 0.998432 and parameters: {'colsample_bytree': 0.8438312507749335, 'eta': 0.020289024121565035, 'max_depth': 3, 'n_estimators': 235, 'subsample': 0.9850407663293481}. Best is trial 143 with value: 0.998394.[0m
[0]	train-rmse:1.09375	valid-rmse:1.09697
[06:32:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[320]	train-rmse:0.99227	valid-rmse:0.99844
[0]	train-rmse:1.09853	valid-rmse:1.10171
[20]	train-rmse:1.00075	valid-rmse:1.00410
[20]	train-rmse:0.99314	valid-rmse:0.99867
[900]	train-rmse:0.99214	valid-rmse:0.99851
[40]	train-rmse:0.99506	valid-rmse:0.99907
[20]	train-rmse:1.02940	valid-rmse:1.03284
[20]	train-rmse:1.08840	valid-rmse:1.09164
[60]	train-rmse:0.99370	valid-rmse:0.99861
[340]	train-rmse:0.99197	valid-rmse:0.99845
[40]	train-rmse:0.98914	valid-rmse:0.99889
[80]	train-rmse:0.99251	valid-rmse:0.99857
[920]	train-rmse:0.99203	valid-rmse:0.99851
[100]	train-rmse:0.99135	valid-rmse:0.99869
[40]	train-rmse:1.07924	valid-rmse:1.08253
[40]	train-rmse:1.00711	valid-rmse:1.01058
[360]	train-rmse:0.99168	valid-rmse:0.99843
[60]	train-rmse:0.98567	valid-rmse:0.99926
[120]	train-rmse:0.99031	valid-rmse:0.99876
[940]	train-rmse:0.99191	valid-rmse:0.99850
[134]	train-rmse:0.98953	valid-rmse:0.99877
[32m[I 2022-04-17 06:35:20,015][0m Trial 151 finished with value: 0.998563 and parameters: {'colsample_bytree': 0.3107678333135863, 'eta': 0.07244659061942124, 'max_depth': 3, 'n_estimators': 179, 'subsample': 0.9493024805054996}. Best is trial 143 with value: 0.998394.[0m
[06:35:24] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09591	valid-rmse:1.09911
[60]	train-rmse:1.07096	valid-rmse:1.07430
[60]	train-rmse:0.99939	valid-rmse:1.00285
[73]	train-rmse:0.98361	valid-rmse:0.99948
[32m[I 2022-04-17 06:35:45,391][0m Trial 150 finished with value: 0.998605 and parameters: {'colsample_bytree': 0.8819844316227796, 'eta': 0.2308308101334781, 'max_depth': 3, 'n_estimators': 173, 'subsample': 0.9477557586802385}. Best is trial 143 with value: 0.998394.[0m
[06:35:49] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09587	valid-rmse:1.09907
[380]	train-rmse:0.99136	valid-rmse:0.99844
[960]	train-rmse:0.99182	valid-rmse:0.99850
[20]	train-rmse:1.04941	valid-rmse:1.05279
[80]	train-rmse:1.06349	valid-rmse:1.06686
[80]	train-rmse:0.99647	valid-rmse:1.00016
[20]	train-rmse:1.04897	valid-rmse:1.05239
[400]	train-rmse:0.99108	valid-rmse:0.99843
[40]	train-rmse:1.02431	valid-rmse:1.02772
[100]	train-rmse:1.05675	valid-rmse:1.06015
[980]	train-rmse:0.99171	valid-rmse:0.99851
[100]	train-rmse:0.99510	valid-rmse:0.99919
[40]	train-rmse:1.02386	valid-rmse:1.02730
[420]	train-rmse:0.99076	valid-rmse:0.99843
[120]	train-rmse:1.05066	valid-rmse:1.05409
[60]	train-rmse:1.01093	valid-rmse:1.01427
[999]	train-rmse:0.99160	valid-rmse:0.99851
[32m[I 2022-04-17 06:38:41,246][0m Trial 134 finished with value: 0.998501 and parameters: {'colsample_bytree': 0.9287356591568188, 'eta': 0.0062795980510117295, 'max_depth': 3, 'n_estimators': 2, 'subsample': 0.9649974601802734}. Best is trial 143 with value: 0.998394.[0m
[06:38:45] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09714	valid-rmse:1.10033
[120]	train-rmse:0.99430	valid-rmse:0.99882
[60]	train-rmse:1.01054	valid-rmse:1.01395
[440]	train-rmse:0.99048	valid-rmse:0.99844
[140]	train-rmse:1.04518	valid-rmse:1.04862
[80]	train-rmse:1.00373	valid-rmse:1.00708
[20]	train-rmse:1.06524	valid-rmse:1.06859
[80]	train-rmse:1.00345	valid-rmse:1.00687
[140]	train-rmse:0.99369	valid-rmse:0.99864
[160]	train-rmse:1.04024	valid-rmse:1.04369
[100]	train-rmse:0.99983	valid-rmse:1.00322
[460]	train-rmse:0.99021	valid-rmse:0.99844
[40]	train-rmse:1.04323	valid-rmse:1.04665
[100]	train-rmse:0.99962	valid-rmse:1.00309
[160]	train-rmse:0.99313	valid-rmse:0.99858
[469]	train-rmse:0.99006	valid-rmse:0.99844
[32m[I 2022-04-17 06:41:08,089][0m Trial 146 finished with value: 0.998428 and parameters: {'colsample_bytree': 0.8894892222426852, 'eta': 0.017955058542173972, 'max_depth': 3, 'n_estimators': 381, 'subsample': 0.9994031327170381}. Best is trial 143 with value: 0.998394.[0m
[06:41:12] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09411	valid-rmse:1.09732
[180]	train-rmse:1.03578	valid-rmse:1.03924
[120]	train-rmse:0.99768	valid-rmse:1.00114
[60]	train-rmse:1.02813	valid-rmse:1.03158
[120]	train-rmse:0.99750	valid-rmse:1.00105
[180]	train-rmse:0.99265	valid-rmse:0.99855
[20]	train-rmse:1.03218	valid-rmse:1.03565
[200]	train-rmse:1.03177	valid-rmse:1.03524
[140]	train-rmse:0.99638	valid-rmse:1.00000
[80]	train-rmse:1.01780	valid-rmse:1.02125
[140]	train-rmse:0.99622	valid-rmse:0.99993
[200]	train-rmse:0.99218	valid-rmse:0.99855
[220]	train-rmse:1.02815	valid-rmse:1.03162
[40]	train-rmse:1.00906	valid-rmse:1.01248
[160]	train-rmse:0.99559	valid-rmse:0.99936
[100]	train-rmse:1.01074	valid-rmse:1.01416
[160]	train-rmse:0.99542	valid-rmse:0.99931
[220]	train-rmse:0.99171	valid-rmse:0.99855
[240]	train-rmse:1.02490	valid-rmse:1.02837
[180]	train-rmse:0.99504	valid-rmse:0.99900
[60]	train-rmse:1.00048	valid-rmse:1.00386
[120]	train-rmse:1.00591	valid-rmse:1.00932
[180]	train-rmse:0.99485	valid-rmse:0.99896
[260]	train-rmse:1.02198	valid-rmse:1.02544
[240]	train-rmse:0.99125	valid-rmse:0.99858
[200]	train-rmse:0.99461	valid-rmse:0.99879
[80]	train-rmse:0.99702	valid-rmse:1.00064
[200]	train-rmse:0.99441	valid-rmse:0.99876
[140]	train-rmse:1.00258	valid-rmse:1.00599
[255]	train-rmse:0.99094	valid-rmse:0.99859
[32m[I 2022-04-17 06:46:22,238][0m Trial 152 finished with value: 0.998537 and parameters: {'colsample_bytree': 0.8821506366951988, 'eta': 0.027688771340589533, 'max_depth': 3, 'n_estimators': 174, 'subsample': 0.9511843712658324}. Best is trial 143 with value: 0.998394.[0m
[06:46:26] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[280]	train-rmse:1.01934	valid-rmse:1.02280
[0]	train-rmse:1.09849	valid-rmse:1.10167
[220]	train-rmse:0.99424	valid-rmse:0.99866
[100]	train-rmse:0.99550	valid-rmse:0.99938
[220]	train-rmse:0.99405	valid-rmse:0.99864
[160]	train-rmse:1.00029	valid-rmse:1.00373
[300]	train-rmse:1.01696	valid-rmse:1.02043
[20]	train-rmse:1.08774	valid-rmse:1.09098
[240]	train-rmse:0.99391	valid-rmse:0.99858
[240]	train-rmse:0.99374	valid-rmse:0.99855
[120]	train-rmse:0.99472	valid-rmse:0.99886
[180]	train-rmse:0.99867	valid-rmse:1.00217
[320]	train-rmse:1.01481	valid-rmse:1.01828
[40]	train-rmse:1.07808	valid-rmse:1.08137
[260]	train-rmse:0.99361	valid-rmse:0.99853
[260]	train-rmse:0.99345	valid-rmse:0.99850
[200]	train-rmse:0.99753	valid-rmse:1.00109
[140]	train-rmse:0.99411	valid-rmse:0.99864
[340]	train-rmse:1.01289	valid-rmse:1.01635
[60]	train-rmse:1.06941	valid-rmse:1.07274
[280]	train-rmse:0.99334	valid-rmse:0.99852
[280]	train-rmse:0.99312	valid-rmse:0.99848
[220]	train-rmse:0.99669	valid-rmse:1.00034
[160]	train-rmse:0.99358	valid-rmse:0.99855
[360]	train-rmse:1.01116	valid-rmse:1.01462
[80]	train-rmse:1.06164	valid-rmse:1.06500
[300]	train-rmse:0.99307	valid-rmse:0.99850
[300]	train-rmse:0.99284	valid-rmse:0.99846
[240]	train-rmse:0.99608	valid-rmse:0.99982
[180]	train-rmse:0.99312	valid-rmse:0.99852
[380]	train-rmse:1.00960	valid-rmse:1.01304
[100]	train-rmse:1.05467	valid-rmse:1.05806
[320]	train-rmse:0.99279	valid-rmse:0.99848
[320]	train-rmse:0.99255	valid-rmse:0.99845
[260]	train-rmse:0.99560	valid-rmse:0.99944
[400]	train-rmse:1.00818	valid-rmse:1.01163
[200]	train-rmse:0.99265	valid-rmse:0.99852
[120]	train-rmse:1.04843	valid-rmse:1.05184
[340]	train-rmse:0.99250	valid-rmse:0.99847
[340]	train-rmse:0.99227	valid-rmse:0.99845
[280]	train-rmse:0.99520	valid-rmse:0.99918
[420]	train-rmse:1.00692	valid-rmse:1.01036
[140]	train-rmse:1.04284	valid-rmse:1.04626
[220]	train-rmse:0.99220	valid-rmse:0.99850
[360]	train-rmse:0.99223	valid-rmse:0.99846
[360]	train-rmse:0.99202	valid-rmse:0.99845
[300]	train-rmse:0.99487	valid-rmse:0.99900
[440]	train-rmse:1.00577	valid-rmse:1.00921
[160]	train-rmse:1.03784	valid-rmse:1.04127
[240]	train-rmse:0.99178	valid-rmse:0.99849
[380]	train-rmse:0.99193	valid-rmse:0.99845
[380]	train-rmse:0.99175	valid-rmse:0.99845
[320]	train-rmse:0.99460	valid-rmse:0.99886
[460]	train-rmse:1.00474	valid-rmse:1.00818
[180]	train-rmse:1.03337	valid-rmse:1.03680
[260]	train-rmse:0.99138	valid-rmse:0.99849
[400]	train-rmse:0.99167	valid-rmse:0.99844
[400]	train-rmse:0.99147	valid-rmse:0.99845
[340]	train-rmse:0.99436	valid-rmse:0.99876
[480]	train-rmse:1.00381	valid-rmse:1.00725
[409]	train-rmse:0.99133	valid-rmse:0.99846
[32m[I 2022-04-17 06:56:33,706][0m Trial 155 finished with value: 0.99844 and parameters: {'colsample_bytree': 0.7962424796313526, 'eta': 0.016513976569473815, 'max_depth': 3, 'n_estimators': 114, 'subsample': 0.9855420533242533}. Best is trial 143 with value: 0.998394.[0m
[06:56:38] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[200]	train-rmse:1.02936	valid-rmse:1.03280
[0]	train-rmse:1.09699	valid-rmse:1.10018
[420]	train-rmse:0.99140	valid-rmse:0.99845
[360]	train-rmse:0.99414	valid-rmse:0.99869
[280]	train-rmse:0.99095	valid-rmse:0.99850
[500]	train-rmse:1.00296	valid-rmse:1.00642
[220]	train-rmse:1.02578	valid-rmse:1.02921
[20]	train-rmse:1.06304	valid-rmse:1.06640
[440]	train-rmse:0.99114	valid-rmse:0.99847
[380]	train-rmse:0.99394	valid-rmse:0.99863
[442]	train-rmse:0.99111	valid-rmse:0.99847
[300]	train-rmse:0.99053	valid-rmse:0.99848
[32m[I 2022-04-17 06:58:17,518][0m Trial 154 finished with value: 0.99844 and parameters: {'colsample_bytree': 0.8022291145451695, 'eta': 0.016316441605318453, 'max_depth': 3, 'n_estimators': 194, 'subsample': 0.999986097664461}. Best is trial 143 with value: 0.998394.[0m
[06:58:21] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[520]	train-rmse:1.00221	valid-rmse:1.00566
[0]	train-rmse:1.09685	valid-rmse:1.10005
[240]	train-rmse:1.02258	valid-rmse:1.02601
[40]	train-rmse:1.04031	valid-rmse:1.04374
[400]	train-rmse:0.99375	valid-rmse:0.99860
[540]	train-rmse:1.00151	valid-rmse:1.00498
[320]	train-rmse:0.99010	valid-rmse:0.99852
[20]	train-rmse:1.06123	valid-rmse:1.06460
[260]	train-rmse:1.01971	valid-rmse:1.02314
[60]	train-rmse:1.02521	valid-rmse:1.02863
[420]	train-rmse:0.99356	valid-rmse:0.99857
[560]	train-rmse:1.00090	valid-rmse:1.00437
[40]	train-rmse:1.03800	valid-rmse:1.04143
[338]	train-rmse:0.98971	valid-rmse:0.99852
[32m[I 2022-04-17 07:00:31,929][0m Trial 157 finished with value: 0.998466 and parameters: {'colsample_bytree': 0.8952465052562365, 'eta': 0.02574629293178263, 'max_depth': 3, 'n_estimators': 339, 'subsample': 0.9809160214800707}. Best is trial 143 with value: 0.998394.[0m
[07:00:36] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[280]	train-rmse:1.01715	valid-rmse:1.02058
[0]	train-rmse:1.09727	valid-rmse:1.10046
[80]	train-rmse:1.01519	valid-rmse:1.01861
[440]	train-rmse:0.99340	valid-rmse:0.99854
[580]	train-rmse:1.00033	valid-rmse:1.00382
[60]	train-rmse:1.02295	valid-rmse:1.02639
[300]	train-rmse:1.01486	valid-rmse:1.01829
[20]	train-rmse:1.06715	valid-rmse:1.07052
[100]	train-rmse:1.00855	valid-rmse:1.01197
[460]	train-rmse:0.99320	valid-rmse:0.99852
[600]	train-rmse:0.99982	valid-rmse:1.00332
[80]	train-rmse:1.01322	valid-rmse:1.01664
[320]	train-rmse:1.01281	valid-rmse:1.01623
[40]	train-rmse:1.04583	valid-rmse:1.04928
[120]	train-rmse:1.00414	valid-rmse:1.00755
[480]	train-rmse:0.99302	valid-rmse:0.99852
[620]	train-rmse:0.99935	valid-rmse:1.00288
[100]	train-rmse:1.00693	valid-rmse:1.01034
[340]	train-rmse:1.01098	valid-rmse:1.01439
[140]	train-rmse:1.00117	valid-rmse:1.00460
[60]	train-rmse:1.03080	valid-rmse:1.03428
[500]	train-rmse:0.99283	valid-rmse:0.99851
[640]	train-rmse:0.99893	valid-rmse:1.00247
[120]	train-rmse:1.00285	valid-rmse:1.00626
[160]	train-rmse:0.99916	valid-rmse:1.00264
[360]	train-rmse:1.00934	valid-rmse:1.01275
[80]	train-rmse:1.02025	valid-rmse:1.02374
[520]	train-rmse:0.99268	valid-rmse:0.99850
[660]	train-rmse:0.99855	valid-rmse:1.00210
[140]	train-rmse:1.00016	valid-rmse:1.00361
[180]	train-rmse:0.99779	valid-rmse:1.00134
[380]	train-rmse:1.00787	valid-rmse:1.01128
[100]	train-rmse:1.01285	valid-rmse:1.01635
[680]	train-rmse:0.99820	valid-rmse:1.00177
[540]	train-rmse:0.99250	valid-rmse:0.99850
[160]	train-rmse:0.99839	valid-rmse:1.00189
[200]	train-rmse:0.99681	valid-rmse:1.00047
[400]	train-rmse:1.00656	valid-rmse:1.00998
[120]	train-rmse:1.00764	valid-rmse:1.01116
[700]	train-rmse:0.99789	valid-rmse:1.00147
[560]	train-rmse:0.99233	valid-rmse:0.99849
[180]	train-rmse:0.99718	valid-rmse:1.00078
[220]	train-rmse:0.99610	valid-rmse:0.99989
[420]	train-rmse:1.00538	valid-rmse:1.00880
[140]	train-rmse:1.00398	valid-rmse:1.00751
[720]	train-rmse:0.99760	valid-rmse:1.00120
[580]	train-rmse:0.99215	valid-rmse:0.99850
[200]	train-rmse:0.99633	valid-rmse:1.00004
[240]	train-rmse:0.99559	valid-rmse:0.99948
[440]	train-rmse:1.00433	valid-rmse:1.00774
[160]	train-rmse:1.00138	valid-rmse:1.00493
[740]	train-rmse:0.99733	valid-rmse:1.00096
[600]	train-rmse:0.99201	valid-rmse:0.99850
[220]	train-rmse:0.99572	valid-rmse:0.99955
[260]	train-rmse:0.99521	valid-rmse:0.99920
[460]	train-rmse:1.00338	valid-rmse:1.00680
[607]	train-rmse:0.99194	valid-rmse:0.99850
[32m[I 2022-04-17 07:09:53,865][0m Trial 156 finished with value: 0.998487 and parameters: {'colsample_bytree': 0.8007948693431802, 'eta': 0.009936034945878466, 'max_depth': 3, 'n_estimators': 206, 'subsample': 0.9866920883175845}. Best is trial 143 with value: 0.998394.[0m
[180]	train-rmse:0.99951	valid-rmse:1.00311
[07:09:58] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09713	valid-rmse:1.10031
[760]	train-rmse:0.99708	valid-rmse:1.00073
[240]	train-rmse:0.99526	valid-rmse:0.99922
[280]	train-rmse:0.99484	valid-rmse:0.99899
[480]	train-rmse:1.00253	valid-rmse:1.00596
[200]	train-rmse:0.99818	valid-rmse:1.00183
[20]	train-rmse:1.06503	valid-rmse:1.06837
[780]	train-rmse:0.99686	valid-rmse:1.00053
[260]	train-rmse:0.99490	valid-rmse:0.99898
[300]	train-rmse:0.99452	valid-rmse:0.99885
[500]	train-rmse:1.00177	valid-rmse:1.00520
[220]	train-rmse:0.99720	valid-rmse:1.00093
[40]	train-rmse:1.04295	valid-rmse:1.04636
[800]	train-rmse:0.99665	valid-rmse:1.00035
[280]	train-rmse:0.99456	valid-rmse:0.99882
[320]	train-rmse:0.99427	valid-rmse:0.99876
[520]	train-rmse:1.00109	valid-rmse:1.00452
[240]	train-rmse:0.99647	valid-rmse:1.00029
[820]	train-rmse:0.99646	valid-rmse:1.00019
[60]	train-rmse:1.02784	valid-rmse:1.03129
[300]	train-rmse:0.99428	valid-rmse:0.99871
[340]	train-rmse:0.99404	valid-rmse:0.99869
[540]	train-rmse:1.00047	valid-rmse:1.00392
[260]	train-rmse:0.99594	valid-rmse:0.99983
[840]	train-rmse:0.99628	valid-rmse:1.00004
[80]	train-rmse:1.01753	valid-rmse:1.02093
[320]	train-rmse:0.99405	valid-rmse:0.99863
[360]	train-rmse:0.99382	valid-rmse:0.99864
[560]	train-rmse:0.99992	valid-rmse:1.00337
[280]	train-rmse:0.99547	valid-rmse:0.99950
[860]	train-rmse:0.99612	valid-rmse:0.99991
[100]	train-rmse:1.01053	valid-rmse:1.01390
[340]	train-rmse:0.99382	valid-rmse:0.99858
[380]	train-rmse:0.99360	valid-rmse:0.99861
[580]	train-rmse:0.99942	valid-rmse:1.00289
[300]	train-rmse:0.99511	valid-rmse:0.99926
[880]	train-rmse:0.99596	valid-rmse:0.99979
[120]	train-rmse:1.00574	valid-rmse:1.00910
[360]	train-rmse:0.99360	valid-rmse:0.99853
[400]	train-rmse:0.99338	valid-rmse:0.99858
[600]	train-rmse:0.99897	valid-rmse:1.00245
[320]	train-rmse:0.99479	valid-rmse:0.99909
[900]	train-rmse:0.99582	valid-rmse:0.99968
[380]	train-rmse:0.99339	valid-rmse:0.99851
[140]	train-rmse:1.00243	valid-rmse:1.00583
[420]	train-rmse:0.99318	valid-rmse:0.99857
[620]	train-rmse:0.99856	valid-rmse:1.00206
[340]	train-rmse:0.99452	valid-rmse:0.99897
[920]	train-rmse:0.99569	valid-rmse:0.99958
[400]	train-rmse:0.99318	valid-rmse:0.99849
[160]	train-rmse:1.00018	valid-rmse:1.00360
[440]	train-rmse:0.99299	valid-rmse:0.99855
[640]	train-rmse:0.99819	valid-rmse:1.00171
[360]	train-rmse:0.99428	valid-rmse:0.99887
[940]	train-rmse:0.99556	valid-rmse:0.99948
[420]	train-rmse:0.99296	valid-rmse:0.99848
[460]	train-rmse:0.99281	valid-rmse:0.99855
[180]	train-rmse:0.99860	valid-rmse:1.00205
[660]	train-rmse:0.99786	valid-rmse:1.00140
[380]	train-rmse:0.99405	valid-rmse:0.99880
[960]	train-rmse:0.99544	valid-rmse:0.99940
[440]	train-rmse:0.99277	valid-rmse:0.99847
[480]	train-rmse:0.99261	valid-rmse:0.99855
[200]	train-rmse:0.99746	valid-rmse:1.00099
[680]	train-rmse:0.99755	valid-rmse:1.00112
[980]	train-rmse:0.99534	valid-rmse:0.99932
[400]	train-rmse:0.99382	valid-rmse:0.99874
[460]	train-rmse:0.99256	valid-rmse:0.99847
[500]	train-rmse:0.99242	valid-rmse:0.99854
[700]	train-rmse:0.99728	valid-rmse:1.00086
[220]	train-rmse:0.99665	valid-rmse:1.00026
[999]	train-rmse:0.99523	valid-rmse:0.99926
[32m[I 2022-04-17 07:22:12,575][0m Trial 153 finished with value: 0.999255 and parameters: {'colsample_bytree': 0.8024033358254883, 'eta': 0.0027502038961016236, 'max_depth': 3, 'n_estimators': 49, 'subsample': 0.9498750327734377}. Best is trial 143 with value: 0.998394.[0m
[07:22:16] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[420]	train-rmse:0.99362	valid-rmse:0.99870
[0]	train-rmse:1.09715	valid-rmse:1.10034
[480]	train-rmse:0.99236	valid-rmse:0.99847
[520]	train-rmse:0.99225	valid-rmse:0.99853
[720]	train-rmse:0.99703	valid-rmse:1.00063
[240]	train-rmse:0.99604	valid-rmse:0.99975
[440]	train-rmse:0.99343	valid-rmse:0.99867
[20]	train-rmse:1.06540	valid-rmse:1.06875
[500]	train-rmse:0.99215	valid-rmse:0.99846
[540]	train-rmse:0.99205	valid-rmse:0.99854
[740]	train-rmse:0.99681	valid-rmse:1.00043
[260]	train-rmse:0.99557	valid-rmse:0.99940
[40]	train-rmse:1.04345	valid-rmse:1.04686
[460]	train-rmse:0.99323	valid-rmse:0.99865
[520]	train-rmse:0.99199	valid-rmse:0.99846
[560]	train-rmse:0.99187	valid-rmse:0.99853
[760]	train-rmse:0.99660	valid-rmse:1.00024
[60]	train-rmse:1.02836	valid-rmse:1.03179
[280]	train-rmse:0.99520	valid-rmse:0.99914
[480]	train-rmse:0.99306	valid-rmse:0.99863
[572]	train-rmse:0.99177	valid-rmse:0.99853
[32m[I 2022-04-17 07:25:47,113][0m Trial 159 finished with value: 0.998528 and parameters: {'colsample_bytree': 0.8052961239847664, 'eta': 0.01073589168455699, 'max_depth': 3, 'n_estimators': 329, 'subsample': 0.9804324863728532}. Best is trial 143 with value: 0.998394.[0m
[540]	train-rmse:0.99180	valid-rmse:0.99846
[07:25:51] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09545	valid-rmse:1.09865
[780]	train-rmse:0.99640	valid-rmse:1.00008
[80]	train-rmse:1.01800	valid-rmse:1.02141
[300]	train-rmse:0.99487	valid-rmse:0.99897
[500]	train-rmse:0.99287	valid-rmse:0.99861
[560]	train-rmse:0.99163	valid-rmse:0.99845
[20]	train-rmse:1.04438	valid-rmse:1.04779
[800]	train-rmse:0.99622	valid-rmse:0.99992
[100]	train-rmse:1.01093	valid-rmse:1.01432
[320]	train-rmse:0.99462	valid-rmse:0.99883
[520]	train-rmse:0.99270	valid-rmse:0.99861
[580]	train-rmse:0.99144	valid-rmse:0.99845
[40]	train-rmse:1.01928	valid-rmse:1.02272
[820]	train-rmse:0.99605	valid-rmse:0.99979
[120]	train-rmse:1.00606	valid-rmse:1.00945
[540]	train-rmse:0.99254	valid-rmse:0.99860
[340]	train-rmse:0.99440	valid-rmse:0.99874
[600]	train-rmse:0.99126	valid-rmse:0.99845
[840]	train-rmse:0.99590	valid-rmse:0.99967
[60]	train-rmse:1.00708	valid-rmse:1.01047
[140]	train-rmse:1.00272	valid-rmse:1.00613
[560]	train-rmse:0.99236	valid-rmse:0.99860
[360]	train-rmse:0.99418	valid-rmse:0.99867
[620]	train-rmse:0.99106	valid-rmse:0.99846
[860]	train-rmse:0.99575	valid-rmse:0.99956
[160]	train-rmse:1.00041	valid-rmse:1.00382
[80]	train-rmse:1.00108	valid-rmse:1.00449
[629]	train-rmse:0.99097	valid-rmse:0.99846
[32m[I 2022-04-17 07:30:21,476][0m Trial 160 finished with value: 0.998447 and parameters: {'colsample_bytree': 0.7995471478593792, 'eta': 0.011408944365626563, 'max_depth': 3, 'n_estimators': 602, 'subsample': 0.9832944390208495}. Best is trial 143 with value: 0.998394.[0m
[07:30:25] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09509	valid-rmse:1.09829
[580]	train-rmse:0.99220	valid-rmse:0.99860
[380]	train-rmse:0.99397	valid-rmse:0.99861
[880]	train-rmse:0.99562	valid-rmse:0.99947
[180]	train-rmse:0.99878	valid-rmse:1.00224
[100]	train-rmse:0.99805	valid-rmse:1.00158
[20]	train-rmse:1.04073	valid-rmse:1.04414
[600]	train-rmse:0.99203	valid-rmse:0.99859
[400]	train-rmse:0.99378	valid-rmse:0.99857
[200]	train-rmse:0.99763	valid-rmse:1.00114
[900]	train-rmse:0.99550	valid-rmse:0.99938
[120]	train-rmse:0.99644	valid-rmse:1.00012
[40]	train-rmse:1.01594	valid-rmse:1.01934
[620]	train-rmse:0.99185	valid-rmse:0.99860
[420]	train-rmse:0.99357	valid-rmse:0.99855
[220]	train-rmse:0.99680	valid-rmse:1.00038
[920]	train-rmse:0.99539	valid-rmse:0.99930
[60]	train-rmse:1.00474	valid-rmse:1.00812
[140]	train-rmse:0.99547	valid-rmse:0.99937
[640]	train-rmse:0.99169	valid-rmse:0.99859
[440]	train-rmse:0.99339	valid-rmse:0.99853
[240]	train-rmse:0.99619	valid-rmse:0.99984
[940]	train-rmse:0.99528	valid-rmse:0.99922
[80]	train-rmse:0.99959	valid-rmse:1.00302
[160]	train-rmse:0.99483	valid-rmse:0.99896
[660]	train-rmse:0.99153	valid-rmse:0.99859
[260]	train-rmse:0.99572	valid-rmse:0.99947
[460]	train-rmse:0.99321	valid-rmse:0.99851
[960]	train-rmse:0.99518	valid-rmse:0.99915
[100]	train-rmse:0.99713	valid-rmse:1.00069
[180]	train-rmse:0.99435	valid-rmse:0.99875
[680]	train-rmse:0.99138	valid-rmse:0.99859
[280]	train-rmse:0.99530	valid-rmse:0.99919
[980]	train-rmse:0.99508	valid-rmse:0.99909
[480]	train-rmse:0.99302	valid-rmse:0.99849
[120]	train-rmse:0.99584	valid-rmse:0.99958
[200]	train-rmse:0.99396	valid-rmse:0.99863
[700]	train-rmse:0.99122	valid-rmse:0.99859
[300]	train-rmse:0.99499	valid-rmse:0.99901
[999]	train-rmse:0.99498	valid-rmse:0.99904
[32m[I 2022-04-17 07:37:13,760][0m Trial 158 finished with value: 0.999044 and parameters: {'colsample_bytree': 0.8052824398013629, 'eta': 0.0029294614909846127, 'max_depth': 3, 'n_estimators': 615, 'subsample': 0.9851696774505145}. Best is trial 143 with value: 0.998394.[0m
[07:37:18] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[140]	train-rmse:0.99506	valid-rmse:0.99903
[500]	train-rmse:0.99284	valid-rmse:0.99849
[0]	train-rmse:1.09559	valid-rmse:1.09879
[220]	train-rmse:0.99361	valid-rmse:0.99858
[717]	train-rmse:0.99108	valid-rmse:0.99859
[320]	train-rmse:0.99471	valid-rmse:0.99887
[32m[I 2022-04-17 07:37:57,670][0m Trial 161 finished with value: 0.998584 and parameters: {'colsample_bytree': 0.8646899797992175, 'eta': 0.009264943310415682, 'max_depth': 3, 'n_estimators': 518, 'subsample': 0.9009891823513705}. Best is trial 143 with value: 0.998394.[0m
[07:38:02] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09585	valid-rmse:1.09905
[160]	train-rmse:0.99452	valid-rmse:0.99877
[20]	train-rmse:1.04585	valid-rmse:1.04925
[520]	train-rmse:0.99267	valid-rmse:0.99848
[340]	train-rmse:0.99448	valid-rmse:0.99879
[240]	train-rmse:0.99328	valid-rmse:0.99853
[20]	train-rmse:1.04872	valid-rmse:1.05211
[180]	train-rmse:0.99408	valid-rmse:0.99865
[40]	train-rmse:1.02071	valid-rmse:1.02413
[540]	train-rmse:0.99251	valid-rmse:0.99847
[360]	train-rmse:0.99425	valid-rmse:0.99872
[40]	train-rmse:1.02359	valid-rmse:1.02702
[260]	train-rmse:0.99293	valid-rmse:0.99851
[200]	train-rmse:0.99368	valid-rmse:0.99858
[60]	train-rmse:1.00812	valid-rmse:1.01150
[560]	train-rmse:0.99233	valid-rmse:0.99848
[380]	train-rmse:0.99404	valid-rmse:0.99865
[60]	train-rmse:1.01035	valid-rmse:1.01369
[280]	train-rmse:0.99258	valid-rmse:0.99849
[220]	train-rmse:0.99333	valid-rmse:0.99853
[80]	train-rmse:1.00178	valid-rmse:1.00519
[580]	train-rmse:0.99214	valid-rmse:0.99847
[400]	train-rmse:0.99384	valid-rmse:0.99862
[80]	train-rmse:1.00333	valid-rmse:1.00669
[240]	train-rmse:0.99292	valid-rmse:0.99848
[100]	train-rmse:0.99851	valid-rmse:1.00199
[300]	train-rmse:0.99227	valid-rmse:0.99849
[420]	train-rmse:0.99363	valid-rmse:0.99859
[600]	train-rmse:0.99198	valid-rmse:0.99847
[100]	train-rmse:0.99955	valid-rmse:1.00298
[120]	train-rmse:0.99674	valid-rmse:1.00034
[260]	train-rmse:0.99256	valid-rmse:0.99849
[320]	train-rmse:0.99197	valid-rmse:0.99849
[440]	train-rmse:0.99348	valid-rmse:0.99856
[120]	train-rmse:0.99748	valid-rmse:1.00098
[620]	train-rmse:0.99183	valid-rmse:0.99847
[140]	train-rmse:0.99571	valid-rmse:0.99948
[280]	train-rmse:0.99221	valid-rmse:0.99848
[337]	train-rmse:0.99170	valid-rmse:0.99849
[32m[I 2022-04-17 07:44:24,987][0m Trial 164 finished with value: 0.998477 and parameters: {'colsample_bytree': 0.8663888866673454, 'eta': 0.018722341293201133, 'max_depth': 3, 'n_estimators': 373, 'subsample': 0.9942660421474134}. Best is trial 143 with value: 0.998394.[0m
[07:44:29] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[460]	train-rmse:0.99330	valid-rmse:0.99854
[634]	train-rmse:0.99172	valid-rmse:0.99847
[32m[I 2022-04-17 07:44:51,765][0m Trial 162 finished with value: 0.998469 and parameters: {'colsample_bytree': 0.8668892009819411, 'eta': 0.010012514455149986, 'max_depth': 3, 'n_estimators': 925, 'subsample': 0.9980579975581072}. Best is trial 143 with value: 0.998394.[0m
[07:44:56] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[140]	train-rmse:0.99627	valid-rmse:0.99989
[0]	train-rmse:1.09363	valid-rmse:1.09686
[160]	train-rmse:0.99505	valid-rmse:0.99903
[299]	train-rmse:0.99190	valid-rmse:0.99849
[32m[I 2022-04-17 07:45:15,174][0m Trial 165 finished with value: 0.998476 and parameters: {'colsample_bytree': 0.7564454256216133, 'eta': 0.020635289579665445, 'max_depth': 3, 'n_estimators': 635, 'subsample': 0.9984448095027608}. Best is trial 143 with value: 0.998394.[0m
[07:45:19] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[20]	train-rmse:1.09906	valid-rmse:1.10224
[480]	train-rmse:0.99312	valid-rmse:0.99853
[160]	train-rmse:0.99550	valid-rmse:0.99931
[20]	train-rmse:1.02857	valid-rmse:1.03202
[180]	train-rmse:0.99454	valid-rmse:0.99879
[40]	train-rmse:1.09906	valid-rmse:1.10223
[20]	train-rmse:1.09906	valid-rmse:1.10224
[500]	train-rmse:0.99294	valid-rmse:0.99851
[180]	train-rmse:0.99496	valid-rmse:0.99898
[40]	train-rmse:1.00660	valid-rmse:1.01002
[200]	train-rmse:0.99413	valid-rmse:0.99864
[60]	train-rmse:1.09905	valid-rmse:1.10223
[40]	train-rmse:1.09906	valid-rmse:1.10223
[520]	train-rmse:0.99278	valid-rmse:0.99850
[200]	train-rmse:0.99453	valid-rmse:0.99878
[60]	train-rmse:0.99910	valid-rmse:1.00255
[220]	train-rmse:0.99379	valid-rmse:0.99857
[80]	train-rmse:1.09905	valid-rmse:1.10223
[540]	train-rmse:0.99262	valid-rmse:0.99849
[60]	train-rmse:1.09906	valid-rmse:1.10223
[80]	train-rmse:0.99628	valid-rmse:1.00002
[220]	train-rmse:0.99413	valid-rmse:0.99866
[240]	train-rmse:0.99346	valid-rmse:0.99855
[100]	train-rmse:1.09905	valid-rmse:1.10222
[560]	train-rmse:0.99247	valid-rmse:0.99848
[100]	train-rmse:0.99501	valid-rmse:0.99916
[240]	train-rmse:0.99382	valid-rmse:0.99859
[80]	train-rmse:1.09906	valid-rmse:1.10223
[260]	train-rmse:0.99316	valid-rmse:0.99852
[120]	train-rmse:1.09905	valid-rmse:1.10222
[580]	train-rmse:0.99230	valid-rmse:0.99848
[120]	train-rmse:0.99425	valid-rmse:0.99882
[260]	train-rmse:0.99352	valid-rmse:0.99855
[100]	train-rmse:1.09905	valid-rmse:1.10223
[280]	train-rmse:0.99284	valid-rmse:0.99849
[140]	train-rmse:1.09904	valid-rmse:1.10222
[600]	train-rmse:0.99214	valid-rmse:0.99848
[140]	train-rmse:0.99368	valid-rmse:0.99867
[280]	train-rmse:0.99322	valid-rmse:0.99851
[300]	train-rmse:0.99252	valid-rmse:0.99849
[120]	train-rmse:1.09905	valid-rmse:1.10223
[160]	train-rmse:1.09904	valid-rmse:1.10221
[620]	train-rmse:0.99198	valid-rmse:0.99849
[160]	train-rmse:0.99312	valid-rmse:0.99859
[300]	train-rmse:0.99292	valid-rmse:0.99848
[320]	train-rmse:0.99220	valid-rmse:0.99847
[140]	train-rmse:1.09905	valid-rmse:1.10223
[180]	train-rmse:1.09904	valid-rmse:1.10221
[640]	train-rmse:0.99182	valid-rmse:0.99848
[180]	train-rmse:0.99266	valid-rmse:0.99856
[320]	train-rmse:0.99263	valid-rmse:0.99847
[642]	train-rmse:0.99180	valid-rmse:0.99848
[32m[I 2022-04-17 07:53:50,361][0m Trial 163 finished with value: 0.998476 and parameters: {'colsample_bytree': 0.7538304006436902, 'eta': 0.009878480601230873, 'max_depth': 3, 'n_estimators': 1005, 'subsample': 0.9959776158934801}. Best is trial 143 with value: 0.998394.[0m
[07:53:54] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09624	valid-rmse:1.09944
[340]	train-rmse:0.99189	valid-rmse:0.99846
[200]	train-rmse:1.09903	valid-rmse:1.10221
[160]	train-rmse:1.09905	valid-rmse:1.10222
[200]	train-rmse:0.99211	valid-rmse:0.99854
[340]	train-rmse:0.99238	valid-rmse:0.99847
[20]	train-rmse:1.05321	valid-rmse:1.05663
[360]	train-rmse:0.99160	valid-rmse:0.99844
[220]	train-rmse:1.09903	valid-rmse:1.10221
[180]	train-rmse:1.09905	valid-rmse:1.10222
[220]	train-rmse:0.99166	valid-rmse:0.99854
[360]	train-rmse:0.99209	valid-rmse:0.99847
[40]	train-rmse:1.02842	valid-rmse:1.03192
[380]	train-rmse:0.99135	valid-rmse:0.99845
[240]	train-rmse:1.09903	valid-rmse:1.10220
[200]	train-rmse:1.09905	valid-rmse:1.10222
[240]	train-rmse:0.99123	valid-rmse:0.99857
[380]	train-rmse:0.99183	valid-rmse:0.99847
[400]	train-rmse:0.99104	valid-rmse:0.99846
[60]	train-rmse:1.01426	valid-rmse:1.01774
[260]	train-rmse:1.09903	valid-rmse:1.10220
[256]	train-rmse:0.99093	valid-rmse:0.99856
[32m[I 2022-04-17 07:57:25,274][0m Trial 169 finished with value: 0.998537 and parameters: {'colsample_bytree': 0.7519699052826694, 'eta': 0.028283793093468415, 'max_depth': 3, 'n_estimators': 117, 'subsample': 0.9658829071093672}. Best is trial 143 with value: 0.998394.[0m
[07:57:29] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09644	valid-rmse:1.09964
[220]	train-rmse:1.09904	valid-rmse:1.10222
[399]	train-rmse:0.99159	valid-rmse:0.99847
[32m[I 2022-04-17 07:57:45,402][0m Trial 167 finished with value: 0.998463 and parameters: {'colsample_bytree': 0.7587529696064285, 'eta': 0.016634228887992552, 'max_depth': 3, 'n_estimators': 371, 'subsample': 0.9961804230625461}. Best is trial 143 with value: 0.998394.[0m
[07:57:49] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.08883	valid-rmse:1.09208
[418]	train-rmse:0.99075	valid-rmse:0.99847
[32m[I 2022-04-17 07:58:00,998][0m Trial 166 finished with value: 0.998439 and parameters: {'colsample_bytree': 0.7586177305867777, 'eta': 0.017995850896528578, 'max_depth': 3, 'n_estimators': 371, 'subsample': 0.9992248725954552}. Best is trial 143 with value: 0.998394.[0m
[80]	train-rmse:1.00617	valid-rmse:1.00962
[07:58:05] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[280]	train-rmse:1.09902	valid-rmse:1.10220
[0]	train-rmse:1.08961	valid-rmse:1.09285
[20]	train-rmse:1.05566	valid-rmse:1.05907
[240]	train-rmse:1.09904	valid-rmse:1.10222
[20]	train-rmse:1.00690	valid-rmse:1.01034
[100]	train-rmse:1.00151	valid-rmse:1.00503
[300]	train-rmse:1.09902	valid-rmse:1.10219
[20]	train-rmse:1.00916	valid-rmse:1.01258
[40]	train-rmse:1.03123	valid-rmse:1.03468
[260]	train-rmse:1.09904	valid-rmse:1.10222
[40]	train-rmse:0.99640	valid-rmse:1.00021
[320]	train-rmse:1.09902	valid-rmse:1.10219
[120]	train-rmse:0.99877	valid-rmse:1.00238
[40]	train-rmse:0.99722	valid-rmse:1.00079
[60]	train-rmse:1.01670	valid-rmse:1.02013
[60]	train-rmse:0.99444	valid-rmse:0.99879
[280]	train-rmse:1.09904	valid-rmse:1.10221
[340]	train-rmse:1.09901	valid-rmse:1.10219
[140]	train-rmse:0.99711	valid-rmse:1.00086
[60]	train-rmse:0.99487	valid-rmse:0.99891
[80]	train-rmse:1.00806	valid-rmse:1.01150
[80]	train-rmse:0.99326	valid-rmse:0.99860
[360]	train-rmse:1.09901	valid-rmse:1.10218
[300]	train-rmse:1.09904	valid-rmse:1.10221
[160]	train-rmse:0.99606	valid-rmse:0.99995
[80]	train-rmse:0.99367	valid-rmse:0.99868
[100]	train-rmse:1.00293	valid-rmse:1.00637
[380]	train-rmse:1.09901	valid-rmse:1.10218
[100]	train-rmse:0.99225	valid-rmse:0.99860
[180]	train-rmse:0.99535	valid-rmse:0.99940
[320]	train-rmse:1.09904	valid-rmse:1.10221
[100]	train-rmse:0.99273	valid-rmse:0.99859
[120]	train-rmse:0.99984	valid-rmse:1.00329
[400]	train-rmse:1.09900	valid-rmse:1.10218
[120]	train-rmse:0.99139	valid-rmse:0.99861
[200]	train-rmse:0.99483	valid-rmse:0.99907
[340]	train-rmse:1.09903	valid-rmse:1.10221
[120]	train-rmse:0.99185	valid-rmse:0.99858
[140]	train-rmse:0.99791	valid-rmse:1.00144
[420]	train-rmse:1.09900	valid-rmse:1.10218
[140]	train-rmse:0.99049	valid-rmse:0.99862
[220]	train-rmse:0.99443	valid-rmse:0.99888
[143]	train-rmse:0.99033	valid-rmse:0.99864
[32m[I 2022-04-17 08:05:23,922][0m Trial 173 finished with value: 0.998575 and parameters: {'colsample_bytree': 0.8219851876586247, 'eta': 0.05383534369835421, 'max_depth': 3, 'n_estimators': 764, 'subsample': 0.968701354256449}. Best is trial 143 with value: 0.998394.[0m
[08:05:28] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[140]	train-rmse:0.99105	valid-rmse:0.99853
[360]	train-rmse:1.09903	valid-rmse:1.10221
[0]	train-rmse:1.09661	valid-rmse:1.09981
[160]	train-rmse:0.99669	valid-rmse:1.00032
[440]	train-rmse:1.09900	valid-rmse:1.10217
[240]	train-rmse:0.99409	valid-rmse:0.99874
[20]	train-rmse:1.05794	valid-rmse:1.06133
[160]	train-rmse:0.99024	valid-rmse:0.99852
[380]	train-rmse:1.09903	valid-rmse:1.10221
[180]	train-rmse:0.99585	valid-rmse:0.99966
[460]	train-rmse:1.09899	valid-rmse:1.10217
[260]	train-rmse:0.99382	valid-rmse:0.99866
[40]	train-rmse:1.03393	valid-rmse:1.03740
[180]	train-rmse:0.98954	valid-rmse:0.99853
[400]	train-rmse:1.09903	valid-rmse:1.10220
[200]	train-rmse:0.99528	valid-rmse:0.99925
[480]	train-rmse:1.09899	valid-rmse:1.10217
[280]	train-rmse:0.99355	valid-rmse:0.99860
[60]	train-rmse:1.01911	valid-rmse:1.02258
[200]	train-rmse:0.98862	valid-rmse:0.99855
[420]	train-rmse:1.09903	valid-rmse:1.10220
[500]	train-rmse:1.09899	valid-rmse:1.10217
[220]	train-rmse:0.99482	valid-rmse:0.99899
[300]	train-rmse:0.99324	valid-rmse:0.99856
[80]	train-rmse:1.01000	valid-rmse:1.01344
[217]	train-rmse:0.98799	valid-rmse:0.99860
[32m[I 2022-04-17 08:09:35,116][0m Trial 174 finished with value: 0.998492 and parameters: {'colsample_bytree': 0.8273626154421165, 'eta': 0.04966099263511946, 'max_depth': 3, 'n_estimators': 438, 'subsample': 0.9680212756667552}. Best is trial 143 with value: 0.998394.[0m
[08:09:39] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09797	valid-rmse:1.10115
[520]	train-rmse:1.09899	valid-rmse:1.10216
[240]	train-rmse:0.99446	valid-rmse:0.99883
[440]	train-rmse:1.09903	valid-rmse:1.10220
[320]	train-rmse:0.99297	valid-rmse:0.99852
[100]	train-rmse:1.00438	valid-rmse:1.00785
[20]	train-rmse:1.07824	valid-rmse:1.08154
[540]	train-rmse:1.09898	valid-rmse:1.10216
[260]	train-rmse:0.99418	valid-rmse:0.99872
[460]	train-rmse:1.09902	valid-rmse:1.10220
[120]	train-rmse:1.00088	valid-rmse:1.00439
[340]	train-rmse:0.99272	valid-rmse:0.99850
[560]	train-rmse:1.09898	valid-rmse:1.10216
[40]	train-rmse:1.06224	valid-rmse:1.06561
[280]	train-rmse:0.99389	valid-rmse:0.99864
[480]	train-rmse:1.09902	valid-rmse:1.10220
[140]	train-rmse:0.99865	valid-rmse:1.00224
[360]	train-rmse:0.99243	valid-rmse:0.99850
[580]	train-rmse:1.09898	valid-rmse:1.10215
[60]	train-rmse:1.04929	valid-rmse:1.05270
[300]	train-rmse:0.99362	valid-rmse:0.99858
[500]	train-rmse:1.09902	valid-rmse:1.10220
[160]	train-rmse:0.99722	valid-rmse:1.00090
[380]	train-rmse:0.99217	valid-rmse:0.99851
[600]	train-rmse:1.09898	valid-rmse:1.10215
[80]	train-rmse:1.03883	valid-rmse:1.04227
[320]	train-rmse:0.99338	valid-rmse:0.99855
[180]	train-rmse:0.99625	valid-rmse:1.00004
[520]	train-rmse:1.09902	valid-rmse:1.10219
[400]	train-rmse:0.99189	valid-rmse:0.99850
[401]	train-rmse:0.99187	valid-rmse:0.99850
[32m[I 2022-04-17 08:14:41,705][0m Trial 171 finished with value: 0.998492 and parameters: {'colsample_bytree': 0.828111779031061, 'eta': 0.014633475225388751, 'max_depth': 3, 'n_estimators': 75, 'subsample': 0.9359075391926983}. Best is trial 143 with value: 0.998394.[0m
[620]	train-rmse:1.09897	valid-rmse:1.10215
[08:14:45] WARNING: ../src/learner.cc:576: 
Parameters: { "n_estimators" } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[0]	train-rmse:1.09906	valid-rmse:1.10224
[100]	train-rmse:1.03039	valid-rmse:1.03387
[340]	train-rmse:0.99313	valid-rmse:0.99852
[200]	train-rmse:0.99555	valid-rmse:0.99951
[540]	train-rmse:1.09902	valid-rmse:1.10219
[640]	train-rmse:1.09897	valid-rmse:1.10214
[20]	train-rmse:1.09906	valid-rmse:1.10224
[120]	train-rmse:1.02359	valid-rmse:1.02707
[360]	train-rmse:0.99291	valid-rmse:0.99852
[220]	train-rmse:0.99507	valid-rmse:0.99916
[560]	train-rmse:1.09901	valid-rmse:1.10219
[660]	train-rmse:1.09897	valid-rmse:1.10214
[40]	train-rmse:1.09906	valid-rmse:1.10223
[140]	train-rmse:1.01812	valid-rmse:1.02160
[380]	train-rmse:0.99267	valid-rmse:0.99850
[240]	train-rmse:0.99467	valid-rmse:0.99893
[680]	train-rmse:1.09896	valid-rmse:1.10214
[580]	train-rmse:1.09901	valid-rmse:1.10219
[60]	train-rmse:1.09905	valid-rmse:1.10223
[160]	train-rmse:1.01371	valid-rmse:1.01718
[260]	train-rmse:0.99437	valid-rmse:0.99878
[400]	train-rmse:0.99242	valid-rmse:0.99850
